그들은 아름다운 그를 못나게 사랑한다.
그는 아름다운 너를 아름답게 사랑한다.
나는 허술한 그들을 아름답게 사랑한다.
오늘 아침, 신선한 공기를 마시며 새로운 하루를 시작했다.
거리를 거닐다가 만난 작은 카페에서 따뜻한 커피 한 잔의 여유를 즐겼다.
파란 하늘과 부드러운 구름이 어우러진 풍경이 마음을 설레게 한다.
바람이 살랑이는 오후, 잔잔한 음악 소리가 거리를 감쌌다.
저녁 노을이 붉게 물드는 순간, 하루의 피로가 씻겨 내려갔다.
고요한 밤하늘 아래 별빛이 반짝이며 꿈을 꾸게 했다.
오래된 책장에서 펼쳐진 이야기들이 잊혀진 추억을 불러일으킨다.
작은 정원에서 피어나는 꽃 한 송이가 마음의 위로를 주었다.
비 내리는 창밖을 바라보며, 고요한 시간을 음미했다.
내일의 희망을 안고 조용히 눈을 감는 순간, 세상 모든 것이 특별해졌다.
어제 밤, 달빛 아래 고요한 도시의 풍경을 감상했다.
아침 햇살이 창문을 통해 스며들며 새로운 기운을 주었다.
산책로를 따라 걷다가 만난 작은 강물이 마음을 편안하게 했다.
도심 속의 분주함 속에서도 한가로운 순간을 즐길 수 있었다.
가을바람이 나뭇잎을 흔들며 소리를 냈다.
잔잔한 음악 소리가 방 안을 가득 채워 기분을 좋게 했다.
작은 정원에서 피어나는 꽃들은 자연의 예술작품처럼 빛났다.
친구와의 짧은 대화 한마디가 하루의 피로를 씻어주었다.
비오는 오후, 창밖 풍경을 바라보며 차분한 생각에 잠겼다.
별이 빛나는 밤하늘 아래, 새로운 꿈을 꾸기 시작했다.
새벽녘, 도시의 불빛이 하나씩 깨어나는 모습을 보았다.
따뜻한 햇살이 가득한 아침, 창문을 열고 신선한 공기를 마셨다.
비 내리는 날, 창밖 풍경은 마치 수채화처럼 아름다웠다.
바람에 실려 온 꽃향기는 마음을 편안하게 해주었다.
조용한 공원에서 벤치에 앉아 책을 읽으며 시간을 보냈다.
밤하늘의 별들이 반짝이며 소원을 빌게 만들었다.
달빛 아래 고요한 강가를 따라 걷는 기분이 황홀했다.
오후의 여유로운 시간에 커피 한 잔의 여운을 즐겼다.
산책로를 따라 걷다 보면 새로운 영감을 얻을 수 있다.
바쁜 도심 속에서도 한가로운 순간은 소중하다.
아침의 첫 빛이 희망을 안겨주는 듯했다.
느긋하게 흐르는 강물 소리가 마음을 어루만졌다.
도서관에서 발견한 작은 보물 같은 책 한 권이 기억에 남았다.
길가에 피어난 작은 꽃들이 봄의 기운을 전해주었다.
산 정상에서 바라본 풍경은 말로 표현할 수 없을 정도로 아름다웠다.
조용한 음악이 흐르는 카페에서 소중한 만남을 가졌다.
바람에 실려 온 소리 없는 이야기들이 마음에 새겨졌다.
햇빛이 가득한 날씨 덕분에 모든 것이 활기차 보였다.
도시의 소음 속에서도 작은 평화를 느낄 수 있었다.
하늘을 수놓은 구름들이 마치 예술작품처럼 보였다.
따뜻한 차 한 잔과 함께하는 오후는 특별했다.
달콤한 디저트가 입안을 감싸며 행복을 선사했다.
고요한 호수 위에 떠 있는 작은 배가 마음을 설레게 했다.
아침 이슬이 맺힌 잔디밭 위에서 자연의 아름다움을 느꼈다.
바람에 흔들리는 나뭇잎들이 속삭이는 소리가 들렸다.
비가 그치고 난 후 나타난 무지개가 희망을 전해주었다.
조용한 밤, 창밖에 비치는 가로등 불빛이 따뜻했다.
도시의 분주함 속에서도 소소한 행복을 찾을 수 있었다.
자연 속에서의 산책은 언제나 마음을 치유해준다.
아침 공기를 마시며 하루의 계획을 세워보았다.
바쁜 일상 속에서 잠시 멈춰 서서 휴식을 즐겼다.
카페에서 들리는 잔잔한 음악이 마음의 안정을 주었다.
따뜻한 햇살이 비추는 창가에서 차 한 잔의 여유를 느꼈다.
자연의 소리를 들으며 산책하는 시간은 가장 소중하다.
도심 속 작은 정원에서 만난 평화로운 순간들이 기억에 남는다.
아침 햇살에 물든 거리는 새로운 시작을 알렸다.
차가운 겨울바람 속에서도 따뜻한 미소가 큰 힘이 되었다.
비 오는 날의 고요함이 마치 잊혀진 기억을 불러일으켰다.
도시의 불빛이 반짝이는 밤은 설레는 기분을 주었다.
작은 골목길을 걸으며 만난 예쁜 카페가 인상적이었다.
깊은 숲 속에서 들리는 새들의 노래가 마음을 울렸다.
바람이 불어오는 언덕 위에서 자유로운 기분을 만끽했다.
비 내리는 창가에서 바라본 도시 풍경은 몽환적이었다.
아침의 상쾌한 공기가 하루를 새롭게 만들어 주었다.
어둠이 내려앉은 도시의 불빛은 또 다른 아름다움을 보여주었다.
따뜻한 온실 안에서 피어나는 꽃들이 생명의 힘을 느끼게 했다.
조용한 음악 소리에 맞춰 흘러가는 시간은 잊을 수 없는 순간이었다.
바쁜 도시 생활 속에서도 자연의 소리를 들을 수 있었다.
한적한 호숫가에서 만난 작은 오솔길이 마음을 평온하게 했다.
창밖으로 보이는 구름 한 점 한 점이 이야기처럼 느껴졌다.
잔잔한 바람이 부는 오후, 창문을 열어 신선한 공기를 맞았다.
따스한 햇살 아래 걷는 길은 언제나 행복을 선사한다.
도심 속에서도 숨겨진 자연의 아름다움을 발견할 수 있다.
바람에 실린 소리가 골목길마다 속삭이듯 퍼져나갔다.
아름다운 노을이 하늘을 물들이며 하루를 마무리했다.
차가운 공기 속에서 따뜻한 커피 한 잔이 큰 위로가 되었다.
한적한 거리에서 들려오는 어린아이의 웃음소리가 잊지 못할 순간을 만들었다.
밤이 깊어갈수록 도시는 또 다른 얼굴을 드러냈다.
새벽녘에 들려오는 새소리가 하루의 시작을 알렸다.
바람에 흔들리는 꽃들이 마치 무용수처럼 우아하게 보였다.
한가로운 오후, 도서관에서 시간을 보내며 지식을 쌓았다.
거리를 거닐다가 우연히 만난 미소가 하루를 밝게 해주었다.
도시의 분주한 소음 속에서도 잔잔한 음악이 들려왔다.
봄의 기운을 담은 바람이 길을 따라 스며들었다.
따뜻한 햇살이 내리쬐는 공원에서 가족과 함께 산책했다.
어둠 속에서도 희망의 불빛은 결코 꺼지지 않았다.
조용한 카페에서 들리는 잔잔한 대화 소리가 마음을 위로해주었다.
아침의 서늘한 공기가 마음을 상쾌하게 했다.
비 오는 날, 창문에 맺힌 빗방울이 이야기를 속삭였다.
도시의 골목길을 걷다 보면 숨겨진 보석 같은 장소들이 나타난다.
따뜻한 차 한 잔과 함께하는 고요한 시간은 특별한 기억으로 남는다.
바람이 불어오는 들판에서 자유롭게 뛰어놀던 아이들의 웃음소리가 퍼졌다.
도시의 불빛 아래, 고요한 밤의 정취가 감돌았다.
아침 이슬이 맺힌 나뭇잎들이 빛을 받아 반짝였다.
창가에 앉아 들려오는 비 소리가 하루를 특별하게 만들어 주었다.
조용한 밤, 별빛이 도시의 소음을 잠재워 주었다.
새로운 시작을 알리는 아침의 첫 기운이 마음에 새겨졌다.
비 내리는 날의 차분한 분위기가 하루를 더 의미 있게 만들었다.
따스한 햇살 아래 펼쳐진 들판은 꿈을 꾸게 하는 풍경이었다.
고요한 새벽, 창밖으로 들려오는 바람 소리에 마음이 평온해졌다.
작은 거리의 작은 가게들이 따뜻한 미소로 맞아주었다.
도시의 분주함 속에서도 소중한 순간을 찾을 수 있었다.
바람에 실린 자연의 향기가 거리를 가득 채웠다.
어느새 저녁이 찾아와 도시는 또 다른 얼굴을 보였다.
창밖에 펼쳐진 풍경은 마치 한 폭의 그림 같았다.
새로운 도전을 앞둔 마음에 용기를 불어넣는 아침이었다.
비 오는 날, 창문을 두드리는 빗소리가 음악처럼 들렸다.
따뜻한 온기와 함께하는 오후는 잊을 수 없는 순간을 선사했다.
고요한 밤, 달빛 아래 펼쳐진 도시의 풍경은 특별했다.
조용한 산책로에서 들려오는 자연의 소리가 마음을 어루만졌다.
아름다운 계절의 변화가 눈앞에서 펼쳐지는 듯했다.
도시의 불빛이 어둠을 밝히며 새로운 이야기를 만들어냈다.
새벽녘, 고요한 공기가 마음의 안식을 선사했다.
한적한 골목길을 걸으며 우연히 마주친 미소가 잊히지 않았다.
비 내리는 날, 창가에 스치는 빗방울이 작은 이야기를 전해주었다.
따뜻한 오후 햇살이 골목길을 비추며 사람들을 반겼다.
조용한 카페의 분위기가 하루의 피로를 잊게 해주었다.
산책을 하며 들려오는 새들의 노래가 마음을 치유해주었다.
바람이 부는 언덕 위에서 느껴지는 자유로움이 가슴 깊이 스며들었다.
비 오는 밤, 창문 너머로 보이는 불빛들이 잔잔한 감동을 선사했다
1. 브라우저는 웹 캐시와 TCP 연결을 설정하고 웹 캐시에 있는 객체에 대한 HTTP 요청을 보낸다.
2. 웹 캐시는 객체의 사본이 저장되어 있는지 확인하고, **저장되어 있다면 클라이언트 브라우저로 HTTP 응답 메시지와 함께 객체를 전송한다.**
3. **갖고 있지 않다면, 기점 서버로 TCP 연결을 설정한다.**
   이후 웹 캐시는 캐시와 서버 간의 TCP 연결로 객체에 대한 HTTP 요청을 보낸다. 기점 서버는 웹 캐시로 HTTP 응답 메시지를 보낸다.
4. 웹 캐시의 객체를 수신할 때, 객체를 지역 저장장치에 복사하고 클라이언트 브라우저에 HTTP 응답 메시지를 보낸다. (이때, 이미 설정된 TCP를 통해 보낸다.)
- `server` for original requesting client
- `client` to origin server
- TCP 혼잡 제어는 각 TCP 연결이 공정하게 병목 링크를 공유하여 **같은 크기의 가용한 대역폭을 공평하게 나누게 해준다.**
- 만일 n개의 TCP 연결이 병목 링크에서 작동하고 있다면, 각 연결은 대략 대역폭의 1/n 씩을 사용하게 된다.
- 하나의 웹 페이지를 전송하기 위해 여러 개의 병렬 TCP 연결을 열게 함으로써 브라우저는 일종의 속임수로 링크 대역폭의 많은 부분을 받게 된다.
- 많은 HTTP/1.1 브라우저들은 6개까지 병렬 TCP 연결을 열고 HOL을 막을 뿐만 아니라 더 많은 대역폭을 사용할 수 있게 한다.
> HTTP/2의 주요 목표 중 하나는 하나의 웹 페이지를 전송하기 위한 병렬 TCP 연결의 수를 줄이거나 제거하는 데 있다.
이는 서버에서 열고 유지되는 데 필요한 소켓의 수를 줄일 뿐만 아니라 목표한 대로 TCP 혼잡 제어를 제어할 수 있게 하는 데 있다.
그러나 웹 페이지를 전송하기 위해 오직 하나의 TCP 연결만을 사용하게 될 경우에 HTTP/2는 HOL 블로킹을 피하기 위해 신중하게 구현된 메커니즘이 필요하다.
예를 들어, 비디오 클립과 크기가 작은 객체 8개의 요청이 들어오면, 서버는 9개의 객체를 보내기 위한 TCP 병렬 요청을 받게된다.
이때 (1) 비디오 클립을 1000개의 프레임으로 나누고 (2) 각 객체를 2개의 프레임으로 나누어 비디오 클립으로부터 하나의 프레임을 전송한다.
이후 프레임 인터리빙을 이용하여 각 소형 객체의 첫 번째 프레임을 보내고 이를 반복하여 HOL 블로킹을 피할 수 있다.
**HTTP 메시지를 독립된 프레임들로 쪼개고 인터리빙하고 반대편 사이트에서 재조립하는 것이야말로 HTTP/2의 가장 중요한 개선점이다.**
프레이밍은 HTTP/2 프로토콜의 프레임으로 구현된 다른 프레이밍 서브 계층에 의해 이루어진다.
서버가 HTTP 응답을 보내고자 할 때, 응답은 프레이밍 서브 계층에 의해 처리되며 프레임들로 나눠진다.
응답의 헤더필드는 하나의 프레임이 되고, 메시지 본문은 하나의 프레임으로 쪼개진다.
응답 프레임들은 서버의 프레이밍 서브 계층에 의해 인터리빙된 후 하나의 지속적인 TCP 연결상에서 전송된다.
프레임들이 클라이언트에 도착하면 프레이밍 서브 계층에서 처음 응답메시지로 재조립되며 브라우저에 의해 처리된다. (클라이언트에서 서버로 요청할 때도 마찬가지이다.)
각 HTTP 메시지를 독립적인 프레임으로 쪼개는 것 외에도 프레이밍 서브 계층은 프레임을 바이너리 인코딩한다.
바이너리 프로토콜은 파싱하기에 효율적이고, 더 작은 프레임 크기를 갖고, 에러에 강하다.
`메시지 우선순위화`는 개발자들로 하여금 요청들의 상대적 우선 순위를 조정할 수 있게 함으로써 애플리케이션의 성능을 최적화할 수 있게 해준다.
클라이언트가 하나의 특정 서버로 동시에 여러 개의 요청을 할 때, 각 메시지에 1에서 256 사이의 가중치를 부여함으로써 요청에 우선순위를 매길 수 있다.
> 높은 수치일수록 높은 우선순위를 갖는다.
클라이언트 또한 각 의존도에 따라 메시지의 ID를 지정하여 서로 다른 메시지들 간의 의존성을 나타낼 수 있다.
HTTP/2의 또 다른 특징은 서버로 하여금 **특정 클라이언트 요청에 대해 여러 개의 응답을 보낼 수 있게 해주는 데 있다.**
처음 요청에 대한 응답 외에도, 서버는 클라이언트의 요청 없이도 추가적인 객체를 클라이언트에게 **푸시**하여 보낼 수 있다.
이는 HTML 기반 페이지가 웹 페이지를 완벽하게 구동시킬 필요가 있는 객체들을 가리킬 수 있기에 가능하다.
이러한 객체에 대한 HTTP 요청을 기다리는 대신 서버는 HTML을 분석할 수 있고, 필요한 객체들을 식별할 수 있고,
**해당 객체들에 대한 요청이 도착하기도 전에** 해당 객체들을 클라이언트로 보낸다.
서버는 해당 요청들을 기다리는 데 소요되는 추가 지연을 없앤다.
트랜스 프로토콜인 QUIC(3장에서 다룬다) 위에서 작동하도록 설계된 새로운 HTTP 프로토콜로서, 완전히 표준화된 상태는 아니다.
이 절에서는 인터넷 전자메일 구조의 중심에 있는 애플리케이션 계층 프로토콜을 알아본다.
Three major components of Electronic mail:
`User agents`
`Mail servers`
`SMTP(Simple Mail Transfer Protocol)`
a.k.a. "mail reader"
사용자 에이전트는 사용자가 메시지를 읽고, 응답하고, 전달하고, 저장하고, 구성하게 해준다.
대표적으로 마이크로 소프트 아웃룩(Outlook), 애플 메일 등이 있다.
전자 메일 인프라스트럭처의 중심이다.
각 수신자는 메일 서버에 `메일 박스(mailbox)`를 갖고 있다.
메일 박스는 수신자의 메시지를 유지하고 관리한다.
일반 메시지는 송신자의 사용자 에이전트에서 전달이 시작되고, 송신자의 메일 서버를 거친 후에 수신자의 메일 서버로 전달된다.**
거기서 수신자의 메일 박스에 저장된다.
전자메일 박스에 있는 메시지를 보려면 메일 서버는 사용자 계정과 비밀 번호를 이용하여 이용자를 인증하여야 한다.
신자는 메일 서버의 고장에도 대처해야 한다.
만약 메일을 수신자의 메일 서버로 전달할 수 없다면 그 메시지를 `메시지 큐(queue)`에 보관하고 나중에 그 메시지를 전달하기 위해 다시 시도한다.
재시도는 약 30분마다 일어나고, 계속 실패 시에 서버는 그 메시지를 제거하고 송신자에게 통보한다.
MTP는 메일을 송신자의 메일 서버로부터 수신자의 메일 서버로 전송하는 데에 `TCP의 신뢰적인 데이터 전송 서비스`를 이용한다.
SMTP는 대부분의 애플리케이션 계층 프로토콜처럼, `클라이언트`와 `서버`를 갖고 있다.
SMTP의 클라이언트와 서버 모두가 모든 메일 서버에서 수행되고, 상대 메일로 송신할 때는 클라이언트가 되고 수신할 때는 서버가 된다.
SMTP에서는 모든 메일 메시지의 몸체는 단순한 `7-bit ASCII`여야 한다.
이 때문에 전송 용량이 제한되어 커다란 첨부 파일이나 비디오 파일을 보낼 때 문제를 일으킨다.
1. handshaking (greeting)
2. transfer of messages (data exchange)
3. closure
1. 앨리스는 `전자 메일 사용자 에이전트`를 수행하고, 밥의 전자 메일 주소를 제공하여 메시지를 보내라고 명령한다.
2. 앨리스의 사용자 에이전트는 메시지를 그녀의 `메일 서버`에게 보내고, 그곳에서 메시지는 `메시지 큐`에 놓인다.
3. 앨리스의 메일 서버에서 동작하는 SMTP의 클라이언트 측은 메시지 큐에 있는 메시지를 본다.
4. 초기 SMTP 핸드셰이킹 이후에 SMTP 클라이언트는 앨리스의 메시지를 TCP 연결로 보낸다.
5. 밥의 메일 서버 호스트에서 SMTP의 서버 측은 메시지를 수신한다. 밥의 `메일 서버`는 그 메시지를 밥의 `메일 박스`에 놓는다.
6. 밥은 편한 시간에 그 메시지를 읽기 위해 `사용자 에이전트`를 시동한다.
> SMTP는 두 메일 서버가 먼 거리에 떨어져 있더라도 **중간 메일 서버를 이용하지 않는다.**
즉, 메시지를 보낼 때 보내는데 실패하더라도 중간 메일 서버에 저장되는 것이 아니라 **송신자의 메일 서버에 남아있다.**
1. 클라이언트 SMTP는 서버의 SMTP의 `25번 포트`로 `TCP 연결`을 설정한다. 서버가 죽어있다면 나중에 시도한다.
2. 연결이 설정되면, `애플리케이션 계층 핸드셰이킹`을 수행한다.
   이때 SMTP 클라이언트는 송신자의 전자메일 주소와 수신자의 전자메일 주소를 제공한다.
3. 이후 클라이언트는 메시지를 보낸다. (TCP의 신뢰적인 데이터 전송 서비스에 의존)
4. **보낼 다른 메시지가 있다면 같은 TCP 연결 상에서 반복하며**, 그렇지 않으면 TCP를 닫는다. (`지속 연결(persistent connection)`)
- 클라이언트는 5개의 `HELO`, `MAIL FROM`, `RCPT TO`, `DATA`, `QUIT` 명령을 내린다.
- 클라이언트는 하나의 점(`.`)으로 된 라인을 송신하며, 그것은 **서버에서 메시지의 끝을 나타낸다.**
- 서버는 각 명령에 응답하며, 각 응답에는 응답 코드와 영문 설명이 있다.
**SMTP는 `지속 연결(persistent connection)`을 사용한다.**
즉, 같은 수신 메일 서버로 보내는 여러 메시지를 갖고 있다면, **같은 TCP 연결을 통해 모든 메시지를 전달할 수 있다.**
telnet 명령어를 사용하면 원격 메일 서버와 위와 같은 대화를 할 수 있다.
전자메일을 보낼 때 주변 정보가 포함된 `헤더(header)`가 `메시지 몸체(body)` 앞에 오게 된다.
이 헤더는 RFC 5322에 정의되어 있으며, 헤더와 몸체는 CRLF로 분리된다.
모든 헤더는 `From:` 헤더라인과 `To:` 헤더 라인을 반드시 가져야 한다. (나머지 헤더는 선택사항이다.)
일반 메시지 헤더는 다음과 같다.
> `메일 서버`가 메일 박스를 관리하고, SMTP의 클라이언트와 서버 측 모두를 수행한다.
메일 서버가 로컬 호스트에 있다면, 호스트는 언제든 도착할 수 있는 전자 메일을 수신하기 위해 항상 켜져 있어야 하고 인터넷에 연결되어 있어야 한다.
이는 대부분의 인터넷 사용자에게는 비현실적이다.
대신에 일반 사용자는 로컬 호스트에서 사용자 에이전트를 수행하고 **늘 켜져 있는 공유 메일 서버에 저장된 메일박스에 접근한다.**
메일 서버는 보통 사용자들과 공유한다.
> 클라이언트의 사용자 에이전트는 수신자의 메일 서버로 직접 대화하지 않는다.
대신에 그림처럼 (1) 클라이언트의 사용자 에이전트는 **클라이언트의 메일 서버로 전자메일 메시지를 `SMTP` 또는 `HTTP`를 이용하여 보낸다.**
(2) 그리고 수신자의 메일 서버는 **`SMTP`를 이용하여 수신자의 메일 서버로 전자메일 메시지를 중계한다.**
두 단계 절차를 거치는 주요 이유는 수신자의 메일 서버를 통해 중계하지 않으면 수신자의 에이전트는 목적지 메일 서버에 도달할 수 없기 때문이다.
송신자는 전자메일을 자신의 메일 서버에 먼저 저장하고, 수신자의 메일 서버는 그 메시지를 수신자의 메일 서버로 받을 때까지 30분 마다 반복해서 보내려고 한다.
수신자는 자신의 ISP 내부의 메일 서버에 메시지를 어떻게 얻을 수 있는가?
SMTP는 `push` 프로토콜인 반면 메시지를 얻는 것은 `pull` 동작이기 때문에 다른 프로토콜을 사용하여야 한다.
두 가지 대표적인 방법
- `IMAP` : RFC 3501에 정의된 인터넷 메일 접근 프로토콜
IP 주소는 4 바이트로 구성되고, **계층구조를 갖는다.**
이러한 이유로 호스트는 흔히 말하는 `IP 주소(IP address)`로 식별된다.
- `121.7.106.83`과 같은 형태로 0 ~ 255의 십진수로 표현하는 각 바이트는 점으로 구분한다.
- **계층구조여서 왼쪽에서 오른쪽으로 조사함으로써, 그 호스트가 인터넷의 어디에 위치하는지에 대한 자세한 정보를 얻을 수 있다.**
  (더 자세히는 4장에서 논의한다.)
사람은 호스트 네임을 선호하지만, 라우터는 고정 길이의 계층구조를 가진 IP 주소를 선호한다.
> 이 차이를 절충하기 위해 **호스트 이름을 IP 주소로 변환해주는** 디렉터리(directory) 서비스가 필요하다.
> 이 서비스가 인터넷 `DNS(Domain name system)`의 주요 임무다. (`hostname translations, address resolutions`)
1. DNS 서버들의 **계층구조**로 구현된 **분산** 데이터 베이스이다.
   implemented in hierarchy of many name servers
2. 호스트가 분산 데이터 베이스로 질의하도록 허락하는 **애플리케이션 계층 프로토콜**이다.
DNS 서버는 주로 BIND(Berkeley Internet Name Domain) 소프트웨어를 수행하는 유닉스(UNIX) 컴퓨터다.
DNS 프로토콜은 `UDP` 상에서 수행되고 `포트 번호 53`을 이용한다.
TCP의 경우 데이터 전송 시작 전에 3-way-handshaking 과정이 있는 반면, UDP는 연결 설정에 드는 비용이 없다.
> DNS는 신뢰성보다 **속도가 더 중요한 서비스이기 때문에** TCP보다 UDP가 더 적합하다.
또한, UDP는 512 bytes를 넘어가지 않는 패킷만 전송이 가능하고 오버헤드가 없어서 속도가 빠른데,
DNS가 전송하는 데이터 패킷 사이즈가 매우 작으므로 UDP가 유리하다.
이때 단순히 패킷의 사이즈가 작다고 DNS가 UDP를 채택한 것은 아니고,
**전달하는 패킷의 크기가 작기 때문에 신뢰성이 보장되지 않아도 되기 때문이다.** (못 받으면 다시 전달하면 된다.)
TCP는 호스트 간의 연결 상태를 유지한다.
이때 TCP의 패킷 안에는 여러 정보가 담겨 있지만, UDP는 어떤 정보도 기록하지 않고 유지할 필요도 없다.
> DNS 서버는 TCP보다 많은 클라이언트를 수용할 수 있으므로 **연결 상태를 유지하지 않고 정보 기록을 최소화할 수 있는** UDP를 채택하였다.
1. 같은 사용자 컴퓨터는 DNS 애플리케이션의 클라이언트를 수행한다.
2. 브라우저는 URL로부터 호스트 이름을 추출하고 그 호스트 이름을 DNS 애플리케이션의 클라이언트에 보낸다.
3. DNS 클라이언트는 DNS 서버로 호스트 이름을 포함하는 질의를 보낸다. (client queries to DNS server)
4. DNS 클라이언트는 결국 호스트 이름에 대한 IP 주소를 받게 된다.
5. 브라우저가 DNS로부터 IP 주소를 받으면,
   브라우저는 해당 IP 주소와 그 주소의 80번 포트에 위치하는 HTTP 서버 프로세스로 TCP 연결을 초기화한다.
DNS는 위 예시에서 알 수 있듯이 추가 지연을 주지만,
가까운 DNS 서버에 `캐싱`되어 있어서 평균 DNS 지연 뿐만 아니라 DNS 네크워크 트래픽 감소에 도움을 준다.
복잡한 호스트 이름을 가진 호스트는 하나 이상의 별명을 가질 수 있다.
이 경우에 `relay1.west-coast.enterprise.com`를 `정식 호스트 이름(canonical hostname)`이라고 한다.
> DNS는 호스트의 IP 주소 뿐만 아니라 제시한 **별칭 호스트 이름에 대한 정식 호스트 이름을 얻기 위해** 이용될 수 있다.
전자 메일 주소는 간단하지만 그 서버의 호스트 네임은 일반적으로 더 복잡하다.
> load balancing among the servers
**인기 있는 사이트는 여러 서버에 중복되어 있어서, 각 서버가 다른 종단 시스템에서 수행되고 다른 IP 주소를 갖는다.**
이때 여러 IP 주소가 하나의 정식 호스트 이름과 연관되어 있다. DNS 데이터베이스는 이 IP 주소 집합을 갖고 있다.
**클라이언트가 주소 집합으로 매핑하는 호스트 이름에 대한 DNS 질의를 하면, 서버는 IP 주소 집합 전체를 가지고 응답한다.**
**각 응답에서의 주소는 순환식으로 보낸다.**
클라이언트는 대체로 주소 집합 내부의 첫 번째 IP 주소로 HTTP 요청 메시지를 보내므로, **DNS의 순환 방식은 트래픽을 분산하는 효과를 낸다.**
사용자의 호스트에서 실행되는 어떤 애플리케이션이 호스트 이름을 IP 주소로 변환하려 한다고 가정하자.
1. 애플리케이션이 호스트 이름을 명시하여 DNS 클라이언트 호출한다.
2. 사용자 호스트의 DNS는 네트워크에 질의 메시지를 보낸다.
   이때 모든 질의와 응답 메시지는 `포트 53의 UDP 데이터그램`으로 보내진다.
3. 응답 메시지를 애플리케이션에 전달한다.
DNS는 간단해보이지만 매우 복잡한데, 이는 전 세계에 분산된 많은 DNS 서버 뿐만 아니라
DNS 서버와 질의를 하는 호스트 사이에서 어떻게 통신하는지를 명시하는 애플리케이션 계층 프로토콜로 구성되어 있다.
> why not centralize DNS?
만약 DNS가 간단한 설계로 모든 매핑을 포함하는 하나의 인터넷 네임 서버를 갖고 있다면, 수많은 호스트를 가진 오늘날 다음과 같은 문제를 일으킬 수 있다.
- 서버의 고장 : 이 네임 서버가 고장 나면, 전체 인터넷이 작동하지 않는다. (`single point of failure`)
- 트래픽 양의 과부하 : 단일 DNS 서버가 모든 질의를 해결해야 한다.
- 먼 거리의 중앙 집중 데이터베이스: 단일 DNS 서버가 모든 질의 클라이언트로부터 '가까울' 수만은 없다. 즉, 멀면 멀수록 모든 질의가 느려진다.
- 유지 관리
  - 단일 네임 서버는 모든 인터넷 호스트에 대한 레코드를 유지해야 한다.
  - 모든 새로운 호스트를 반영하기 위해 자주 갱신되어야 하고, 사용자에게 호스트를 등록할 수 있도록 허용하는 것과 관련된 인증 문제가 있다.
요약하면 중앙 집중 데이터베이스는 **확장성(scalability)이 전혀 없고**, 결과적으로 DNS는 분산되도록 설계되어있다.
DNS는 많은 서버를 이용하고 이들을 계층 형태로 구성하며 전세계에 분산시킨다.
- 1000개 이상의 루트 서버 인스턴스가 세계에 흩어져 있다.
- 루트 네임 서버는 TLD 서버의 IP 주소들을 제공한다.
- `인터넷 할당 번호 관리기관 ICANN(Internet Corporation for Assigned Names and Numbers)`에 의해 조정된다.
- Top-Level Domain, TLD
- `com`, `org`, `net` 같은 상위 레벨 도메인과 `kr`, `uk` 같은 모든 국가의 상위 레벨 도메인에 대한 TLD 서버가 있다.
- Authoritative(책임) DNS 서버에 대한 IP 주소를 제공한다.
- 인터넷에서 접근하기 쉬운 호스트를 가진 모든 기관은 호스트 이름을 IP 주소로 매핑하는 공개적인 DNS 레코드를 제공해야 한다.
  - 기관의 책임 DNS 서버는 이 DNS 레코드를 갖고 있다.
- 기관은 직접 자신의 책임 DNS 서버의 구현을 선택할 수 있고, 일부 서비스 제공자의 책임 DNS 서버에 이 레코드를 저장하도록 비용을 지불한다.
- 로컬 DNS 서버는 서버들의 계층 구조에 엄격하게 속하지는 않지만 DNS 구조의 중심에 있다.
- ISP는 로컬 DNS 서버를 갖고, 로컬 DNS 서버로부터 IP 주소를 호스트에게 제공한다.
- 대체로 호스트에 가까이 있기 때문에 지연이 적다.
일반적으로 TLD 서버는 위의 예시와 같이 책임 DNS 서버를 알지 않고, 책임 DNS 서버를 아는 중간 DNS 서버를 알고 있다.
즉, 해당 질의 과정 까지 포함되면 전체 10번의 메시지를 보내게 된다.
위 예는 `재귀적 질의`와 `반복적 질의`를 사용한다.
`cse.nyu.edu`로부터 `dns.nyu.edu`로 보내는 질의는 자신을 필요한 매핑을 대신하여 얻도록 `dns.nyu.edu`에 요구하므로 재귀적 질의이고,
나머지는 반복적 질의다.
> 일반 질의는 전형적으로 반복적 질의를 따른다.
- 재귀적 질의에서는 높은 계층에 있는 DNS server가 책임져야 하는 것들이 많다.
  - puts burden of name resolutions on contacted name server
  - heavy load at upper levels of hierarchy
- 중요한 infra를 지키는 것이 훨씬 낫기 때문에, 중요한 root name server 보단 default name server가 일을 더 하는 것이 좋다.
실제로는 DNS 지연 성능 향상과 네트워크의 DNS 메시지 수를 줄이기 위해 `캐싱(caching)`을 사용한다.
> 질의 사슬에서 **DNS 서버는 DNS 응답을 받았을 때 로컬 메모리에 응답에 대한 정보를 저장할 수 있다.**
만약 호스트의 이름과 IP 주소 쌍이 DNS 서버에 저장되고 다른 호스트 이름으로부터 같은 질의가 DNS 서버로 도착한다면,
DNS 서버는 호스트 이름에 대한 책임이 없을 때조차 원하는 주소를 제공할 수 있다.
호스트 DNS와 IP 사이의 매핑과 호스트는 영구적이지 않기 때문에 어떤 기간(`TTL, Time to Live`) 이후에 저장된 정보를 제거한다.
로컬 DNS 서버는 구체적인 IP 주소 이외에도 TLD 서버의 IP를 저장하여 루트 DNS 서버를 우회할 수 있게 한다.
각 DNS는 **하나 이상의 자원 레코드를 가진** 메시지로 응답한다.
DNS 서버들은 호스트 이름을 IP 주소로 매핑하기 위한 `자원 레코드(Resource Records)`를 저장한다.
자원 레코드는 다음과 같은 필드를 포함하는 4개의 Tuple로 되어 있다.
- Value : 별칭 호스트 이름 Name을 갖는 메일 서버의 정식 이름
- MX 레코드는 메일 서버의 호스트 이름이 간단한 별칭을 갖는 것을 허용한다.
메일 서버의 정식 이름을 얻기 위해서는 MX 레코드에 대한 질의를 해야 하고, 다른 서버의 정식 이름을 얻기 위해선 CNAME 레코드에 대한 질의를 한다.
DNS 서버가 특별한 호스트 이름에 대한 책임 서버이면, 그 DNS 서버는 호스트 이름에 대한 Type A 레코드를 포함한다.
서버가 호스트 이름에 대한 책임 서버가 아니라면, 그 서버는 호스트 이름을 포함하는 DNS 서버의 IP 주소를 제공하는 Type A 레코드도 포함할 것이다.
DNS의 요청과 응답 메시지는 모두 아래 그림과 같은 포맷을 갖고 있다.
`처음 12 byte의 헤더 영역` : 여러 필드를 갖고 있다.
- 첫 필드는 질의를 식별하는 16 bit의 숫자이다.
  이 식별자는 질의에 대한 응답 메시지에 복사되어, 클라이언트가 보낸 질의와 수신된 응답 간의 일치를 식별하게 한다.
- `플래그(flag) 필드`에는 여러 개의 플래그가 있다.
  - 1 비트의 `질의/응답 플래그`는 메시지가 질의인지 응답인지 구분하게 한다.
  - 1 비트의 `책임 플래그`는 DNS 서버가 질의 이름에 대해 책임 서버일 때 응답 메시지에 설정된다.
  - 1 비트의 `재귀 요구 플래그`는 DNS 서버가 레코드를 갖지 않을 때 재귀적 질의를 수행하기를 클라이언트가 원할 때 설정된다.
  - 1 비트로 된 `재귀 가능 필드`는 DNS 서버가 재귀 질의를 지원하면 응답에 설정된다.
- 나머지 4개의 `'개수' 필드`는 헤더 다음에 오는 데이터 영역의 네 가지 타입의 발생 횟수를 나타낸다.
도메인 네임 `networkutopia.com`을 `등록 기관(DNS registrar)`에 등록한다고 가정해보자.
> `등록 기관(DNS registrar)`은 도메인 네임의 유일성을 확인하고,
> 그 도메인 네임을 DNS 데이터베이스에 넣고, 그 서비스에 대한 요금을 받는 상업 기관이다.
이전에는 작은 등록기관이 독점했었지만, 이제는 많은 기관이 경쟁하고 ICANN이 이러한 여러 등록기관을 승인해준다.
도메인 네임을 어떤 등록기관에 등록할 때 등록 기관에 주책임 서버와 부책임 서버의 이름과 IP 주소를 등록기관에 제공해야 한다.
- 주책임 서버 : `dns1.networkutopia.com` / 주책임 서버 IP : 212.2.212.1
- 부책임 서버 : `dns2.networkutopia.com` / 부책임 서버 IP : 212.2.212.2
위와 같다고 가정하자.
이 두 책임 DNS 서버 각각에 대해 등록 기관은 `Type NS`와 `Type A` 레코드가 **TLD com 서버에 등록되도록 확인한다.**
특히 주책임 서버의 경우 다음 두 개의 자원 레코드를 DNS 서버에 삽입한다.
또한, `Type A` 레코드와 메일 서버에 대한 `Type MX` 자원 레코드가 **책임 DNS 서버에 등록되는 것을 확인한다.**
이러한 모든 단계가 끝나면 여러 사람들이 웹 사이트를 방문할 수 있고, 전자메일을 보낼 수 있게 된다.


공격자는 DNS 루트 서버로 다량의 패킷을 보내려는 시도를 하여 다른 DNS 질의들이 응답을 받지 못하게 하려 한다.

실제로 이 일이 일어났지만, 많은 DNS 루트 서버들은 루트 서버로 향하는 공격자가 사용한 ICMP 핑 메시지를 블록하도록 형상화한 패킷 필터로 보호되었고,
대부분의 로컬 DNS 서버가 최상위 도메인 서버들의 IP 주소들을 캐싱하고 있어서 피해가 거의 없었다.

즉, 더 효과적인 공격은 최상위 도메인 서버를 공격하는 것이고, 실제로 최상위 도메인 서비스 제공자 Dyn에 이러한 일이 발생했다.

이는 유명 애플리케이션들이 무차별 교란되는 결과를 야기했다.

공격자는 DNS 서버로 가짜 응답을 보내어 그 서버가 자신의 캐시에 가짜 레코드를 받아들이도록 속임수를 쓴다.

이러한 공격은 웹 사용자들을 공격자의 웹사이트로 유도하는 데 이용될 수 있다.

이러한 공격을 막기 위해 DNS 보안 확장 프로토콜이 개발되어 사용되고 있다.


> P2P 구조는 항상 켜져있는 인프라스트럭처 서버에 최소한으로 의존하고, **간헐적으로 연결되는 호스트 쌍들(피어, peer)이 서로 직접 통신한다.**

- 클라이언트-서버 파일 분배에서 서버는 파일 복사본을 각 클라이언트에게 보내려면 서버에게 커다란 부하를 주고, 많은 양의 서버 대역폭을 소비한다.
- **P2P 파일 분배에서 각 피어는 수신한 파일의 임의의 부분을 다른 피어들에게 재분배할 수 있어서 서버의 분배 프로세스를 도울 수 있다.**

2020년에 가장 인기 있는 **P2P 파일 분배 프로토콜**은 `비트 토렌트(BitTorrent)`다.

서버와 피어들은 접속 링크로 인터넷에 연결되어 있다.

- 서버의 접속 링크 업로드 속도를 `u(s)`로, i번째 피어의 접속 링크 업로드 속도는 `u(i)`로,
  그리고 i번째 피어의 접속 링크 다운로드 속도는 `d(i)`로 나타낸다.
- 또한, 분배되는 파일의 크기는 `F bit`로, 파일을 얻고자 하는 피어들의 수는 `N`으로 나타낸다.

`분배 시간`은 **모든 N개의 피어들이 파일의 복사본을 얻는데 걸리는 시간**이다.

다음 분배 시간에 대한 분석에서 클라이언트-서버와 P2P 구조 모두의 경우, 인터넷 코어가 풍부한 대역폭을 갖고 있다는 간단한 가정을 하며,
이는 모든 병목 현상은 다른 네트워크 애플리케이션에 참여하지 않아서 이들의 모든 업로드와 다운로드 접속 대역폭은 이 파일 분배에 모두 사용된다고 가정한다.


- **서버는 파일 복사본을 N개의 피어 각각에게 전송해야 한다.** 따라서 서버는 `NF 비트`를 전송해야 한다.
  - 즉, 서버가 파일을 분배하는 시간은 적어도 `NF/u(s)`이다.
- d(min)이 가장 낮은 다운로드 속도를 가진 피어의 다운로드 속도를 나타낸다고 하자.
  - 가장 낮은 속도를 가진 피어는 F/d(min)초보다 적은 시간에 파일의 모든 F 비트를 얻을 수 없다.
  - 즉 최소 분배 시간은 `F/d(min)`이다.
즉, 분배 시간을 D(cs)라고 하면 다음과 같은 수식을 얻을 수 있다.
위 식에서 충분히 큰 N에 대해 클라이언트-서버 분배 시간은 `NF/u(s)`로 주어진다는 사실을 알 수 있다. **즉, N에 따라 선형 증가한다.**
여기서는 각 피어들이 서버가 파일을 분배하는 데 도움을 줄 수 있다.
특히 한 피어가 파일 데이터 일부를 수신할 때, 피어는 그 데이터를 다른 피어들에게 재분배하는 데 자신의 업로드 용량을 이용할 수 있다.
분배가 시작되면 서버만이 파일을 갖고 있다.
이 파일이 피어 커뮤니티에 도달할 수 있도록 하기 위해, 서버는 적어도 한 번 접속 링크로 파일의 각 비트를 보내야 한다.
따라서 최소 분배 시간은 적어도 `F/u(s)`다.
(서버가 한 번 보낸 비트는 서버가 다시 보낼 필요가 없는데, 이는 **피어들이 그들 사이에서 재분배할 수 있기 때문이다.**)
클라이언트-서버 구조와 마찬가지로 다운로드 속도가 가장 낮은 피어는 F/d(min)초보다 적은 시간 안에 파일의 모든 F 비트를 얻을 수 없다.
따라서 최소 분배시간은 적어도 `F/d(min)`이다.
마지막으로, **시스템의 전체 업로드 용량**은 전체적으로 서버의 업로드 속도와 각 피어들의 속도를 더한 것이다. 이를 u(total)이라 하자.
시스템은 각 피어들 각각에게 F 비트를 전달해야 한다. 이는 u(total)보다 빠르게 할 수 없다.
따라서 최소 분배 시간은 `NF/u(total)`이다.
즉, 분배시간을 D(p2p)라고 하면 다음과 같은 수식을 얻을 수 있다.
위 수식들에서 하한값은 서버-클라이언트 구조에서 서버가 전송을 스케줄링 하거나,
P2P 구조에서는 각 피어가 비트를 수신하자마자 그 비트를 재분배할 수 있다고 가정하면(실제로는 chunk가 재분배된다.),
식의 하한값을 최소 분배시간으로 채택할 수 있다.
위 그래프를 통해 임의의 피어 수 N에 대해 클라이언트-서버 구조보다 P2P 구조가 더 시간이 적다는 것을 볼 수 있다.
따라서 P2P 구조를 가진 애플리케이션은 **자가 확장성**을 갖는다.
비트토렌트 용어로 **특정 파일의 분배에 참여하는 모든 피어의 모임**을 `토렌트(torrent)`라고 부른다.
토렌트에 참여하는 피어들은 **서로에게서 같은 크기의 `청크(chunk)`를 다운로드한다.** (일반적으로 256KB)
처음으로 가입하면 그 피어에는 청크가 없지만, 시간이 지나면 점점 많은 청크를 쌓을 수 있다.
피어가 청크를 다운로드할 때 또한 청크를 다른 피어들에게 업로드한다.
일단 한 피어가 전체 파일을 얻으면 토렌트를 떠나거나, 토렌트에 남아서 다른 피어들로 청크를 계속해서 업로드할 수 있다.
각 토렌트는 `트래커(traker)`라고 부르는 **인프라스트럭처 노드**를 갖고있다.
한 피어가 토렌트에 가입할 때 트래커에 자신을 등록하고 주기적으로 자신이 아직 토렌트에 있음을 알려, **트래커는 토렌트에 있는 피어들을 추적할 수 있다.**
위의 그림을 예시로 보자.
새로운 피어 앨리스가 토렌트에 가입하면
**트래커는 참여하고 있는 피어 집합에서 임의로 피어들의 부분집합(정확히는 50)을 선택하여 이 `50개 피어들의 IP 주소`를 앨리스에게 보낸다.**
이 피어들의 목록을 얻고 나서, 앨리스는 이 목록에 있는 모든 피어와 동시에 `TCP 연결`을 맺고,
성공적으로 맺은 피어를 `이웃 피어(neighbors)`라고 부른다.
> The peers fluctuate over time
`churn` : peers may come and go
시간이 지남에 따라 피어들 중 일부는 떠나고, 다른 피어들이 앨리스와 TCP 연결을 시도하고, 피어의 이웃 피어들은 시간에 따라 변동한다.
> requesting chunks: rarest first
어느 임의의 시간 안에 앨리스는 청크의 일부를 가질 것이고, 이웃들이 어느 청크를 가지고 있는지를 알게 될 것이다.
앨리스는 이러한 정보를 바탕으로 다음 2가지 결정을 한다.
1. 이웃으로부터 어느 청크를 먼저 요구할 것인가?
2. 이웃들 중 어느 피어에게 청크를 요청할 것인가?
이때 `rarest first(가장 드문 것 먼저)` 기술을 사용한다.
갖고 있지 않은 청크 중에서, **이웃 가운데 가장 드문 청크를 결정하고 이를 먼저 요구하는 것이다.**
이 방법을 통해 가장 드문 청크들은 더 빨리 재분배될 수 있어서 각 청크의 복사본 수가 대략적으로 동일해질 수 있다.
> sending chunks: tit-for-tat
어느 요청에 응답할지 결정할 때 앨리스가 **가장 빠른 속도로 그녀에게 데이터를 제공하는 이웃에게 우선순위를 주는 것이다.**
비트 토렌트 용어로 이 피어는 `낙관적으로 활성화되었다(optimistically unchoked)`고 한다.
- 즉, 이제 앨리스는 임의의 피어에게 활성화될 수 있고, 활성화가 된다면 임의의 피어도 앨리스에게 활성화될 수 있다.
- 임의의 선택을 통해 고정된 피어들과만 청크를 교역하는 것이 아니라 여러 피어와 교역할 수 있게 된다.
이러한 5개의 피어 외의 모든 이웃 피어는 비활성화되어 어떤 청크도 교역하지 않는다. (`choked` by Alice = do not receive chunks from her)
비트 토렌트는 여기서 논의하지 않은 여러 기법들도 갖고 있다.
비디오는 이미지의 연속으로서 일반적으로 초당 24개에서 30개의 이미지로 일정한 속도로 표시된다.
압축되지 않은 디지털 인코딩된 이미지는 픽셀 단위로 구성되며, 각 픽셀은 휘도와 색상을 나타내는 여러 비트들로 인코딩된다.
비디오의 중요한 특징은 압축될 수 있다는 것인데, 비디오 품질과 비트 전송률은 서로 반비례한다.
오늘날의 상용 압축 알고리즘은 근본적으로 원하는 모든 비트 전송률로 비디오를 압축할 수 있다. (비트 전송률이 높을수록 이미지 품질이 좋다.)
네트워킹 측면에서 비디오의 가장 두드러진 특성은 높은 비트 전송률이다.
인터넷 비디오는 일반적으로 고화질 동영상을 스트리밍 하기 위해 100 kbps에서 4 Mbps 이상으로 구성된다.
4K 스트리밍은 10 Mbps 이상의 비트 전송률로 예상된다. 이는 하이엔드 동영상의 경우 트래픽과 스토리지 용량이 엄청나게 필요함을 의미한다.
연속 재생을 제공하기 위해, 네트워크는 압축된 비디오의 전송률 이상의 스트리밍 애플리케이션에 대한 평균 처리량을 제공해야 한다.
→ 압축을 사용하여 동일한 비디오를 여러 버전의 품질로 만들 수 있다.
1. 클라이언트는 서버에게 TCP 연결을 설립하고 해당 URL에 대한 HTTP GET 요청을 발생시킨다.
2. 서버는 기본 네트워크 프로토콜 및 트래픽이 허용되는 대로 HTTP 응답 메시지 내에서 비디오 파일을 전송한다.
3. 애플리케이션 버퍼에 전송된 바이트가 저장된다.
4. 버퍼의 바이트 수가 미리 정해진 임계값을 초과하면 재생을 시작한다.
특히, 버퍼에서 주기적으로 비디오 프레임을 가져와 프레임을 압축 해제한 다음 사용자의 화면에 표시한다.
가용 대역폭이 달라도 똑같이 인코딩된 비디오를 전송 받는다는 문제가 있다.
이 문제로 인한 HTTP 기반 스트리밍인 `DASH(Dynamic Adaptive Streaming over HTTP)`가 개발되었다.
> 비디오는 여러가지 버전으로 인코딩 되며, 각 버전은 비트율과 품질 수준이 서로 다르다.
클라이언트는 동적으로 서로 다른 버전의 비디오를 몇 초 분량의 길이를 갖는 비디오 조각 단위로 요청한다.
가용 대역폭이 충분할 때는 높은 비트율의 비디오 버전을 요청하며, 가용 대역폭이 적을 때는 낮은 비트율의 비디오 버전을 요청한다.
즉, 클라이언트는 자신의 상황에 알맞은 비디오 버전을 요청한다.
각 비디오 버전은 HTTP 서버에 서로 다른 URL을 가지고 저장된다.
HTTP 서버는 비트율에 따른 각 버전의 URL을 제공하는 `매니페스트(manifest) 파일`을 갖고 있다.
클라이언트는 이 매니페스트 파일을 제공받고,
> 단일 거대 데이터 센터를 구축하고 모든 비디오 자료를 데이터 센터에 저장한 뒤, 전 세계의 사용자에게 비디오 스트림을 데이터 센터로부터 직접 전송한다.
1. 클라이언트가 데이터 센터로부터 먼 지점에 있는 경우 다양한 통신 링크와 ISP를 거치게 되고,
   이 링크들 중 하나라도 비디오 소비율 보다 낮은 전송 용량을 갖는 경우 병목현상이 발생한다.
2. 인기 있는 비디오는 같은 통신 링크를 통해 여러 번 반복적으로 전송될 것이다. 동일한 바이트를 전송하는 데에 반복 비용을 지불하게 된다.
3. 한 번의 장애로 전체 서비스가 중단될 수 있다.
이러한 문제를 해결하기 위해 대부분의 비디오 스트리밍 회사들은 `콘텐츠 분배 네트워크(CDN)`를 이용한다.
사용자는 최적의 사용자 경험을 제공받을 수 있는 지점의 CDN 서버로 연결된다.
CDN은 구글처럼 사설 CDN일 수도 있으며, 제 3자가 운영하는 CDN을 통해 서비스될 수도 있다.
두 개의 철학 중 하나를 채용한다.
- Enter Deep
- Bring Home
> push CDN servers deep into many access networks
Akamai에 의해 주창된 것으로서 서버 클러스터를 세계 곳곳의 접속 네트워크에 구축함으로써 ISP의 접속 네트워크로 깊숙이 들어가는 것이다.
즉, 최대한 서버를 사용자 근처에 위치시켜 링크 및 라우터를 거치는 횟수를 줄여 지연시간 및 처리율을 개선하는 것이다.
> smaller number (10’s) of larger clusters in POPs near (but not within) access networks
Limelight와 다른 회사들에 의해 적용된 것으로, 좀 더 적은 수의 핵심 지점에 큰 규모의 서버 클러스터를 구축하여 ISP를 Home으로 가져오는 개념이다.
접속 ISP에 연결하는 대신, 일반적으로 CDN들은 그들의 클러스터를 `인터넷 교환 지점(IXP)`에 배치한다.
이에 따라 Enter Deep보다 처리율(throughput)은 더 낮고 delay가 더 걸릴 수 있지만, 회사의 입장에서는 유지 보수하기에 편하며, 비용이 적게 든다.
CDN은 콘텐츠의 복사본을 이들 클러스터에 저장하는데 모든 복사본을 유지하지는 않는다.
어떤 비디오는 인기가 거의 없거나 특정 국가에서만 인기가 있을 수 있기 때문이다.
실제로 CDN은 클러스터에 대해 사용자의 요청이 오면 중앙 서버나 다른 클러스터로부터 전송받아 사용자에게 서비스하는 동시에 복사본을 만들어 저장하는 `pull 방식`을 이용한다.
저장 공간이 가득 차게 되면 자주 사용되지 않는 비디오 데이터는 삭제된다.
1. 사용자가 URL을 지정하여 비디오를 요청한다.
2. CDN은 그 요청을 가로채 클라이언트에게 가장 적당한 CDN 클러스터를 선택한다.
3. 클라이언트의 요청을 해당 클러스터의 서버로 연결한다.
요청을 가로챌 때 CDN은 DNS를 활용한다. 이를 `DNS redirection`이라고 한다.
1. 사용자가 URL을 입력한다.
2. 사용자의 호스트는 URL의 host name에 대한 질의를 로컬 DNS로 보낸다.
3. 로컬 DNS는 host name의 책임 DNS 서버로 질의를 전달한다.
   책임 DNS 서버는 해당 질의를 CDN 서버로 연결하기 위해 CDN 서버의 책임 DNS 서버의 IP를 전달한다.
4. 로컬 DNS는 CDN 서버의 책임 DNS로 질의를 보내고, CDN 콘텐츠 서버의 IP 주소를 로컬 DNS 서버로 응답한다.
   이때 클라이언트가 콘텐츠를 전송받게 될 서버가 결정된다.
5. 로컬 DNS 서버는 사용자 호스트에게 CDN 서버의 IP 주소를 알려준다.
6. 클라이언트는 호스트가 알게된 IP 주소로 HTTP 혹은 DASH 프로토콜을 통해 비디오를 받아온다.

위 CDN이 DNS를 통해 가로채는 과정에서 CDN은 클라이언트의 로컬 DNS 서버의 IP 주소를 알게된다. 이 IP 주소에 기초해 최선의 클러스터를 선택한다.


> 지리적으로 가장 가까운 클러스터를 할당한다.

사용자 지리정보 데이터베이스를 이용하면 얻은 IP 주소를 지리적으로 매핑할 수 있고, 가장 가까운 클러스터를 선택하는 것이다.

대부분 잘 동작하나, 지리적으로 가까운 클러스터가 네트워크 경로의 길이 홉의 수에 따라 가장 가까운 클러스터가 아닐 수 있고,
가까운 로컬 DNS 서버를 이용하고 있지 않을 수 있기 때문에 잘 동작하지 않을 수 있다.

> 실시간 측정

클러스터와 클라이언트 간의 **지연 및 손실 성능에 대한 주기적인 실시간 측정**을 통해 현재 네트워크 상황을 반영하여 최선의 클러스터를 선택하는 것이다.

문제는 많은 로컬 DNS 서버가 이러한 측정에 응답을 하지 않도록 설정되어 있다.



- 콘텐츠 수집 : 영화를 수집하고 처리한다. 영화의 스튜디오 마스터 버전을 받아서 아마존 클라우드 시스템의 호스트에 업로드한다.
- 콘텐츠 처리 : 아마존 클라우드 시스템의 기기에서는 데스크톱 컴퓨터, 스마트폰, TV에 견결된 게임 콘솔 등 고객들의 다양한 플레이어 기기 사양에 적합하도록 각 영화의 여러가지 형식의 비디오를 생성한다.
  DASH를 이용하여 각 형식별로 다양한 비트율의 여러가지 버전을 생성한다.
- CDN으로 버전 업로드 : 영화의 다양한 버전이 생성되면 아마존 클라우드 시스템의 호스트는 이러한 버전을 CDN으로 업로드할 수 있다.

자체 CDN을 구축하기 위해 넷플릭스는 IXP 및 거주용 ISP 자체에서 서버 랙(rack)을 설치했다.

현재 IXP 위치에 200대 이상의 서버 렉과 서버 랙을 수용하는 수백 개의 ISP 장소도 보유하고 있다.

각각의 랙 서버에는 10 Gbps 이더넷 포트와 100 테라바이트 이상의 스토리지가 있다.

넷플릭스는 `푸시 캐싱(push caching)`을 사용하여 IXP 및 ISP CDN 서버를 채운다.

전체 라이브러리를 보유할 수 없는 위치의 경우, 매일매일 가장 많이 결정되는 비디오만 푸시한다.

1. 사용자가 재생할 영화를 선택한다.
2. 아마존 클라우드에서 실행 중인 넷플릭스 소프트웨어가 영화 사본을 갖고 있는 CDN 서버를 결정한다.
3. 영화가 있는 서버 중에서 클라이언트 요청에 대한 최적의 서버를 결정한다.
4. 일반적으로 로컬 ISP가 CDN 서버 랙(rack)이 있다면 해당 CDN을 사용하거나, 근처 CDN 서버가 있는 IXP를 사용한다.
5. 클라이언트는 요청된 영화의 다른 버전에 대한 URL을 가진 메니페스트 파일과 특정 서버의 IP 주소를 보낸다.
6. 클라이언트와 해당 CDN 서버는 독점 버전의 DASH를 이용하여 직접 상호작용한다.
넷플릭스는 자체 CDN을 사용하고 있기 때문에 `DNS redirection`을 사용할 필요가 없다.
대신 아마존 클라우드에서 실행되는 것처럼 넷플릭스 소프트웨어는 클라이언트에게 특정 CDN 서버를 사용하도록 알려준다.
또한 넷플릭스 CDN은 `풀 캐싱`보다 `푸시 캐싱`을 사용한다.
콘텐츠는 캐시 미스 중에 동적으로 사용되는 것이 아니라 사용량이 적은 시간 중 예약된 시간에 서버에 푸시한다.
넷플릭스와 마찬가지로 자체 CDN을 사용한다.
구글 역시 사용자를 특정 서버 클러스터와 연결하는 데 DNS를 사용한다.
대부분의 경우 클러스터 선택 정책은 클라이언트와 클러스터간의 RTT가 가장 적은 곳을 선택하는 것이다.
때로는 작업 부하를 위해 더 멀리 있는 CDN을 선택하기도 한다.
유튜브는 HTTP 스트리밍을 채용하여 사용자가 직접 버전을 선택하게 했다.
재생 위치 조정과 조기 종료로 인한 대역폭과 서버 자원의 낭비를 줄이기 위해,
유튜브는 HTTP byte-range 헤더를 이용해 목표한 분량의 선인출 데이터 이후에 추가로 전송되는 데이터 흐름을 제한한다.
위 그림은 UDP 서비스 상에서 통신하는 클라이언트와 서버의 주요 소켓 관련 활동을 나타낸다.
1. 클라이언트는 키보드로부터 한 줄의 문자를 읽고 그 데이터를 서버로 보낸다.
2. 서버는 그 데이터를 수신하고 문자를 대문자로 변환한다.
3. 서버는 수정된 데이터를 클라이언트에게 보낸다.
4. 클라이언트는 수정된 데이터를 수신하고 그 줄을 화면에 나타낸다.
위 순서로 작동하는 간단한 클라이언트-서버 애플리케이션을 만들 예정이다.
`TCP`는 **연결 지향 프로토콜**로, 서로 데이터를 보내기 전에 먼저 TCP 연결을 설정할 필요가 있다.
TCP 연결을 생성할 때 클라이언트 소켓 주소와 서버 소켓 주소를 연결과 연관시킨다.
연결이 설정된 후 소켓을 통해 데이터를 TCP 연결로 보내면 된다.
서버 프로세스가 실행되면 클라이언트 프로세스는 서버로의 TCP 연결을 시도하는데, 이는 **클라이언트 프로그램에서 TCP 소켓을 생성**함으로써 가능하다.
소켓을 생성한 후 클라이언트는 3-way handshake를 하고 서버와 TCP 연결을 설정한다. (핸드셰이킹은 프로그램에서 전혀 인지 못한다.)
핸드셰이킹 동안 서버는 **해당 클라이언트에게 지정되는 새로운 소켓**을 생성한다. 이를 `연결 소켓`이라고 한다.
애플리케이션 관점에서 볼 때 클라이언트의 소켓과 서버의 연결 소켓은 파이프에 의해 직접 연결된다.
파이프를 통해 클라이언트는 자신의 소켓으로 임의의 바이트를 보낼 수 있으며, 서버 프로세스가 그것을 수신하는 것을 TCP가 보장한다. 이는 서버 입장에서도 마찬가지이다.
위 그림은 전형적인 클라이언트-서버 TCP 연결 구조이다.
UDP 프로그램과 똑같은 기능을 하는 프로그램을 작성해보자.
두 호스트 H1과 H2가 있을 때, 네트워크 계층은 두 호스트 중 하나의 트랜스포트 계층 세그먼트를 추출하여 H2의 트랜스포트 계층까지 전달하는 역할을 한다.
라우터는 트랜스포트 계층과 애플리케이션 계층을 지원하지 않으므로 프로토콜 스택에서 네트워크 계층의 상위 계층은 존재하지 않는다.
각 라우터에는 데이터 평면과 제어 평면이 존재한다.
- `데이터 평면` : 입력 링크에서 출력 링크로 데이터그램을 전달한다.
- `제어 평면` : 데이터그램이 출발지 호스트에서 목적지 호스트까지 전달되게끔 로컬 포워딩, 라우터별 포워딩을 대응시킨다.
> 💡 네트워크 계층의 근본적인 역할은 송신 호스트에서 수신 호스트로 패킷을 전달하는 것이다.
위 역할을 위한 중요한 기능 두 가지
- `포워딩(전달)` : 패킷이 라우터의 입력 링크에 도달했을 때 라우터는 그 패킷을 적절한 출력 링크로 이동시켜야한다. 포워딩에서 예외적으로 한 기능은 데이터 평면에서 실행된다. 매우 짧은 시간 단위(보통 몇 나노초)를 갖기에 대표적으로 하드웨어에서 실행된다.
- `라우팅` : 송신자가 수신자에게 패킷을 전송할 때 네트워크 계층은 패킷 경로를 결정해야 한다. 이러한 경로를 계산하는 알고리즘을 `라우팅 알고리즘`이라고 한다. 네트워크 전반에 걸쳐 출발지에서 목적지까지 데이터그램의 종단 간 경로를 결정하여 시간이 오래걸려 소프트웨어에서 실행된다.
라우터는 도착하는 **패킷 헤더의 필드값**을 통해 **`포워딩 테이블`의 내부 색인으로 사용하여 패킷을 전달**한다.
포워딩 테이블 엔트리에 **저장되어 있는 헤더의 값은 해당 패킷이 전달되어야 할 라우터의 외부 링크 인터페이스**를 나타낸다.
라우팅 알고리즘은 각각의 모든 라우터에서 실행되며, 라우터는 포워딩과 라우팅 기능을 모두 갖고 있어야 한다.
또한, 한 라우터의 라우팅 알고리즘 기능은 다른 라우터의 라우팅 알고리즘과 소통하며 포워딩 테이블의 값을 계산한다.
이러한 소통은 라우팅 프로토콜에 따라 라우팅 정보에 포함된 라우팅 메시지를 교환하며 이루어진다.
라우터는 원격 컨트롤러와 포워딩 테이블과 그 밖의 라우팅 정보를 포함한 메시지를 교환함으로써 소통한다.
**원격 컨트롤러가 포워딩 테이블을 계산 및 배분하는 동안 라우팅 기기는 포워딩만을 수행**한다.
즉, 네트워크가 **소프트웨어적으로 정의되었을 때** `포워딩 테이블`을 계산하는 **컨트롤러는 라우터와 상호작용을 하며 소프트웨어에서 실행**된다.
이렇게 원격 컨트롤러가 라우터와 떨어져서 높은 신뢰성과 중복성을 갖춘 원격 데이터 센터에 위치하는 접근 방법은 `SDN(software defined networking)`의 중심이다.
4장에서는 네트워크 계층 데이터 평면의 구성요소를 살펴본다.
입력 포트의 기능은 위에서 언급한 바와 같다.
입력 포트에서 수행되는 검색은 라우터 동작의 핵심이다.
라우터는 포워딩 테이블을 사용하여 도착 패킷이 스위치 구조를 통해 전달되는 출력 포트를 검색한다.
포워딩 테이블은 라우팅 프로세서에서 계산되거나 갱신되거나 원격 SDN 컨트롤러에서 수신된다.
포워딩 테이블은 라우팅 프로세서에서 맨위 그림과 같이 각 라인 카드로 복사되고, 이렇게 각 라인이 복사본을 사용하여 패킷 단위로 중앙 집중식 라우팅 프로세서를 호출하지 않게 되어 병목 현상을 피할 수 있다.
32비트의 IP 주소의 경우 포워딩 테이블을 억지로 구현한다면 모든 가능한 목적지 주소마다 하나의 엔트리가 필요하고, 이는 40억개 이상의 주소가 있어야 하므로 불가능하다.
라우터에서 0에서 3까지의 4개의 링크가 있다고 가정해보자.
목적지 주소 범위로 포워딩 테이블을 구성할 경우 4개의 엔트리를 갖는 포워딩 테이블이면 된다.
이런 형식의 포워딩 테이블에서 라우터는 패킷의 목적지 주소의 `프리픽스(prefix)`를 테이블의 엔트리와 매치한다.
예를 들어, 패킷의 목적지 주소가 `11001000 00010111 00010110 10100001` 라면 앞 21개의 비트 프리픽스가 테이블의 첫 번째 엔트리와 매치되므로 라우터는 이 패킷을 링크 인터페이스 0으로 보낸다.
`11001000 00010111 00011000 10101010`와 같이 처음 24비트는 2번째에 처음 21비트는 3번째에 매치되는 경우 라우터는 `최장 프리픽스 매치 규칙(longest prefix matching rule)`을 사용한다.
즉, 테이블에서 가장 긴 매치 엔트리를 찾고, 여기에 연관된 링크 인터페이스로 패킷을 보낸다. (이유에 대해서는 4.3절에서 다룬다.)
이러한 테이블 설계 뿐만 아니라 검색은 나노초 단위로 수행되어야 하므로 이외의 기술이 필요하다.
메모리 접속 시간에 특별한 주의를 기울여야하므로 내장형 DRAM과 빠른 SRAM 메모리가 있는 설계가 필요하다. 실제로 TCAM도 검색을 위해 자주 사용된다.
검색을 통해 패킷의 출력 포트가 결정되면 패킷을 스위치 구조로 보낼 수 있다. 일부 설계에서는 다른 입력 포트로부터 패킷이 현재 구조를 사용하고 있다면 패킷이 스위칭 구조에 들어가는 것을 일시적으로 차단할 수 있다.
앞으로 패킷의 차단, 큐잉, 스케줄링에 대해 자세히 살펴본다.
스위치 구조는 패킷이 입력 포트에서 출력 포트로 실제로 스위칭 되는 구조를 통과하므로 라우터의 핵심이다.
여기서는 여러가지 스위칭 방법을 설명한다.
초기의 라우터는 라우터 프로세서를 직접 제어해서 입력 포트와 출력 포트 사이에서 패킷을 스위칭하는 전통적인 컴퓨터다. 입력 포트와 출력 포트는 I/O 장치처럼 작동한다.
패킷 전달 과정
1. 패킷이 도착하면 입력 포트는 라우팅 프로세서에게 인터럽트를 보내 패킷을 프로세서 메모리에 복사한다.
2. 라우팅 프로세서는 헤더에서 목적지 주소를 추출한다.
3. 포워딩 테이블에서 적절한 출력 포트를 찾은 다음 패킷을 출력 포트의 버퍼에 복사한다.
위 과정에서 메모리 대역폭이 초당 최대 B인 패킷을 메모리에 쓰거나 메모리에서 읽을 수 있는 경우 전체 전달 처리량은 B/2 보다 작아야하며 목적지 포트가 다른 경우라도 공유 시스템 버스를 통해 한 번에 하나의 메모리 읽기/쓰기 작업을 수행할 수 있기 때문에 두 패킷을 동시에 전달할 수 없다.
최근의 메모리를 통해 스위칭하는 라우터는 목적지 주소를 검색하고 해당 메모리 위치에 패킷을 저장하는 것이 입력 라인 카드에서 처리함으로써 수행한다.
입력 포트는 라우팅 프로세서의 개입 없이 공유 버스를 통해 직접 출력 포트로 패킷을 전송한다.
일반적으로 미리 준비된 입력 포트 스위치 내부 레이블이 로컬 출력 포트를 나타내는 패킷에게 전송되거나 버스에 패킷을 전송하여 수행된다.
모든 출력 포트에 패킷이 수신되지만 레이블과 매치되는 포트만 패킷을 유지한다.
레이블은 버스를 통과하기 위해서만 사용되므로 출력 포트에서 제거된다.
동시에 여러 패킷이 다른 입력 포트에 있는 라우터에 도착하면 한 번에 하나의 패킷만 버스를 통과할 수 있기 때문에 하나를 제외한 모든 패킷이 대기 해야한다.
모든 패킷이 하나의 버스를 통과해야하므로 라우터의 교환 속도는 버스 속도에 의해 제한된다.
크로스바 스위치는 N개의 입력 포트를 N개의 출력 포트에 연결하는 2N 버스로 구성된 상호연결 네트워크다.
각 수직 버스는 교차점에서 각 수평 버스와 교차하며 스위치 구조 컨트롤러에 의해 언제든지 열거나 닫을 수 있다.
이를 통해 앞의 두가지 방식과 달리 크로스바 스위치는 여러 패킷을 병렬로 전달할 수 있다.
그러나 두개의 서로 다른 입력 포트에서 나오는 2개의 패킷이 동일한 출력 포트로 보내지는 경우 한번에 하나의 패킷만 특정 버스에서 전송될 수 있기 때문에 입력을 기다려야한다.
좀 더 정교한 상호연결 네트워크는 다단계 스위치 구조를 통해 각기 다른 입력 포트의 패킷이 동일한 출력 포트를 향해 동시에 전달할 수 있도록 여러 단계의 스위칭 요소를 사용한다.
위 그림의 출력 포트 처리는 출력 포트의 메모리에 저장된 패킷을 가져와서 출력 링크를 통해 전송한다. 여기에는 전송을 위한 패킷 선택 및 큐 제거, 필요한 링크 계층 및 물리 계층 전송 기능을 수행하는 것이 포함된다.
패킷 큐는 입력 포트와 출력 포트 모두에서 형성될 수 있다.
큐의 위치와 범위는 트래픽 로드, 스위치 구조의 상대 속도 및 라인 속도에 따라서 달라진다.
이 큐가 커지면 라우터의 메모리가 결국 소모될 수 있고 도착하는 패킷을 저장할 수 있는 메모리가 없을 때 패킷 손실이 발생한다.
지연 없이 구조를 통해 도착하는 모든 패킷을 전송하기에 스위치 구조가 충분히 빠르지 않으면 어떻게 될까?
이 경우에는 패킷이 스위치 구조를 통해 출력 포트로 전송되기 위해 차례를 기다려야한다.
이 큐잉의 결과를 살펴보기 위해 크로스바 스위치 구조를 가정해보자.
1. 모든 링크의 속도는 같다.
2. 입력 링크가 패킷을 받는 것과 같은 속도로 하나의 패킷을 입력 포트에서 주어진 출력 포트로 전달한다.
3. FCFS (First-Come-First-Served) 방식으로 패킷은 입력 큐에서 출력 큐로 이동된다.
출력 포트가 다르다면 여러 패킷이 병렬로 전달 가능하지만, 같다면 하나의 패킷만 지정된 출력 포트로 전송이 가능하고 나머지 패킷은 기다려야한다.
위 그림에서 왼쪽 상단 큐의 앞쪽에서 먼저 패킷을 전송한다고 가정해보자.
왼족 하단 큐의 가장 앞쪽의 패킷은 출력 포트가 같으므로 대기하여야하고, 두번째 패킷은 출력 포트가 다름에도 앞의 패킷 때문에 대기하여야한다.
이 현상은 입력 대기 중인 스위치에서의 `HOL(Head-of-the-line) 차단` 이라고 한다.
입력 포트와 출력 포트의 개수가 각각 N개이고 속도가 R이라 할 때, 스위치의 속도가 R보다 N배 빠르고 모든 입력 포트의 패킷이 동일한 출력 포트로 향한다고 가정해보자.
이 경우, 출력 링크에서 단일 패킷을 보내는 데 걸리는 시간에 N개의 새로운 패킷이 출력 포트에 도착한다. 출력 포트는 **시간 단위에 단일 패킷만을 전송할 수 있기 때문에 N개의 도착 패킷은 출력 링크를 통한 전송 큐에서 대기** 해야한다.
이때 큐의 공간이 충분하지 않을 때, 즉 **메모리가 충분하지 않을 때 도착한 패킷을 삭제하거나 이미 대기 중인 하나 이상의 패킷을 제거하여 새로 도착한 패킷을 저장하기 위한 공간을 확보**해야 한다.
위 그림은 출력 포트 큐잉의 예시이다.
이러한 큐잉의 결과는 출력 포트의 `패킷 스케줄러`가 전송 대기 중인 패킷 중 하나의 패킷을 선택하여 큐에서 제거 해야한다는 것이다. (다음 절에서 다룬다.)
링크가 현재 다른 패킷을 전송 중이면, 출력 링크 큐에 도착한 패킷은 전송을 기다린다.
도착한 패킷을 담을 버퍼 공간이 충분하지 않은 경우 도착 패킷의 공간을 확보하기 위해 큐의 패킷 폐기 정책은 패킷 손실 여부 또는 다른 패킷을 큐에서 제거할 것인지 여부를 결정한다.
FIFO 스케줄링 규칙은 출력 링크 큐에 도착한 순서와 동일한 순서로 출력 링크에서 전송할 패킷을 선택한다.
위 그림에서는 FIFO 큐의 동작을 보여준다.
우선순위 큐잉에서 출력 링크에 도착한 패킷은 우선순위 클래스로 분류된다.
실제로 네트워크 오퍼레이터는 네트워크 관리 정보를 운반하는 패킷이 사용자 트래픽보다 우선순위를 수신하도록 큐를 구성할 수 있다.
전송할 패킷을 선택할 때 전송 대기 중인 패킷으로 차 있는 상태이고 가장 높은 우선순위 클래스에서 패킷을 전송한다.
우선순위가 동일한 패킷들 중에서의 선택은 FIFO 방식으로 행해진다.
위 그림은 우선순위 클래스가 2개인 경우의 큐 동작을 보여준다.
패킷 1,3,4가 우선순위가 높기 때문에 먼저 전송된다.
이때는 `비선점 우선순위 큐잉`이기 때문에 패킷 4의 우선순위가 높더라도 패킷 2의 전송이 시작되면 선점하지 않고 전송이 끝난 후에야 전송이 시작된다.
즉, 클래스에 패킷이 없다면 바로 시퀀스의 다음 클래스를 검사한다.
위 그림은 라운드 로빈 큐의 동작을 보여준다.
라우터에서 널리 구현된 라운드 로빈 큐잉의 일반화된 형태는 소위 `WFQ(Weighted Fair Queueing) 규칙`이다.
도착하는 패킷은 적절한 클래스별 대기 영역에서 분류되며 대기한다.
WFQ 스케줄러는 **라운드 로빈과 같이 순환식**으로 동작한다.
또한, **작업 보존 큐잉 규칙**을 따른다.
WFQ는 각 클래스 i 는 가중치 w(i)를 할당 받는다.
WFQ에서는 전송할 클래스 i 패킷이 있는 동안에 클래스 i는 `w(i) / ∑w(i)` 만큼의 서비스 시간을 보장받으며, 이 식에서 분모 부분은 전송을 위해 큐에 패킷이 있는 모든 클래스의 합이다.
즉, 최악의 경우 모든 큐에 패킷이 있을 때도 위의 시간을 보장 받는다.
따라서 전송률 R인 링크에 대해 클래스 i는 항상 최소한 `R x w(i) / ∑w(i)`의 처리율을 갖는다.
패킷이 이상적인 단위 데이터라는 것과 패킷 전송이 다른 패킷을 전송하기 위해 방해되지 않는다는 사실을 고려하지 않았기 때문에 위 설명은 이상적이다.
인터넷 네트워크 계층 패킷을 데이터그램(datagram)이라고 부른다.
 4비트로 데이터그램의 IP 프로토콜 버전을 명시한다.
라우터는 버전 번호를 확인하여 데이터그램의 나머지 부분을 어떻게 해석할지 결정한다.
다른 버전의 IP는 다른 데이터그램 포맷을 사용한다.
IPv4 데이터그램은 헤더에 가변 길이의 옵션을 포함하므로 이 네 비트로 IP 데이터그램에서 실제 페이로드가 시작하는 곳을 결정한다.
대부분의 IPv4는 옵션을 포함하지 않으므로 대체로 IPv4 데이터그램 헤더는 20바이트다.
데이터그램이 존재하는 이유이자 가장 중요한 마지막 필드이다. 대부분의 경우 목적지에 전달하기 위해 트랜스포트 계층 세그먼트를 포함한다.
대부분의 IP 데이터그램은 총 20바이트(옵션은 없다고 가정)의 헤더를 갖는다.
TCP 세그먼트를 전송한다면 단편화가 되지 않은 각 데이터그램은 애플리케이션 계층의 메시지와 더불어 총 40바이트의 헤더(IP 헤더 20, TCP 헤더 20)을 전송한다.
호스트는 일반적으로 네트워크와 연결되는 하나의 링크를 갖는다.
호스트 IP가 데이터그램을 보낼 때 이 링크를 통해 데이터링크를 보낸다.
호스트와 물리적 링크 사이의 경계를 `인터페이스(interface)`라고 부른다.
라우터는 여러 개의 링크와 연결되고, 링크와 라우터 사이도 `인터페이스(interface)`로 이루어져있어 여러개의 `인터페이스(interface)`를 갖는다.
모든 호스트와 라우터는 IP 데이터그램을 송수신할 수 있으므로 IP는 각 호스트와 라우터 인터페이스가 IP 주소를 갖도록 요구한다.
이러한 각 인터페이스는 고유한 IP 주소를 갖는다.
따라서 **기술 면에서 IP 주소는 `인터페이스(interface)`를 포함하는 호스트 라우터보다는 `인터페이스(interface)`와 관련이 있다.**
IP의 또 다른 형태인 브로드캐스트 주소 255.255.255.255가 있다.
호스트가 목적지 주소가 255.255.255.255인 데이터그램을 보내면, 이 메시지는 같은 서브넷에 있는 모든 호스트에게 전달된다.
다음으로는 한 기관에서 그들의 장비를 위한 주소 블록을 어떻게 획득하는지 알아본 후에, 이 획득한 주소 블록의 주소를 어떻게 장비에 할당하는지 살펴보겠다.
본질적으로 NAT 가능 라우터는 외부에서 들어오는 홈 네트워크의 상세한 사항을 숨긴다.
WAN에서 같은 목적지 IP 주소를 갖는 NAT 라우터에 모든 데이터 그램이 도착하면, 라우터가 주어진 데이터그램을 전달하는 내부 호스트를 어떻게 알 수 있을까?
NAT 라우터에서 `NAT 변환 테이블`을 사용하고, 그 테이블에 IP 주소와 포트 번호를 포함하여 알 수 있다.
위 그림의 **NAT 변환 테이블**을 보며 순서대로 잘 따라가보길 바란다.
웹 서버는 내부 호스트를 모른채 WAN side의 라우터를 목적지 IP로 하여 응답하고, 라우터는 이 응답을 NAT 변환 테이블을 사용하여 알맞은 내부 호스트에 전달한다.
포트 번호는 호스트 주소 지정이 아닌 프로세스 주소 지정에 사용된다.
서버 프로세스는 잘 알려진 포트 번호에서 요청이 올 때까지 기다리고 P2P 프로토콜의 피어는 서버로서의 역할을 할 때 들어오는 연결을 수락해야 하기 때문에 홈 네트워크에서 실행되는 서버에 문제가 발생할 수 있다.
이 문제의 기술적인 해결책으로는 NAT 순회 도구가 있다.
IPv4 주소 공간이 빠르게 고갈되어가면서 IPv6 주소 체계가 개발되었다.
IPv6 중요한 변화
- 확장된 주소 기능
  - IPv6는 유니캐스트, 멀티캐스트 주소뿐만 아니라 새로운 주소 형태인 애니캐스트 주소가 도입되었다. 애니 캐스트 주소로 명시된 데이터그램은 호스트 그룸의 어떤 이에게든 전달될 수 있다.
- 간소화된 40 바이트 헤더
  - 40 바이트 고정 길이 헤더는 라우터가 IP 데이터그램을 더 빨리 처리하게 해준다.
  - 새로운 옵션 인코딩은 유연한 옵션 처리를 가능하게 한다.
- 흐름 레이블링
  - 정의하기 어려운 흐름을 갖고있다. RFC는 "비 디폴트 품질 서비스나 실시간 서비스 같은 특별한 처리를 요청하는 송신자에 대해 특정 흐름에 속하는 패킷 레이블링"을 가능하게 한다고 설명한다. 아직 정확한
    의미는 정의되지 않았지만, 언젠가 필요할 흐름 차별화를 예견하여 구현하였다.
IPv6 데이터그램 포맷은 그림과 같다.
- `버전`
  - 4비트 필드는 IP 버전 번호를 인식한다. IPv6라면 6이다.
- `트래픽 클래스`
  - IPv4의 TOS 필드와 비슷한 의미로 만든 8비트 필드는 흐름 내의 SMTP 이메일 같은 애플리케이션의 데이터그램보다 Volp 같은 특정 애플리케이션 데이터그램에 우선순위를 부여하는데 사용된다.
- `흐름 레이블`
  - 데이터그램의 흐름을 인식하는데 사용된다.
- `페이로드 길이`
  - 이 16비트 값은 IPv6 데이터그램에서 고정 길이 40바이트 패킷 헤더 뒤에 나오는 바이트 길이이며, 부호 없는 정수다.
- `다음 헤더`
  - 이 필드는 데이터그램의 내용이 전달될 프로토콜을 구분한다.(TCP, UDP)
- `홉 제한`
  - 라우터가 데이터그램을 전달할 때 마다 1씩 감소하고, 0이되면 데이터그램이 라우터에 의해 버려진다.
- `출발지와 목적지 주소`
  - 출발지와 목적지 주소를 담고 있다.
- `데이터`
  - IPv6 데이터그램의 페이로드 부분이다. 데이터그램이 목적지에 도착하면 IP 데이터그램에서 페이로드를 제거한 후, 다음 헤더 필드에 명시한 프로토콜에 전달한다.
IPv4에는 있지만 IPv6에는 없는 필드
  - IPv6에서는 단편화와 재결합을 출발지와 목적지만이 수행한다.
  - 라우터가 받은 IPv6 데이터그램이 너무 커서 출력 링크로 전달할 수 없다면 라우터는 데이터그램을 폐기하고 너무 크다는 ICMP 오류 메시지를 송신자에게 보낸다.
  - 송신자는 데이터를 IP 데이터그램 크기를 줄여서 다시 보낸다.
  - 라우터에서 이 기능을 수행하는 것은 시간이 오래 걸리므로 이 기능을 삭제하여 IP 전달 속도를 증가시켰다.
- `헤더 체크섬`
  - 트랜스포트 계층 프로토콜과 데이터 링크 프로토콜은 체크섬을 수행하므로 IP 설계자는 네트워크 계층의 체크섬 기능이 반복되는 것으로 생략해도 될 것이라 생각하여 삭제했다.
- `옵션`
  - IPv4에서도 잘 사용되지 않았던 필드가 사라지고 고정 헤더의 길이를 갖게되었다.
  - 다대신 옵션 필드는 IPv6 헤더에서 다음 헤더 중 하나가 될 수 있다.
IPv6는 IPv4 데이터그램을 보내고 라우팅하며 받을 수 있는 새 IPv6 시스템이 있는 반면에, IPv4로 구축된 시스템은 IPv6 데이터그램을 처리할 수 없다는 것에서 발생한다.
모든 인터넷 장비를 끄고 IPv4를 IPv6로 업그레이드하는 시간과 날짜를 정하는 것으로 40년 전에 실제로 NCP를 TCP로 전이하였다.
그러나 수억개의 장비가 관련된 플레그 데이는 오늘날에는 절대 불가능하다.
실제로 널리 사용하는 방법이다.
두 IPv6 노드(그림에서는 B와 E)가 IPv6 데이터그램을 사용해서 작동한다고 가정해보자.
물론 이들은 IPv4 라우터를 통해 연결되어있다. 이렇게 IPv6 노드 사이에 연결되어있는 IPv4 라우터들을 `터널(tunnel)`이라고 한다.
IPv6 송신 과정
1. 터널의 송신 측에 있는 IPv6 노드는 IPv6 데이터그램을 받고 IPv4 데이터그램의 데이터 필드에 이것을 넣는다.
2. IPv4 데이터그램에 목적지 주소를 터널의 수신 측에 IPv6 노드로 적어서 터널의 첫 번째 노드에 보낸다.
3. 터널 내부에 있는 IPv4라우터는 IPv4 라우터는 IPv4 데이터그램이 IPv6 데이터그램을 갖고 있다는 사실을 모른채 다른 데이터그램을 처리하는 방식으로 IPv4 데이터 그램을 처리한다.
4. 터널 수신 측에 있는 IPv6 노드는 IPv4 데이터그램을 받고 이 IPv4 데이터그램이 실제 IPv6 데이터그램임을 결정한다.
5. 다음 노드에 IPv6 데이터그램을 보낸다.
기초적인 IPv6 수용은 이루어지고 있지만 최근에 이루어진 것은 없다.
목적지 IP 주소를 찾은(`매치`) 후 패킷을 스위치 구조로 지정된 출력 포트로 전송(`액션`)하는 두 단계의 목적지 기반 포워딩을 앞서 설명했다.
프로토콜 스택의 다른 계층에서 다른 프로토콜과 관련된 여러 헤더 필드에 대해 `매치`를 수행할 수 있는 일반적인 `매치 플러스 액션` 방법을 생각해보자.
`액션`은 하나 이상의 출력 포트로 패킷을 전달하고, 인터페이스에서 나가는 패킷을 로드 밸런싱(load balancing)하고 헤더값을 다시 쓰고, 의도적으로 패킷을 차단/삭제 및 추가 처리 작업을 위해 특수 서버로 패킷을 보내는 등의 작업을 수행한다.
일반화된 포워딩에서는 각각의 패킷 스위치는 원격 컨트롤러에 의해 계산 및 분포된 `매치 플러스 액션 테이블`을 포함하고 있다.
위 그림은 `매치 플러스 액션 테이블`을 보여준다.
OpenFlow의 플로우 테이블로 알려진 `매치 플러스 액션 포워딩 테이블`의 각 엔트리는 다음을 포함한다.
- 들어오는 패킷에 대한 헤더값들의 세트가 매치될 것이다. 하드웨어 기반 매치는 TCAM 메모리에서 가장 신속하게 수행되며, 백만 개가 넘는 목적지 주소를 동반한다. 플로우 테이블 엔트리와 매치되지 않는 패킷은 더 많은 처리를 위해 원격 컨트롤러로 전송될 수 있다.
- 패킷들에 의해 갱신되는 `카운터 세트`는 플로우 테이블 엔트리들과 매치된다. 이러한 카운터는 플로우 테이블 엔트리와 마지막으로 갱신된 테이블 엔트리 이후에 매치된 다수의 패킷을 포함하고 있다.
- 패킷이 플로우 테이블 엔트리와 매치될 때 여러가지 액션이 가능해진다. 이러한 액션은 패킷을 지정된 출력 포트로 전달하고, 패킷을 삭제하고, 패킷의 복사본을 만들어 여러 출력 포트로 보내거나 선택한 헤더 필드를 다시 쓰는 것일 수 있다.
위 그림은 OpenFlow 1.0 `매치 플러스 액션` 규칙에서 매치될 수 있는 11개의 패킷 헤더 필드와 수신 포트 ID를 보여준다.
진입 포트는 패킷이 수신되는 패킷 스위치의 입력 포트를 나타낸다.
플로우 테이블 엔트리에는 와일드카드도 있을 수 있다. 예를 들어, 플로우 테이블의 `128.119.*.*` 의 주소는 128.119를 주소의 첫 번째 16 비트로 갖는 데이터그램의 해당 주소 필드와 매치된다.
또한 각 플로우 테이블 엔트리에는 우선순위가 있어 여러 플로우 테이블 엔트리와 매치되면, 선별된 매치 엔트리에 해당하는 패킷이 가장 높은 우선순위가 된다.
IP 헤더의 모든 필드가 매치될 수 있는 것은 아니다.
예를 들어 OpenFlow에서는 TTL 필드 또는 데이터그램 길이 필드에 기반한 매치를 허용하지 않는다.
여러 액션이 있는 경우 목록에 지정된 순서대로 수행된다.
가장 중요한 액션들은 다음과 같다.
- `포워딩`
  - 들어오는 패킷은 특정 실제 출력 포트로 전달되거나 모든 포트를 통해 브로드캐스트되거나 선택된 포트 세트를 통해 멀티캐스트될 수 있다.
  - 패킷은 캡슐화되어 원격 컨트롤러로 전송될 수 있다.
  - 컨트롤러는 새 플로우 테이블 엔트리를 설치하고 해당 패킷에 대한 조치를 취하거나 갱신된 플로우 테이블 규칙에 따라 포워딩을 위해 패킷을 장치로 반환할 수 있다.
- `삭제`
  - 아무 액션이 없는 플로우 테이블 엔트리는 매치된 패킷을 삭제해야함을 나타낸다.
- `필드 수정`
  - 패킷이 선택된 출력 포트로 전달되기 전에 10개의 패킷 헤더 필드의 값을 다시 쓸 수 있다.
위 그림의 상황을 가정하고 다음 예시들을 보자.
아주 간단한 예로 포워딩 동작이 h3 또는 h4로 예정된 h5 또는 h6 패킷이 s3에서 s1으로 전달된 다음 s1에서 s2로 전달된다고 가정한다.
위 상황에서 s1의 플로우 테이블 엔트리는 다음과 같다.
s3에 플로우 테이블 엔트리가 필요하므로 h5 또는 h6에서 전송된 데이터그램은 인터페이스 3을 통해 s1으로 전달된다.
마찬가지로, s1에 도착한 데이터그램을 호스트 h3 또는 h4로 전달할 수 있도록 s2에 플로우 테이블 엔트리가 필요하다.
위를 바탕으로 직접 채워보길 바란다.
두 번째 예로 h3에서 `10.1.*.*`로 향하는 데이터그램이 s2와 s1 사이의 링크를 통해 전달되는 반면, h4에서 `10.1.*.*` 로의 데이터그램은 s2와 s3 사이의 링크를 통해 전달되는 로드 밸런싱 시나리오를 고려해보자.
이 동작은 IP의 목적지 기반 포워딩으로 수행될 수 없다.
이 경우 s2의 포워딩 테이블은 다음과 같다.
s2에서 수신한 데이터그램을 h1 또는 h2로 전달하려면 s1에서 플로우 테이블 엔트리가 필요하다.
인터페이스 4에서 수신한 데이터그램을 s3에서 인터페이스 3을 통해 s1로 전달하려면 s3에서 플로우 테이블 엔트리가 필요하다. s1및 s3에서 이러한 플로우 테이블 엔트리를 파악할 수 있는지 확인하자.
s2가 s3에 연결된 호스트에서 보낸 트래픽만 수신하려고 하는 방화벽 시나리오를 생각해보자.
s2 플로우 테이블에 다른 엔트리가 없으면 `10.3.*.*`의 트래픽만 s2에 연결된 호스트로 전달된다.
`매치 플러스 액션` 플로우 테이블은 제한된 형태의 **프로그래밍 가능성**이다.
- NAT 변환 : NAT 박스는 사설 네트워크 주소체계를 구현하여 데이터그램 헤더 IP 주소 및 포트 번호를 다시 작성한다.
- 보안 서비스 : 방화벽은 헤더 필드 값을 기준으로 트래픽을 차단하거나 DPI(Deep Packet Inspection) 같은 추가 처리를 위해 패킷을 리다이렉션한다. 침입 탐지 시스템(IDS)은 미리 결정된 패턴을 탐지하고 그에 따라 패킷을 필터링할 수 있다.
- 성능 향상 : 미들박스는 압축과 같은 서비스를 수행한다. 즉, 원하는 서비스를 제공할 수 있는 서버 집합 중 하나에 대한 서비스 요청의 로드 밸런싱을 하는 주체다.
미들 박스는 네트워크 계층과 트랜스포트계층, 애플리케이션 계층을 명확히 구분하는 이전 네트워크의 분리를 명백히 위반한다.
예를 들어, 라우터와 호스트 사이에 위치한 NAT 박스는 네트워크 계층 IP 주소와 트랜스포트 계층 포트 번호를 다시 쓴다.
네트워크 내의 방화벽 블록은 IP 데이터그램 헤더 뿐만 아니라 애플리케이션 계층, 트랜스포트 계층 헤더까지 사용하여 데이터그램을 의심한다.
미들박스를 아키텍처적으로 혐오스럽다고 간주하는 사람들도 있지만, 다른 이들은 이러한 미들 박스가 '중요하고 영구적으로 존재한다'는 철학을 채택하고 있다.
`포워딩 테이블`(목적지 기반 포워딩의 경우)과 `플로우 테이블`(일반화된 포워딩의 경우)이 네트워크 계층의 데이터 평면과 제어 평면을 연결하는 수요 요소였는데,
이 테이블들이 라우터의 로컬 데이터 평면에서의 포워딩을 지정했다.
바로 이전 장에서의 그림을 상기해보자.
일반화된 포워딩의 경우에 라우터가 취하는 행동은 다양한 형태로 나타날 수 있었다.
- 라우터의 출력 포트로 패킷을 전달
- 패킷을 버리거나 복제
이 장에서는 **포워딩 테이블이나 플로우 테이블이 어떻게 만들어지고 유지 및 설치되는지**를 알아볼 것이다.
아래 그림은 라우팅 알고리즘들이 모든 라우터 **각각에서** 동작하는 경우를 나타낸다.
- 포워팅과 라우팅 기능이 모두 개별 라우터에 포함되어 있다.
- 각 라우터는 **다른 라우터의 라우팅 구성요소와 통신하여**
  자신의 포워딩 테이블의값을 계산하는 라우팅 구성요소를 갖고 있다.
- `OSPF`, `BGP` 프로토콜이 이 라우터별 제어 방식을 기반으로 한다.
아래 그림은 `논리적 중앙 집중형 컨트롤러`가 포워딩 테이블을 작성하고, 이를 모든 개별 라우터가 사용할 수 있도록 배포한 경우를 나타낸다.
일반화된 ‘`매치 플러스 액션(match plus action)`’ 추상화를 통해
라우터는 기존에는 별도로 장치로 구현되었던 다양한 기능(부하 분산, 방화벽, NAT) 뿐만 아니라 전통적인 IP 포워딩을 수행할 수 있다.
컨트롤러는 프로토콜을 통해 각 라우터의 `제어 에이전트(control agent, CA)`와 상호작용하여 라우터의 플로우 테이블을 구성 및 관리한다.
라우터별 제어 방식과는 다르게, CA는 서로 직접 상호작용하지 않으며, 포워딩 테이블을 계산하는 데도 적극적으로 참여하지 않는다.
일반적으로 ‘좋은’ 경로란 <b>최소 비용 경로(least-cost path)</b>를 말한다.
그러나 현실적으로는 **네트워크 정책**과 같은 실제 문제가 고려된다.
(e.g., Y 기관에 속해 있는 라우터 x는 Z 기관이 소유한 네트워크가 보낸 패킷을 전달해서는 안 됨)
라우팅 알고리즘을 분류하는 일반적인 방법 한 가지는 알고리즘이 `중앙 집중형`인지 `분산형`인지다.
계산 자체는 한 장소에서 수행되거나 모든 라우터 각각의 라우팅 모듈로 복사될 수 있다.
전체 상태 정보를 갖는 알고리즘을 `링크 상태(link-state, LS) 알고리즘`이라고 하는데,
이는 이 알고리즘이 네트워크 내 각 링크의 비용을 알고 있어야 하기 때문이다.
최소 비용 경로의 계산이 라우터들에 의해 반복적이고 분산된 방식으로 수행된다.
> 💡 각 노드는 **자신에게 직접 연결된 링크에 대한 비용 정보만을 가지고** 시작한다.
이후 반복된 계산과 이웃 노드와의 정보 교환을 통해 노드는 점차적으로 목적지 또는 목적지 집합까지의 최소 비용 경로를 계산한다.
분산 라우팅 알고리즘은 `거리 벡터(distance-vector, DV) 알고리즘`이라고도 하는데,
이는 각 노트가 네트워크 내 다른 모든 노드까지 비용(거리)의 추정값을 벡터 형태로 유지하기 때문이다.
라우팅 알고리즘을 분류하는 일반적인 두 번째 방식은 `정적 알고리즘`과 `동적 알고리즘`으로 분류하는 것이다.
사람이 직접 링크 비용을 수정하는 경우와 같은 종종 사람이 개입하는 상황 때문에 정적 라우팅 알고리즘에서 경로는 아주 느리게 변한다.
네트워크 트래픽 부하(load)나 토폴로지 변화에 따라 라우팅 경로를 바꾼다.
동적 알고리즘은 주기적으로, 혹은 토폴로지나 링크 비용의 변경에 직접적으로 응답하는 방식으로 수행된다.
- 장점 : 네트워크 변화에 빠르게 대응한다.
- 단점 : 경로의 루프(loop)나 경로 진동(oscillation) 같은 문제에 취약하다.
라우팅 알고리즘을 분류하는 세 번재 방식은 라우팅 알고리즘이 `부하에 민감한지 아닌지`에 따른다.
링크 비용은 **해당 링크의 현재 혼잡 수준을 나타내기 위해** 동적으로 변한다.
현재 혼잡한 링크에 높은 비용을 부과한다면, 라우팅 알고리즘은 혼잡한 링크를 우회하는 경로를 택하는 경향을 보일 것이다.
초기 ARPAnet 라우팅 알고리즘이 부하에 민감해서 많은 어려움이 있었다.
오늘날 인터넷 라우팅 알고리즘(RIP, OSPF, BGP 등)은 링크 비용이 현재(또는 가장 최근)의 혼잡을 반영하지 않기 때문에 부하에 민감하지 않다.
> 링크 상태 알고리즘에서는 **네트워크 토폴로지와 모든 링크 비용이 알려져 있어서** 링크 상태 알고리즘의 입력값으로 사용될 수 있다.
이것은 각 노드가 자신과 직접 연결된 링크의 식별자와 비용 정보를 담은 `링크 상태 패킷`을
알고리즘의 **k번째 반복** 이후에는 k개의 목적지 노드에 대해 최소 비용 경로가 알려지며,
이들은 모든 목적지 노드로의 최소 비용 경로 중에서 가장 낮은 비용을 갖는 k개의 경로다.
중앙 집중형 라우팅 알고리즘은 2단계로 구성된다.
아래 그래프의 네트워크에서 링크 상태 알고리즘을 수행한 결과는 다음과 같다.
링크 상태 알고리즘이 종료된 후에 우리는 각 노드에 대해 출발지 노드로부터의 최소 비용 경로상의 직전 노드를 알게 된다.
`노드 u의 포워딩 테이블`은 각 목적지에 대해 / 노드 u에서 그 목적지까지의 최소 비용 경로상의 다음 홉 노드 정보를 저장하여 구성한다.
`n개의 노드(출발지 노드 제외)`가 있다면 출발지에서 모든 목적지까지 최단 비용 경로를 찾기 위해 최악의 경우 얼마나 많은 계산이 필요한가?
첫 번째 반복에서 최소 비용이 이미 계산된 노드의 집합 N’에 포함되지 않은 노드 w를 결정하기 위해 모든 **n**개의 노드를 검사해야 하며,
두 번째 반복에서는 **n-1**개의 노드를, 세 번째 반복에서는 **n-2**개의 노드를 검사해야 한다.
따라서 찾아야 하는 노드의 총수는 `n(n+1)/2`가 되며,
링크 상태 알고리즘은 최악의 경우 `O(n^2)`의 복잡성을 갖는다.
진동 문제는 링크 상태 알고리즘뿐만 아니라 혼잡이나 지연 시간을 기반으로 링크 비용을 산출하는 모든 알고리즘에서 발생할 수 있다.
아래의 과정을 통해 진동 문제에 대하여 살펴보자.
초기의 라우팅은 다음과 같다.
링크의 비용은 통과하는 트래픽 양에 따른다.
링크 상태 알고리즘이 다시 수행되면 노드 y는 w로 가는 **시계 방향**의 경로 비용이 `1`인 반면,
지금까지 사용해왔던 **반시계 방향**으로의 경로 비용은 `1+e`임을 알게 된다.
따라서 w로 가는 y의 최소 비용 경로는 시계 방향이며,
x도 마찬가지로 w로 가는 **시계 방향** 경로를 새로운 최소 비용 경로로 결정한다.
링크 상태 알고리즘이 다시 한번 수행되면
다음번 링크 상태 알고리즘 수행 시에는 x, y, z 모두 **시계 방향**으로 트래픽을 전송한다.
라우터들이 동일한 주기 간격으로 링크 상태 알고리즘을 수행한다 하더라도
각 노드에서의 알고리즘의 실행 시각은 같지 않을 것이기 때문에 합리적인 방법이라고 생각된다.
하지만 연구자들은 라우터들이 알고리즘을 처음에는 각기 다른 시작 시각에, 그러나 같은 주기를 갖도록 해서 실행하더라도
**점진적으로 결국엔 서로 동기화된다**는 것을 발견하였다.
이러한 `자기 동기화`는 각 노드가 링크 상태 정보를 송신하는 시각을 임의로 결정하게 함으로써 회피할 수 있다.
_오늘날 실제로 사용되는 알고리즘은 거리 벡터(distance-vector, DV) 라우팅 알고리즘이다._
링크 상태 알고리즘이 네트워크 전체 정보를 이용하는 알고리즘인 반면,
- `분산적(distributed)` : 각 노드는 하나 이상의 직접 연결된 이웃으로부터 정보를 받고, 계산을 수행하며, 계산된 결과를 다시 이웃들에게 배포한다.
- `반복적(iterative)` : 이웃끼리 더 이상 정보를 교환하지 않을 때까지 프로세스가 지속된다.
- `비동기적(asynchronous)` : 모든 노드가 서로 정확히 맞물려 동작할 필요가 없다.
따라서 거리 벡터 라우팅 알고리즘의 기본 아이디어는 다음과 같다.
> 출발지 노드를 x라고 가정하면, 노드 x는 자신으로부터 집합 N에 속한 다른 모든 노드 y까지의 최소 비용 경로의 비용 D.x(y)를 추정한다.
D.x을 노드 x에서부터 N에 속한 모든 다른 노드 y까지의 비용 추정값의 벡터라고 하자.
DV 알고리즘으로 각 `노드 x`는 다음과 같은 라우팅 정보를 유지한다.
- 각 이웃 노드 v 중에서 x에 **직접 접속된 이웃 노드까지의 비용** `c(x, v)`
- **노드 x의 거리 벡터**, 즉 x로부터 N에 있는 모든 목적지 y로의 비용 예측값을 포함하는 벡터 `D.x`
- **이웃 노드들의 거리 벡터들**, 즉 v가 x의 이웃이라고 하면 `D.v = [D.v(y): y in N]`
> 분산적이고 비동기적으로 동작하는 알고리즘에서는 때때로 각 노드가 **자신의 거리 벡터를 이웃들에게 보낸다.**
노드 x가 이웃 w에게서 새로운 거리 벡터를 수신하면,
x는 w의 거리 벡터를 저장하고 벨만-포드 식을 사용하여 다음처럼 자신의 거리 벡터를 **갱신**한다.
1. 노드 x는 이 수정된 거리 벡터를 자신의 이웃들에게 보내고
2. 그에 따라 이웃들도 자신의 거리 벡터를 갱신한다.
> 모든 노드가 자신의 거리 벡터를 비동기적으로 교환하는 동작을 계속하다 보면,
> 비용 추정값 D.x(y)는 노드 x에서 노드 y까지의 실제 최소 비용 경로의 비용인 d.x(y)로 수렴하게 된다.
각 노드 x에서,
특정 목적지 y에 대한 자신의 포워딩 테이블을 갱신하기 위해 노드 x가 알아야 하는 것은 **y로의 최단 경로상의 다음 홉 라우터**인 `이웃 노드 v*(y)`다.
다음 홉 라우터 v*(y)는 위 DV 알고리즘의 14번째 줄에서 최솟값을 갖게 하는 이웃 v이기에,
13~14번째 줄에서 각 목적지 y에 대해 노드 x는 v*(y)를 결정하고 목적지 y에 대해 포워딩 테이블도 갱신한다.
> 💡 DV 알고리즘에서 하나의 노드가 갖는 정보는 단지 자신에게 직접 연결된 **이웃으로의 링크 비용과 그 이웃들로부터 수신하는 정보뿐**이다.
1. 각 노드는 이웃으로부터의 갱신을 기다리고 _(10~11번째 줄)_
2. 업데이터를 수신하면 새로 거리 벡터를 계산하고 _(14번째 줄)_
3. 이 새로운 거리 벡터를 이웃들에게 배포한다. _(16~17번째 줄)_
이 과정은 **더 이상의 갱신 메시지가 없을 때까지** 계속된다.
갱신 메시지가 더 이상 없으면 라우팅 테이블 계산도 더 이상 없고 알고리즘은 정지 상태가 된다.
_(10~11번째 줄 대기 명령을 수행)_
이 알고리즘은 링크 비용이 변할 때까지 정지 상태로 있는다.
여기서는 모든 노드가 동기적 방식으로 동작하지만, 비동기적 방식으로도 알고리즘은 올바르게 동작한다.
거리 벡터 알고리즘을 수행하는 노드가
1. 자신과 이웃 사이 링크의 비용이 변경된 것을 알게 되면
2. 자신의 거리 벡터를 갱신한 후
3. **최소 비용 경로의 비용에 변화가 있는 경우**에는 이웃에게 새로운 거리 벡터를 보낸다.
이때 최소 비용 경로의 비용이 감소한 상황과 증가한 상황 두 가지를 전부 살펴보자.
아래는 y에서 x로의 링크 비용이 4에서 1로 변한 상황을 나타낸 것이다.
이 상황에서의 DV 알고리즘은 다음과 같은 일련의 사건을 발생시킨다.
1. 시각 t0 : `y`가 링크 비용의 변화를 감지하고, 자신의 거리 벡터를 갱신한 후 이 변경값을 이웃에게 알린다.
2. 시각 t1 : `z`는 y로부터 갱신 정보를 받고 자신의 테이블을 갱신한다.
   - z는 x까지의 새로운 최소 비용을 계산한다.
   - 이웃에게 자신의 새로운 거리 벡터를 전송한다.
3. 시각 t2 : `y`는 z로부터 갱신 정보를 받고 자신의 테이블을 갱신한다.
   - **y의 최소 비용은 변화가 없으므로 y는 z에게 아무런 메시지를 보내지 않는다.**
   - 이에 알고리즘은 정지 상태가 된다.
따라서 거리 벡터 알고리즘은 정지 상태가 될 때까지 두 번만 반복하면 된다.
아래는 y에서 x로의 링크 비용이 4에서 60로 변한 상황을 나타낸 것이다.
이 상황에서의 DV 알고리즘은 다음과 같은 일련의 사건을 발생시킨다.
1. 시각 t0 : `y`가 링크 비용 변화를 감지하고 노드 x까지 다음의 비용을 갖는 새로운 최소 비용 경로를 계산한다.
   - 이때 우리는 네트워크 전체를 한눈에 볼 수 있기 때문에 z를 경유하는 이 새로운 비용이 **잘못되었다**는 사실을 알 수 있지만,
     노드 y의 입장에서는 아니다.
2. 시각 t1
   - x로 가기 위해 y는 z로 경로 설정을 하고, z는 y로 경로 설정을 하는 `라우팅 루프(routing loop)`가 발생한다.
     > t1에 x를 목적지로 하는 패킷이 y나 z에 도착하면 포워딩 테이블이 변할 때까지 이 두 노드 사이에서 왔다 갔다 순환할 것이다.
   - 노드 y는 x까지의 새로운 최소 비용을 계산했으므로 z에게 새로운 거리 벡터를 알린다.
3. 시각 t2 : z는 y로부터 갱신 정보를 받고 새로운 최소 비용을 계산한다.
   - D.z(x) = min{50+0, 1+6} = 7
4. 시각 t3 : y는 z로부터 새로운 거리 벡터를 수신하고 새로운 최소 비용을 계산한다.
   - Dy(x) = min{60+0, 1+7} = 8
   - x까지의 y의 최소 비용이 증가했으므로, 새로운 거리 벡터를 z에 알린다.
이렇게 계속 반복되는 문제를 `무한 계수 문제(count-to-infinity)`라고 한다.
방금 설명한 특정한 라우팅 루프 시나리오는 `포이즌 리버스(poisoned reverse)`라는 방법을 통해 방지할 수 있다.
즉, 만약 z가 y를 통해 목적지 x로 가는 경로 설정을 했다면, **z는 y에게 x까지의 거리가 무한대라고 알린다.**
_z는 y를 통과해서 x로 가는 동안은 이러한 거짓말을 계속한다._
이에 y는 z에서 x로 가는 경로가 없다고 믿으므로,
z가 계속해서 y를 통해 x로 가는 경로를 사용하는 동안은 y는 z를 통해 x로 가는 경로를 시도하지 않을 것이다.
**하지만 포이즌 리버스는 모든 무한 계수 문제를 해결할 수는 없다.**
단순히 직접 이웃한 2개의 노드가 아닌, 3개 이상의 노드를 포함한 루프는 포이즌 리버스로는 감지할 수 없다.
LS와 DV 알고리즘은 경로를 계산할 때 서로 대비되는 방법을 취한다.
- 전체 정보를 필요로 한다.
- 각 노드는 다른 **모든** 노드와 (브로드캐스트를 통해) 통신한다.
- **오직** 자신에게 직접 연결된 링크의 비용만 알린다.
- 각 노드는 **오직** 직접 연결된 이웃과만 메시지를 교환한다.
- 자신으로부터 네트워크 내 (자신이 알고 있는) **모든** 노드로의 최소 비용 추정값을 이웃들에게 제공한다.
- 각 노드는 네트워크 내 각 링크 비용을 알아야 하며, 이를 위해서는 `O(|N| |E|)`개의 메시지가 전송되어야 한다.
- 링크 비용이 변할 때마다 새로운 링크 비용이 모든 노드에게 전달되어야 한다.
- 알고리즘의 결과가 수렴하는 데 걸리는 시간은 많은 요소에 좌우된다.
- 링크 비용이 변하고, 이 새로운 링크 비용이 이 링크에 연결된 어떤 노드의 최소 비용 경로에 변화를 준 경우에만
  DV 알고리즘은 수정된 링크 비용을 전파한다.
라우터가 고장나거나 오동작하거나 파손된다면 어떤 일이 발생할까?
- 라우터는 연결된 링크에 대해 잘못된 비용 정보를 브로드캐스트할 수 있다.
- 노드는 링크 상태 브로드캐스트를 통해 받은 패킷을 변질시키거나 폐기할 수 있다.
그러나 **하나의 링크 상태 노드는 자신의 포워딩 테이블만 계산하기 때문에**
링크 상태 알고리즘에서 경로 계산은 어느 정도 분산되어 수행된다.
따라서 링크 상태 알고리즘은 어느 정도의 견고성을 제공한다.
- 노드는 잘못된 최소 비용 경로를 일부 혹은 모든 목적지에 알릴 수 있다.
각 반복마다 한 노드의 거리 벡터 계산이 이웃에게 전달되고 다음 반복에서 이웃의 이웃에게 간접적으로 전달된다.
따라서 거리 벡터 알고리즘을 사용하는 네트워크에서 한 노드의 잘못된 계산은 **전체로 확산될 수 있다.**
실제로 1997년에 작은 ISP에서 오작동한 라우터가 잘못된 라우팅 정보를 전국망의 백본 라우터에 제공한 적이 있었다.
이는 다른 라우터들이 오작동한 라우터에게 대규모 트래픽을 보내게 만들었고,
결국 어떤 알고리즘이 다른 알고리즘보다 명백히 낫다고 말할 수는 없으며,
실제로 두 알고리즘 모두는 인터넷에서 사용되고 있다.
네트워크를 **동일한 라우팅 알고리즘을 수행하는 동종의 라우터 집합**으로 간주하는 관점은 다음의 두 가지 문제점이 존재한다.
1. `확장`
   라우터의 수가 증가함에 따라 라우팅 정보의 통신, 계산, 저장에 필요한 오버헤드가 걷잡을 수 없이 증가한다.
2. `관리 자율성`
   ISP는 일반적으로 자신의 네트워크를 원하는 대로 운용하거나(e.g., 어떠한 라우팅 알고리즘이라도 수행할 수 있도록),
   네트워크 내부 구성을 외부에 감추기를 원한다.
위의 문제점들은 라우터들을 `자율 시스템(autonomous system, AS)`으로 조직화하여 해결할 수 있다.
- 각 AS는 동일한 관리 제어하에 있는 라우터의 그룹으로 구성된다.
- 자율 시스템은 전 세계적으로 고유한 `AS 번호(autonomous system number, ASN)`으로 식별된다.
- 같은 AS 안에 있는 라우터들은 동일한 라우팅 알고리즘을 사용하고 상대방에 대한 정보를 갖고 있다.
- 자율 시스템 내부에서 동작하는 라우팅 알고리즘을 `AS 내부 라우팅 프로토콜(intra-autonomous system routing protocol)`이라고 한다.
`개방형 최단 경로 우선(open shortest path first, OSPF) 라우팅`과 `IS-IS(Intermediate System to Intermediate System)`는
인터넷에서 AS 내부 라우팅에 널리 사용된다.
OSPF는 링크 상태 정보를 플러딩(flooding)하고 다익스트라 최소 비용 경로 알고리즘을 사용하는 **링크 상태 알고리즘**이다.
- OSPF를 이용하여 각 라우터는 <b>전체 AS에 대한 완벽한 토폴로지 지도(그래프)</b>를 얻는다.
- 각 라우터는 자신을 루트 노드로 두고 모든 서브넷에 이르는 최단 경로 트리를 결정하기 위해 혼자서 다익스트라의 최단 경로 알고리즘을 수행한다.
- OSPF를 사용하는 라우터는 **자율 시스템 내의 다른 모든 라우터에게** 라우팅 정보를 브로드캐스팅한다.
  - 링크 상태가 변경될 때마다
  - 링크 상태가 변경되지 않았더라도 정기적으로(최소한 30분마다 한 번씩)
- OSPF 메시지에 포함된 상태 정보는 인터넷 프로토콜에 의해 전달되며, 상위 계층 프로토콜 번호로는 OSPF를 의미하는 `89`를 갖는다.
  - 따라서 OSPF 프로토콜은 신뢰할 수 있는 메시지 전송과 링크 상태의 브로드캐스트와 같은 기능을 스스로 구현해야 한다.
  - 또한 OSPF 프로토콜은 링크가 동작하고 있는지 검사하고,
    OSPF 라우터가 네트워크 전반의 링크 상태에 대한 이웃 라우터의 데이터베이스를 얻을 수 있도록 해야 한다.
링크 상태 라우팅을 설명하면서 우리는 순서를 묵시적으로 아래와 같이 가정했다.
1. 링크 가중치가 설정되고,
2. OSPF 같은 라우팅 알고리즘이 수행되며,
3. LS 알고리즘에 의해 계산된 라우팅 테이블의 내용에 따라 트래픽이 흐른다.
이를 원인과 결과 방식으로 설명하면,
- 원인 : 링크 가중치가 주어지고
- 결과 : 이에 따라 전체 비용을 최소화하는 라우팅 경로가 결정된다.
실제로는 링크 가중치와 라우팅 경로 간의 원인과 결과 관계는 반대가 될 수도 있다.
네트워크 운영자가 어떤 트래픽 관리 목표를 충족시키는 라우팅 경로를 얻기 위해 링크 가중치를 설정할 수 있다.
즉, 트래픽 흐름에 대한 바람직한 경로가 알려져 있고, OSPF 라우팅 알고리즘이 이 경로대로 구성하게 되도록 OSPF 링크 가중치를 찾아야 한다.
따라서 관리자는 모든 링크 비용을 1로 설정함으로써 최소 홉 라우팅이 이루어지게 하거나,
적은 대역폭을 가진 링크 사용을 억제하기 위해 링크 용량에 반비례하게 링크 가중치를 설정할 수 있다.
OSPF 라우터들 간의 정보 교환(e.g., 링크 상태 갱신)을 인증할 수 있으며,
인증을 통해 신뢰할 수 있는 라우터들만이 AS 내부의 OSPF 프로토콜에 참여할 수 있다.
원래 라우터 간의 OSPF 패킷은 인증을 하지 않으므로 위조될 수 있다.
두 종류의 인증
- 단순 인증 : 동일한 패스워드가 각 라우터에 설정되며, 라우터가 OSPF 패킷을 보낼 때 패스워드를 평문 그대로 포함하기 때문에 안전하지 않다.
- MD5 인증 : 모든 라우터에 설정된 공유 비밀키를 기반으로 한다. _(8장 내용)_
하나의 목적지에 대해 동일한 비용을 가진 여러 개의 경로가 존재할 때 OSPF는 여러 개의 경로를 사용할 수 있도록 한다.
즉, 비용이 동일한 여러 개의 경로가 있을 때 **모든 트래픽을 전달하기 위한 단 하나의 경로를 선택할 필요가 없다.**
`MOSPF(multicast OSPF)`는 멀티캐스트 라우팅 기능을 제공하기 위해 OSPF를 단순 확장했다.
- 기존의 OSPF 링크 데이터베이스를 사용
- OSPF 링크 상태 브로드캐스트 메커니즘에 새로운 형태의 링크 상태 알림을 추가
- `MAC 주소` : 네트워크 상에서 서로를 구분하기 위해 디바이스마다 할당된 물리적 주소
- `유니캐스트(Unicast)` : 정보를 전송하기 위한 프레임에 자신의 MAC 주소와 목적지의 MAC 주소를 첨부하여 전송하는 방식 (일대일 통신)
- `브로드캐스트(Broadcast)` : 로컬 네트워크에 연결되어 있는 모든 시스템에게 프레임을 보내는 방식
  (송신 노드 하나가 네트워크에 연결된 수신 가능한 모든 노드에 데이터를 전송)
- `멀티캐스트(Multicast)` : 네트워크에 연결되어 있는 시스템 중 특정 그룹을 지정해서 해당 그룹원에게만 한 번에 정보를 전송하는 방식
  (라우터가 멀티캐스트를 지원해야만 사용 가능)
OSPF의 자율 시스템(AS)는 계층적인 영역(area)으로 구성될 수 있다.
- 각 영역은 자신의 OSPF 링크 상태 라우팅 알고리즘을 수행한다.
- 한 역역 내의 라우터는 **같은 영역 내의 라우터들에게만** 링크 상태를 브로드캐스트한다.
- 각 영역 내에서 하나 혹은 그 이상의 `영역 경계 라우터(area border router)`가 **영역 외부로의 패킷 라우팅을 책임진다.**
- `백본 영역`의 주요 역할은 AS 내 영역 간의 트래픽을 라우팅하는 것이다.
AS 내 영역 간 라우팅을 위해서는,
1. 영역 경계 라우터로 패킷을 라우팅한다. (영역 내 라우팅)
2. 백본을 통과하여 목적지 영역의 영역 경계 라우터로 라우팅한다.
3. 그 후 최종 목적지로 라우팅한다.
패킷이 **여러 AS를 통과하도록** 라우팅할 때,
(e.g., 한국에 있는 스마트폰이 실리콘 밸리에 있는 데이터 센터로 전송을 할 경우)
`자율 시스템 간 라우팅 프로토콜(inter-autonomous system routing protocol)`이 필요하다.
통신하는 AS들은 같은 AS 간 라우팅 프로토콜을 수행해야만 한다.
실제로 인터넷의 모든 AS는 `경계 게이트웨이 프로토콜(Border GateWay Protocol, BGP)`을 사용하며,
이는 거리 벡터 라우팅과 같은 줄기에서 나왔다고 볼 수 있는 **분산형 비동기식 프로토콜**이다.
`같은 AS 내에 있는 목적지`에 대해서는 라우터의 포워딩 테이블 엔트리들이 해당 AS의 AS 내부 라우팅 프로토콜에 의해 결정된다.
하지만 목적지가 AS 외부에 있는 경우, `BGP`가 필요하다.
BGP에서는 패킷이 `CIDR(Classless Inter-Domain Routing) 형식`으로 표현된, `주소의 앞쪽 프리픽스(prefix)`를 향해 전달된다.
각 프리픽스는 서브넷이나 서브넷의 집합을 나타낸다. (e.g., 139.16.68/22)
라우터의 포워딩 테이블은 `(x, I)` 같은 형식의 엔트리들을 갖게 된다
AS 간 라우팅 프로토콜로서 BGP는 각 라우터에게 다음과 같은 수단을 제공한다.
1. 이웃 AS를 통해 도달 가능한 서브넷 프리픽스 정보를 얻는다.
   - **특히 각 서브넷이 자신의 존재를 인터넷 전체에 알릴 수 있도록 한다.**
2. 서브넷 주소 프리픽스로의 가장 좋은 경로를 결정한다.
   - 라우터는 특정한 주소 프리픽스를 향한 2개 이상의 경로를 알 수도 있다.
   - 가장 좋은 경로를 결정하기 위해 라우터는 BGP의 경로 결정 프로시저를 수행한다.
아래의 단순한 네트워크는 3개의 자율 시스템 `AS1`, `AS2`, `AS3`를 가지며,
AS3는 주소 프리픽스가 `x`인 서브넷을 포함한다.
각 AS에서 각각의 라우터들은 `게이트웨이 라우터(gateway router)` 또는 `내부 라우터(internal router)`다.
- AS의 경계에 있는 라우터
- 다른 AS들에 있는 하나 또는 여러 개의 라우터와 직접 연결된다.
- e.g., AS1의 `라우터 1c`
- 자신의 AS 내에 있는 호스트 및 라우터와만 연결된다.
- e.g., AS1의 `라우터 1a, 1b, 1d`
자율 시스템은 서로 메시지를 보내지 않고 **라우터가 보낸다.**
- BGP에서 라우터의 쌍들은 포트 번호가 `179`이고 `반영구적인 TCP 연결`을 통해 라우팅 정보를 교환한다.
- 이 TCP 연결을 통해 모든 BGP 메시지가 전송된다.
- **2개의 AS**를 연결하는 BGP 연결
- **같은 AS 내의 라우터**를 연결하는 BGP 연결
보통 각기 다른 AS에 속하는 게이트웨이 라우터들을 직접 연결하는 링크에는 `eBGP 연결`이 존재한다.
각 AS 내부 라우터 간에는 `iBGP 연결`도 존재하며,
> iBGP 연결은 물리적인 링크와 항상 일치하지는 않는다.
위 예시에서 프리픽스 `x`에 대한 **도달 가능성 정보**를 AS1과 AS2의 모든 라우터에게 알리는 작업을 생각해보자.
아래의 과정이 완료되면 AS1과 AS2의 각 라우터들은 x의 존재와 x로 향하는 AS 경로를 알게 된다.
1. 먼저 게이트웨이 라우터 3a는 게이트웨이 라우터 2c에게 ‘`AS3 x`’라는 `eBGP 메시지`를 보낸다.
   (<b>’x가 존재하고 AS3 내에 있다’</b>는 의미)
2. 게이트웨이 라우터 2c는 `iBGP 메시지` ‘`AS3 x`’를 게이트웨이 라우터 2a를 포함한 **AS2 내부의 모든 라우터에게 전송한다.**
3. 게이트웨이 라우터 2a는 `eBGP 메시지` ‘`AS2 AS3 x`’를 게이트웨이 라우터 1c에게 보낸다.
   (’x가 존재하고 x에 도달하기 위해서는 먼저 **AS2를 통과하고 그 후 AS3으로 갈 수 있다**’는 의미)
4. 마지막으로, 게이트웨이 라우터 1c는 iBGP를 사용하여 AS1 내의 **모든 라우터에게** 메시지 ‘`AS2 AS3 x`’를 전달한다.
실제 네트워크에서는 주어진 라우터에서 특정 목적지까지 다른 많은 경로가 존재할 수 있고, 심지어 각기 다른 일련의 AS들을 통과하기도 한다.
이 경우에 AS1에서 x로는 2개의 경로가 존재한다.
1. 라우터 1c를 통과하는 경로 ‘`AS2 AS3 x`’
2. 라우터 1d를 통과하는 새로운 경로 ‘`AS3 x`’
> 주어진 라우터에서 목적지 서브넷까지는 많은 경로가 있을 수 있는데,
> 이런 경로들 중에서 라우터는 어떻게 **선택**을 할까? 그리고 어떻게 그에 따라 **포워딩 테이블을 설정**할까?
라우터가 BGP 연결을 통해 주소 프리픽스를 알릴 때 몇몇 `BGP 속성(attribute)`을 함께 포함한다.
BGP의 용어로는 **프리픽스와 그것의 속성**을 `경로(route)`라고 한다.
- **알림 메시지가 통과하는 AS들의 리스트**를 담는다.
  1. 프리픽스가 어떤 AS에 전달되었을 때
  2. 그 AS는 자신의 ASN을 `AS-PATH` 내 현재 리스트에 추가한다.
- 메시지의 루프를 감지하고 방지하기 위해 활용한다.
  1. 어떤 라우터가 자신의 AS가 경로 리스트에 포함되어 있는 것을 발견하면
  2. 그 알림 메시지를 버린다.
- **AS-PATH가 시작되는 라우터 인터페이스의 IP 주소**
AS1에서 AS2를 통과하여 x로 가는 ‘`AS2 AS3 x`’ 경로의 NEXT-HOP 속성은 **라우터 2a의 왼쪽 인터페이스의 IP 주소**다.
AS1에서 AS2를 우회하여 x로 가는 ‘`AS3 x`’ 경로의 NEXT-HOP 속성은 **라우터 3d의 맨 왼쪽 인터페이스의 IP 주소**다.
즉, AS1의 각 라우터는 프리픽스 x로 가는 2개의 BGP 경로를 알게 된다.
> 라우터 2a의 맨 왼쪽 인터페이스의 IP 주소; AS2 AS3; x
> 라우터 3d의 맨 왼쪽 인터페이스의 IP 주소; AS3; x
NEXT-HOP 속성은 **AS1에 속하지 않는** 라우터의 IP 주소이다.
그러나 이 IP 주소를 포함하는 서브넷이 AS1에 **직접적으로 연결된다.**
> 💡 가능한 모든 경로 중, 경로 각각의 시작점인 **NEXT-HOP 라우터까지의 경로 비용이 최소가 되는 경로**를 선택한다.
1. 여러 게이트웨이를 통해 서브넷 x에 도달할 수 있다는 사실을 AS 간 프로토콜로부터 알게 된다.
2. 각 게이트웨이까지의 최소 비용 경로를 정하기 위해 AS 내부 프로토콜을 통해 얻은 라우팅 정보를 이용한다.
3. **뜨거운 감자 라우팅: 가장 적은 비용의 게이트웨이를 선택한다.**
4. 포워딩 테이블로부터 최소 비용 게이트웨이로의 인터페이스 I를 결정한 후 포워딩 테이블에 `(x, I)`를 추가한다.
> 포워딩 테이블에 AS 외부의 목적지를 추가할 때
   - 라우터 1b에서 `라우터 2a`까지의 최소 비용 : 2
   - 라우터 1b에서 `라우터 3d`까지의 최소 비용 : 3
   따라서 라우터 2a가 선택된다.
4. 라우터 1b는 자신의 (AS 내부 알고리즘에 의해 설정된) 포워딩 테이블을 관찰하여 라우터 2a로 가기 위한 인터페이스 I를 찾아내고,
> 라우터가 목적지까지의 경로 중 **자신의 AS 바깥에 있는 부분에 대한 비용은 신경 쓰지 않고**
> 최대한 신속하게(가능한 한 최소의 비용으로) 패킷을 자신의 AS 밖으로 내보내는 것이다.
즉, 뜨거운 감자 라우팅은 오로지 자신의 경로 중에서 **자기 AS 내부 비용만 줄이려는** 이기적인 알고리즘이다.
이를 사용하면 한 AS 내 2개의 라우터가 동일한 목적지 주소에 대해 각기 다른 AS 경로를 선택할 수도 있다.
실제로 BGP는 **뜨거운 감자 라우팅을 포함하는** 더 복잡한 알고리즘을 사용한다.
목적지 주소의 프리픽스가 주어지면, 지금까지 라우터가 알아낸 해당 목적지까지의 모든 경로가 BGP의 경로 선택 알고리즘에 입력으로 주어진다.
여기서 뜨거운 감자 라우팅에서 추가된 것은 속성 중의 하나로서 `지역 선호도(local preference)`가 경로에 할당되었다는 것이다.
한 경로의 지역 선호도는 라우터에 의해 설정되었거나 같은 AS 내부의 다른 라우터로부터 학습된 것이다.
1. `최고 지역 선호 값`을 가진 경로가 선택된다.
2. 최고 지역 선호 값을 가진 경로가 여러 개 있다면 이들 중에서 `최단 AS-PATH`를 가진 경로가 선택된다.
   - 만약 이 규칙이 경로 선택을 위한 유일한 규칙이라면, BGP는 **경로 결정을 위해** `DV 알고리즘`을 사용할 것이다.
   - 여기서 거릿값으로는 **AS 홉 수**를 사용한다.
3. (같은 최고 지역 선호 값 및 같은 AS-PATH 길이를 가진) 모든 남은 경로들에 대해 `뜨거운 감자 라우팅`을 수행한다.
4. 만일 아직도 하나보다 많은 경로가 남아 있다면 라우터는 `BGP 식별자`를 사용하여 경로를 선택한다.
`라우터 1b`에서 서브넷 `x`로 가는 BGP 경로는 2가지가 존재했고(AS2를 통과 또는 우회),
뜨거운 감자 라우팅이 바로 사용된다면 BGP는 AS2를 통과하는 경로로 패킷을 보내야 한다.
하지만 위의 경로 선택 알고리즘에서 규칙 2가 규칙 3보다 먼저 적용되므로, **더 짧은 AS-PATH를 가진** AS2 우회 경로가 선택된다.
따라서 이는 더이상 이기적인 알고리즘이 아니며, 결과적으로 종단 간 지연 시간이 줄어들 것이다.
BGP는 `IP 애니캐스트(anycast) 서비스`를 구현하는 데도 활용된다.
많은 애플리케이션에서 (1) 같은 콘텐츠를 **지리적으로 분산된 다른 많은 서버에 복제하고,**
(2) 각 사용자를 가장 가까운 서버의 콘텐츠로 접근하게 하려고 하는 경우를 생각해보자.
이 경우, BGP의 경로 선택 알고리즘을 사용할 수 있다.
1. IP 애니캐스트 설정 단계에서
   (1) CDN 사업자가 자신의 서버 여러 대에 **동일한** IP 주소를 할당하고
   (2) 표준 BGP를 활용하여 이 주소를 서버 각각으로부터 알린다.
   - 라우터가 이 IP 주소에 대한 복수 개의 경로 알림 메시지를 받으면
     이를 동일한 물리적 위치로의 서로 다른 경로에 대한 정보를 제공받고 있는 것으로 생각한다.
   - 실제로는 서로 다른 물리적 위치로 가는 서로 다른 경로다.
2. 각 라우터는 라우팅 테이블을 설정하면서 `BGP 경로 선택 알고리즘`을 수행하여 해당 IP 주소로의 최고의 경로를 골라낸다.
이러한 최초의 BGP 주소 알림 단계 이후에 CDN는 콘텐츠 배포를 할 수 있다.
3. 사용자가 비디오를 요청하면 CDN은 사용자가 어디에 위치해 있든 상관없이
   지리적으로 분산되어 있는 서버들이 **공통적으로 사용하는 IP 주소**를 사용자에게 돌려준다.
4. 사용자가 그 주소로 요청을 보내면 인터넷 라우터는 그 요청 패킷을 BGP 경로 선택 알고리즘이 정의한 가장 ‘가까운’ 서버로 전달한다.
실제로는 BGP 라우팅이 변경되면 하나의 TCP 연결에 속한 패킷들이 서로 다른 복제 웹 서버로 도착될 수 있기 때문에
CDN은 위의 예처럼 IP 애니 캐스트를 사용하지 않으며,
DNS 시스템에서는 DNS 질의를 가장 가까운 루트 DNS 서버로 전달하기 위해 IP 애니캐스트를 광범위하게 사용된다.
라우터가 목적지까지의 경로를 선택하려고 할 때
`AS 라우팅 정책`은 최단 AS-PATH나 뜨거운 감자 라우팅 등의 다른 모든 고려사항보다 우선시된다.
아래 그림에서는 **A, B, C, W, X, Y** 이렇게 6개의 `자율 시스템(AS)`이 서로 연결되어 있다.
현재는 백본 ISP들 사이의 경로를 결정하는 방법에 대한 공식적인 표준은 없지만,
상업적 ISP들이 따르는 대략적인 규칙은
**ISP 백본 네트워크를 통해 흐르는 트래픽은 해당 ISP의 고객 네트워크를 출발지로 하거나 목적지로 해야 한다**는 것이다(또는 둘 다).
개별적인 상호 협정은 전통적으로 두 ISP 간에 협상되고 종종 기밀사항이다.
_IP 주소체계, DNS, BGP를 포함하여 지금까지 살펴본 많은 프로토콜과 개념을 한데 모은다._
작은 회사를 설립했다고 가정하다.
회사에는 회사의 제품과 서비스를 설명하는 공개 웹 서버, 메일 서버, DNS 서버를 포함한 많은 서버가 있다.
1. 먼저 `지역 ISP`와 계약하여 인터넷 연결을 해야 한다.
   - 회사는 `게이트웨이 라우터`를 갖게 될 텐데, 이는 지역 ISP의 라우터에 연결될 것이다.
   - 물리적 연결과 IP 주소 범위를 가지면
     회사의 웹 서버, 메일 서버, DNS 서버, 게이트웨이 라우터와 다른 서버 및 네트워킹 장치들에 IP 주소(주소 범위에서)를 할당해야 한다.
2. 회사의 `도메인 이름`(e.g., xanadu.com)을 얻기 위해 인터넷 등록 기관과 계약을 해야 하며, `DNS 시스템`에 등록해야 한다.
   - 회사의 `DNS 서버`의 IP 주소를 등록 기관에 제공해야 한다.
   (메일 서버를 포함하여 회사의 공개적으로 사용 가능한 다른 서버들에 대해서도 유사한 항목들을 가져야 한다.)
     1. DNS 시스템은 회사의 DNS 서버에 접촉하여 웹 서버의 IP 주소를 알아낸 후
     2. 이를 앨리스에게 제공한다.
   - 이제 앨리스는 회사의 웹 서버에 직접적으로 TCP 연결을 설립할 수 있다.
4. 전 세계의 외부인이 회사의 웹 서버에 접근할 수 있도록 하기 위해서는
   - 예시 상황
     1. 회사의 웹 서버의 IP 주소를 알아낸 앨리스가 그 IP 주소로 IP 데이터그램(e.g., TCP SYN 세그먼트)을 보낸다.
     2. 이 데이터그램은 인터넷을 통해 라우팅되어 여러 자율 시스템의 라우터들을 연속적으로 거친 후 마침내 웹 서버에 도착하게 된다.
        - 라우터들 각각은 이 데이터 그램을 수신하면,
          **어느 출력 포트로 내보내야 하는지 결정하기 위해** 자신의 `포워딩 테이블`에서 해당 엔트리를 찾는다.
   - 이는 `BGP`를 통해서 이루어지게 된다.
     - 회사가 지역 ISP와 계약하고 주소 프리픽스(즉, 주소 범위)를 할당 받을 때,
       지역 ISP는 BGP를 사용하여 자신과 연결되어 있는 ISP들에게 회사의 주소 프리픽스를 알린다.
     - 연결된 ISP들 역시 BGP를 활용하여 이 알림 정보를 전파한다.
이 절에서는 4.4절에서 사용한 SDN 용어들을 다시 채택하여
네트워크의 포워딩 장비들은 ‘`패킷 스위치`’ 또는 그냥 ‘`스위치`’라고 부를 것이다.
이 스위치들에서의 포워딩 결정은 네트워크 계층에서의 출발지/목적지 주소, 링크 계층에서의 출발지/목적지 주소 외에도
트랜스포트 계층, 네트워크 계층, 링크 계층 패킷 헤더의 다른 많은 값에 기반하여 이루어진다.
> `SDN`으로 제어되는 스위치들에서의 패킷 전달은 트랜스포트 계층, 네트워크 계층, 또는 링크 계층 헤더의 **어떤 값을 기반으로 하든 이루어질 수 있다.**
이는 앞 절에서 살펴본,
`IP 데이터그램`의 포워딩이 온전히 데이터그램의 목적지 주소를 기반으로 이루어지는 전통적인 라우터 기반 포워딩과는 매우 대조적인 특성이다.

> 💡 SDN에서는 모든 네트워크 스위치의 플로우 테이블 항목들을 계산하고 관리, 설치하는 일이 모두 `SDN 제어 평면`의 임무다.


- 네트워크의 `스위치`들로 구성된다. (이들은 상대적으로 단순하지만 빠른 장치들)
- 자신들의 플로우 테이블 내용을 기반으로 ‘매치 플러스 액션’을 수행한다.


- 서버와 스위치들의 플로우 테이블을 결정, 관리하는 `소프트웨어`로 이루어진다.

`SDN 제어 평면`은 소프트웨어로 구현되어 있으며, 네트워크 스위치로부터 멀리 떨어진 별도의 서버에서 수행된다.

아래의 그림에서 볼 수 있듯, 제어 평면은 2개의 구성요소로 이루어진다.

1. `SDN 컨트롤러`(또는 네트워크 운영체제)
2. `SDN 네트워크 제어 애플리케이션`들의 집합

SDN 컨트롤러는

1. 정확한 상태정보(e.g., 원격 링크와 스위치, 호스트들의 상태)를 유지하고,
2. 이 정보를 네트워크 제어 애플리케이션들에 제공하며,
3. 애플리케이션들이 하부 네트워크 장치들을 모니터하고 프로그램하고 제어까지 할 수 있도록 수단을 제공한다.

그림에서의 컨트롤러는 단일 중앙 서버의 형태이지만, 실제로 컨트롤러는 **논리적으로만 중앙 집중 형태**다.

(일반적으로는 협업 능력과 확장성, 높은 이용성을 갖도록 몇 개의 서버에 구현)
제어 평면에서 수행 중인 네트워크 제어 애플리케이션을 통해 네트워크를 프로그램할 수 있다.
이 애플리케이션들은 **SDN 컨트롤러가 제공하는 API를 이용하여** 네트워크 장치들에 있는 데이터 평면을 명세하고 제어한다.
e.g.,
라우팅 네트워크 제어 애플리케이션은 **SDN 컨트롤러가 갖고 있는 노드 상태 및 링크 상태 정보에 기반한** 다익스트라 알고리즘을 수행하여
출발지와 목적지 사이의 종단 간 경로를 결정한다.
: SDN 컨트롤러와 SDN 네트워크 제어 애플리케이션
컨트롤러의 기능은 크게 3개의 계층으로 구성된다.
1. `네트워크 제어 애플리케이션 계층과의 인터페이스`
2. `네트워크 전역 상태 관리 계층`
3. `통신 계층`

> 💡 제어받는 장치들과의 통신

- SDN 컨트롤러가 원격의 SDN 기능이 가능한 장치들의 동작을 제어하려면 컨트롤러와 그 장치들 사이에 정보를 전달하는 프로토콜이 필요하다.
- 장치는 주변에서 관찰한 이벤트를 컨트롤러에 알려, 네트워크 상태에 대한 최신의 정보를 제공해야 한다.

컨트롤러와 제어받는 장치들 간의 통신은 ‘`사우스바운드(southbound)`’라고 알려진 **컨트롤러 인터페이스**를 넘나든다.

이 통신 기능을 제공하는 구체적 프로토콜은 `OpenFlow`이며, 이는 모두는 아니지만 대부분의 SDN 컨트롤러에 구현되어 있다.


> 💡 네트워크 전역에 분산되고 견고한 상태 관리

SDN 제어 평면의 궁극적인 제어 결정을 위해서는
컨트롤러가 네트워크 호스트와 링크, 스위치, 그리고 SDN으로 제어되는 다른 장치들에 대한 최신 정보를 알아야 한다.

제어 평면의 궁극적인 목적은 다양한 제어 장치들의 플로우 테이블을 결정하는 것이므로 컨트롤러도 이 테이블들의 복사본을 유지해야 할 것이다.

스위치의 플로우 테이블이 가지는 카운터들과 같은 이러한 정보 조각들은 모두 SDN 컨트롤러가 유지하는 <b>네트워크 전역 ‘상태’</b>의 예들이다.

> 💡 네트워크 제어 애플리케이션들을 위한 인터페이스와 추상화

컨트롤러는 `‘노스바운드(northbound)’ 인터페이스`를 통해 네트워크 제어 애플리케이션과 상호작용한다.

이 API는 네트워크 제어 애플리케이션이 상태 관리 계층 내의 네트워크 상태 정보와 플로우 테이블을 읽고 쓸 수 있도록 해준다.

---

SDN 컨트롤러는 외부에서 볼 때 _‘논리적으로 중앙 집중된’_, 잘 짜여진 하나의 서비스로 보일 수 있지만,

이 서비스들과 상태 정보를 보관하기 위한 데이터베이스는
장애 허용성(fault tolerance)과 높은 가용성, 또는 다른 성능상의 이유로 실제로는 **분산된** 서버의 집합에 구현된다.

근래의 컨트롤러는 논리적으로는 중앙 집중 형태이나 물리적으로는 분리된 컨트롤러 플랫폼 구조이다.

이런 구조는 제어되는 장치와 네트워크 제어 애플리케이션에게 늘어나는 장치 수에 따라 확장 가능한 서비스와 높은 가용성을 제공한다.


- OpenFlow 프로토콜은 SDN 컨트롤러와 SDN으로 제어되는 스위치 또는 OpenFlow API를 구현하는 다른 장치와의 사이에서 동작한다.
- OpenFlow 프로토콜은 TCP상에서 디폴트 포트 번호 `6653`을 가지고 동작한다.

**컨트롤러가 제어되는 스위치로 전달하는** 중요한 메시지는 다음과 같다.

- `설정` : 이 메시지는 컨트롤러가 스위치의 설정 파라미터들을 문의하거나 설정할 수 있도록 한다.

- `상태 수정` : 이 메시지는 컨트롤러가 스위치 플로우 테이블의 엔트리를 추가/제거 또는 수정하거나 스위치 포트의 특성을 설정하기 위해 사용한다.
- `상태 읽기` : 이 메시지는 컨트롤러가 스위치 플로우 테이블과 포트로부터 통계 정보와 카운터값을 얻기 위해 사용한다.
- `패킷 전송` : 이 메시지는 컨트롤러가 제어하는 스위치의 지정된 포트에서 특정 패킷을 내보내기 위해 사용한다.
  이 메시지 자체는 페이로드 부분에 보낼 패킷을 포함한다.

SDN으로 제어되는 **스위치에서 컨트롤러로 전달되는** 주요 메시지는 다음과 같다.

- `플로우 제거` : 이 메시지는 컨트롤러에게 어떤 플로우 테이블 엔트리가 시간이 만료되었거나 **상태 수정** 메시지를 수신한 결과로 삭제되었음을 알린다.
- `포트 상태` : 이 메시지는 스위치가 컨트롤러에게 포트의 상태 변화를 알리기 위해 사용된다.
- `패킷 전달`
  - 4.4절에서 스위치 포트에 도착한 패킷 중에서 플로우 테이블의 어떤 엔트리와도 일치하지 않는 패킷은 처리를 위해 컨트롤러에게 전달된다고 했다.
  - 어떤 엔트리와 일치한 패킷 중에서도 일부는 그에 대한 작업을 수행하기 위해 컨트롤러에게 보내지기도 한다.
    이 메시지는 그러한 패킷을 컨트롤러에게 보내기 위해 사용한다.

아래 그림은 SDN의 제어를 받는 스위치와 SDN 컨트롤러 간의 상호작용에 대한 것이다.

- 여기서는 다익스트라 알고리즘이 최단 경로를 결정하기 위해 사용되는데,
  다익스트라 알고리즘은 **패킷 스위치 외부에서** 별도의 애플리케이션으로 수행된다.

- 패킷 스위치들이 **링크 갱신 정보를** 서로 간이 아닌 **SDN 컨트롤러에게 전송한다.**

- 최단 경로 알고리즘이 사용되고 있다.
- `스위치 s1과 s2 사이의 링크가 단절되었다`고 가정해보자.
  - 따라서 s1, s3, s4로 들어오고 나가는 플로우 포워딩 규칙은 변경되었으나, s2의 동작은 바뀌지 않았다고 가정한다.
- 통신 계층 프로토콜로는 OpenFlow가 사용된다.
- 제어 평면은 링크 상태 라우팅 외의 기능은 수행하지 않는다.

1. **스위치 s2와의 링크 단절을 감지한 s1**은 OpenFlow의 `포트 상태 메시지`를 사용하여 링크 상태의 변화를 SDN 컨트롤러에게 알린다.

2. 링크 상태 변화를 알리는 OpenFlow 메시지를 받은 `SDN 컨트롤러`는 링크 상태 관리자에게 알리고,
   `링크 상태 관리자`는 링크 상태 데이터베이스를 갱신한다.

3. 다익스트라 링크 상태 라우팅을 담당하는 `네트워크 제어 애플리케이션`은 링크 상태의 변화가 있을 경우 알려달라고 이전에 등록해두었다.
   이 애플리케이션이 링크 상태의 변화에 대한 알림을 받게 된다.

4. `링크 상태 라우팅 애플리케이션`이 링크 상태 관리자에게 요청하여 **갱신된 링크 상태**를 가져온다.

   - 이 작업은 상태 관리 계층에 있는 다른 구성 요소의 도움이 필요할 수도 있다.
   - **그 후 새로운 최소 비용 경로를 계산한다.**

5. 링크 상태 라우팅 애플리케이션은 갱신되어야 할 플로우 테이블을 결정하는 플로우 테이블 관리자와 접촉한다.

6. `플로우 테이블 관리자`는 OpenFlow 프로토콜을 사용하여 **링크 상태 변화에 영향을 받는 스위치들의 플로우 테이블을 갱신한다.**
   - 이 예에서는 s1, s2, s4가 이에 해당한다.
   - s1 : 이제부터 s2를 목적지로 하는 패킷을 s4로 보낸다.
   - s2 : 이제부터 s1로부터의 패킷을 중간 스위치 s4를 통해 받는다.
   - s4 : s1에서 s2로 가는 패킷을 전달해야 한다.

> 💡 컨트롤러가 플로우 테이블을 마음대로 변경할 수 있기 때문에
> 단순히 애플리케이션 제어 소프트웨어를 바꿈으로써 원하는 어떤 형태의 포워딩 방식도 구현할 수 있다.


SDN이 많은 관심을 받게 된 것은 비교적 최근의 현상이지만,
SDN의 기술적인 뿌리, 특히 데이터와 제어 평면의 분리를 상당히 거슬러 올라간다.

- 2004년에 [Feamster 2004, Lakshman 2004, RFC 3746]은 모두 **네트워크 데이터와 제어 평면의 분리**를 주장했다.

- `에탄(Ethane) 프로젝트[Casado 2007]`는
  (1) ‘매치 플러스 액션’ 플로우 테이블이 있는 간단한 플로우 기반 이더넷 스위치,
  (2) 플로우 수용 및 라우팅을 관리하는 중앙 집중식 컨트롤러,
  (3) 그리고 플로우 테이블의 어떤 엔트리와도 일치하지 않는 **패킷을 스위치에서 컨트롤러로 전달하는 개념**을 개척했다.

  - 300개 이상의 에탄 스위치로 구성된 네트워크가 2007년에 운영되었다.
  - 에탄은 OpenFlow 프로젝트로 빠르게 진화했다.


SDN 혁명은 ‘`단순한 상용 스위칭 하드웨어와 정교한 소프트웨어 제어 평면`’으로
’모든 기능이 하나로 통합된 스위치와 라우터(데이터 및 제어 평면 모두)’를 교체해나가고 있다.

`네트워크 기능 가상화(network functions virtualization, NFV)`로 알려진 **SDN의 일반화**는 단순한 상용 서버, 스위칭 및 저장소를 가지고
복잡한 미들박스(전용 하드웨어 및 미디어 캐싱/서비스를 위한 고유의 소프트웨어를 가진 미들박스)를 혁신적으로 교체하는 것을 목표로 한다.

연구의 중요한 두 번째 영역은 SDN 개념을 AS 내부 설정에서 **AS 간 설정으로 확장**하려는 것이다.

일부 SDN 컨트롤러는 특정 회사를 위한 고유 제품이다.

그러나 더 많은 컨트롤러는 오픈소스이며 다양한 프로그래밍 언어로 구현된다.

가장 최근에는 `OpenDaylight 컨트롤러`와 `ONOS 컨트롤러`가 산업계에서 상당한 지지를 얻었다.

이 둘은 모두 오픈소스이며, 리눅스 재단(Linux Foundation)과 공동으로 개발 중이다.


아래 그림은 `ODL(OpenDaylight) 컨트롤러 플랫폼[OpenDaylight 2020, Eckel 2017]`의 간략한 구조다.

- ODL의 기본 네트워크 서비스 기능들은 컨트롤러의 핵심부에 있다.

- `서비스 추상 계층(Service Abstraction Layer, SAL)`

  - 컨트롤러 구성요소와 애플리케이션이 서로의 서비스를 호출하고 그들이 생성한 이벤트에 대한 알림을 받을 수 있도록 한다.
  - OpenFlow와 SNMP(Simple Network Management Protocol) 및 NETCONF(Network Configuration) 같은,
    ODL 컨트롤러와 제어 장치 간 프로토콜들에게 **균일한 추상 인터페이스**를 제공한다.

- `OVSDB(Open vSwitch Database Management Protocol)`는 **데이터 센터 스위칭**을 관리하는 데 사용된다.
  _(데이터 센터 네트워킹에 대해서는 6장에서 다룸)_

가장 상단의 `네트워즈 조정 및 애플리케이션`부는
데이터 평면의 포워딩과 방화벽 및 로드 밸런싱 같은 **서비스들이 제어 장치에서 어떻게 수행될지를 결정한다.**

아래 그림은 `ONOS 컨트롤러[ONOS 2020]`를 간략화한 모습이다.

표준 컨트롤러와 유사하게 3개의 계층을 구분할 수 있다.

1. `노스바운드` 추상화 프로토콜

   - ONOS는 의도(intent) 프레임워크이다.
     - 이는 애플리케이션이 해당 서비스가 구체적으로 어떻게 구현되는지 몰라도
       높은 수준의 서비스(e.g., 어떤 호스트 A와 B 사이의 연결을 설정)를 요청할 수 있게 해준다.
   - 상태 정보가 노스바운드 API를 통과하여
     네트워크 제어 애플리케이션에게 동기적(직접 질의를 통해) 또는 비동기적(e.g,. 네트워크 상태가 변화했을 때 알림 기능)으로 제공된다.

2. `분산 코어`

   - 네트워크 링크, 호스트, 장치의 상태는 ONOS의 분산 코어에 유지된다.
   - ONOS 코어는 서비스 복제와 인스턴스 간 협력 메커니즘을 제공함으로써
     상부의 애플리케이션과 하부의 네트워크 장치에게 논리적 중앙 집중형 코어 서비스의 추상화를 제공한다.

3. `사우스바운드` 추상화와 프로토콜
   - 사우스바운드 추상화는 하부의 호스트, 링크, 스위치, 프로토콜의 이질성을 숨겨준다.
   - 따라서 분산 코어가 장치나 프로토콜 종류에 상관없이 동작할 수 있다.
   - 이 추상화 때문에 분산 코어 아래의 사우스 바운드 인터페이스는 표준 컨트롤러나 ODL 컨트롤러보다 논리적으로 높다.


`인터넷 제어 메시지 프로토콜(Internet Control Message Protocol, ICMP)`은 호스트와 라우터가 서로 간에 네트워크 계층 정보를 주고받기 위해 사용된다.

ICMP는 종종 IP의 한 부분으로 간주되지만, ICMP 메시지가 IP 데이터그램에 담겨 전송되므로 **구조적으로는 IP 바로 위에 있다.**

즉, ICMP 메시지도 **IP 페이로드로 전송되며,**
호스트가 상위 계층 프로토콜이 ICMP라고 표시된(상위 계층 프로토콜 번호가 1번인) IP 데이터그램을 받으면 ICMP로 내용을 역다중화한다.

ICMP 메시지는 `타입(type)과 코드(code) 필드`가 있고,
ICMP 메시지의 발생 원인이 된 IP 데이터그램의 헤더와 첫 8바이트를 갖는다.

이는 송신자가 오류를 발생시킨 패킷을 알 수 있도록 하기 위해서이다.

중요한 ICMP 메시지 타입들은 다음과 같다

> 💡 ICMP 메시지는 오류 상태를 알리기 위해서만 사용되는 것이 아니다.

1. `타입 8, 코드 0인 ICMP 메시지`를 특정 호스트에 보낸다.
2. 목적지 호스트는 에코 요청을 보고 나서 `타입 0, 코드 0인 ICMP 에코 응답`을 보낸다.

대부분의 TCP/IP 구현은 ping 서버를 운영체제에서 직접 지원한다.
(즉, ping 서버는 별도의 프로세스가 아님)


이 메시지의 원래 목적은 혼잡 제어를 수행하기 위한 것이다.

즉, **혼잡이 발생한 라우터가 호스트의 전송 속도를 늦추도록** `ICMP 출발지 억제 메시지`를 해당 호스트에 보낸다.

하지만 우리는 앞서 TCP가 ICMP 출발지 억제 메시지와 같은 네트워크 계층의 피드백 없이도
전달 계층에서 동작하는 자신만의 혼잡 제어 메커니즘을 갖고 있음을 보았고, 이에 이 메시지는 실제로는 잘 사용되지 않는다.

아래의 방식으로 출발지 호스트는 자신과 목적지 호스트 사이에 있는 라우터들의 수와 정체, 그리고 두 호스트 간의 왕복 시간을 알게 된다.

1. **출발지와 목적지 사이의 라우터 이름과 주소를 알아내기 위해**
   출발지의 Traceroute는 일련의 `IP 데이터그램`을 목적지에 보낸다.

   - 각각의 데이터그램은 UDP 포트 번호를 가진 **UDP 세그먼트**를 운반한다.
   - TTL 값은 첫 번째 데이터그램이 1, 두 번째는 2, 세 번째는 3, 이런 식이다.

2. 출발지는 각 데이터그램에 대해 타이머를 작동시킨다.

   - n번째 데이터그램이 n번째 라우터에 도착하면 해당 라우터는 데이터그램의 TTL이 방금 만료되었음을 알게 된다.

3. IP 프로토콜 규칙에 따라 라우터는 데이터그램을 폐기하고 `ICMP 경고 메시지(타입 11, 코드 0)`를 출발지에 보낸다.

   - 이 경고 메시지는 라우터의 이름과 IP 주소를 포함한다.

4. 이 ICMP 메시지가 출발지에 도착하면, 출발지는
   (1) 타이머로부터 왕복 시간(round-trip time, RTT),
   (2) ICMP 메시지로부터 n번째 라우터의 주소와 이름을 획득한다.

_Traceroute 출발지는 UDP 세그먼트 전송을 언제 멈춰야 하는지 어떻게 알까?_

1. 출발지가 자신이 보내는 각 데이터그램마다 차례로 TTL을 1씩 증가시키기 때문에
   이들 데이터그램 중 하나는 결국 목적지 호스트에 도착하게 될 것이다.

2. 이 데이터그램은 없을 것 같은 UDP 포트 번호를 가진 UDP 세그먼트를 포함하고 있으므로,
   목적지 호스트는 `포트 도달 불가능 ICMP 메시지(타입 3, 코드 3)`를 출발지에 보낸다.

3. 출발지 호스트가 이 ICMP 메시지를 받게 되면 추가적인 탐색 패킷을 보낼 필요가 없음을 알게 된다.


`네트워크 관리`란 무엇인가?

[Saydam 1996]에는 이에 대해 잘 정리된, 한 문장으로 된 정의가 나온다.

> 네트워크 관리는 적정한 비용으로 실시간, 운용 성능, 서비스 품질 등의 요구사항을 만족시키기 위해
> 네트워크와 구성요소 자원을 감시, 테스트, 폴링, 설정, 분석, 평가, 제어하는
> 하드웨어, 소프트웨어, 인간 요소 등을 배치하고, 통합, 조정하는 것이다.

이 절에서는 이 광범위한 정의 중에서 네트워크 관리의 기초,
즉 네트워크 관리자가 자신의 일을 수행하는 데 사용하는 구조, 프로토콜, 데이터만을 다룬다.

아래 그림은 네트워크 관리의 핵심 요소들을 나타낸다.


> 관리 서버는
> `네트워크 운영 센터(network operations center, NOC)`의 중앙 집중형 네트워크 관리 스테이션에서 동작하는,
> 일반적으로 `네트워크 관리자(network managers, 사람)`**와 상호작용하는 애플리케이션이다.**

- 네트워크 관리 활동이 일어나는 장소로서 네트워크 관리 정보의 수집, 처리, 분석, 발송을 제어한다.
- 여기서 네트워크의 피관리 장치를 설정, 감시, 제어하기 위한 작업이 시작된다.
- 하나의 네트워크는 여러 개의 관리 서버를 가질 수 있다.

> 피관리 장치는 관리 대상 네트워크에 존재하는 네트워크 장비(소프트웨어 포함)들이다.

- e.g., 호스트, 라우터, 스위치, 미들박스, 모뎀, 온도계, 그 외 네트워크에 연결된 그 밖에 장치들
- 이 장치들은 많은 **관리 가능한 요소들**(e.g,. 네트워크 인터페이스 카드는 호스트나 라우터의 구성요소)과
  이러한 **하드웨어 및 소프트웨어 요소에 대한 설정 매개변수들**(e.g., OSPF와 같은 AS 내부 라우팅 프로토콜)을 갖는다.


> 각 피관리 장치는 ‘`상태(state`)’라고 부르는, 장치와 관련된 데이터를 갖는다.

데이터의 유형들

- `설정 데이터(configuration data)`

  - 장치 인터페이스에 관리자가 할당 및 설정한 장치 정보
  - e.g., IP 주소 또는 인터페이스 속도

- `동작 데이터(operational data)`

  - 장치가 동작하면서 획득하는 정보
  - e.g., OSPF 프로토콜의 인접 항목 목록

- `장치 통계(device statistics)`
  - 장치가 운영되면서 갱신되는 상태 표시기 및 계수기
  - e.g., 인터페이스에서 삭제된 패킷 수 또는 장치의 냉각 팬 속도

관리 서버는 네트워크 토폴로지 같은 전체 네트워크와 관련된 데이터뿐만 아니라
**관리 대상 장치들의 구성과 운영, 그리고 통계 데이터의 복사본도 유지 관리한다.**

> 네트워크 관리 에이전트는 관리 서버와 통신하는 피관리 장치상의 소프트웨어 프로세스다.

관리 서버의 명령과 제어에 따라 피관리 장치에 국한되는 행동을 취한다.


> 네트워크 관리 프로토콜은 관리 서버와 피관리 장치들 사이에서 동작하면서
> (1) 관리 서버가 피관리 장치의 상태에 대해 질의하고
> (2) 에이전트를 통해 피관리 장치에 행동을 취할 수 있도록 해준다.

에이전트는 예외적인 사건을 관리 서버에게 알리기 위해 네트워크 관리 프로토콜을 사용할 수 있다.
(e.g., 부품의 고장 또는 성능 임계치의 위반)

> 💡 네트워크 관리 프로토콜 스스로가 네트워크를 관리하지 않는다.

대신에 네트워크 관리자가 네트워크를 관리(감시, 테스트, 폴링, 설정, 분석, 평가, 제어)할 수 있도록 기능을 제공한다.

---

네트워크 운영자가 위의 구성요소들을 활용하여 네트워크를 관리할 수 있는, 흔히 사용하는 세 가지 방법이 있다.

> 네트워크 운영자는 `명령줄 인터페이스(Command Line Interaface, CLI)`를 통해 장치에 직접 명령을 보낼 수 있다.

이러한 명령은
(1) 운영자가 피관리 장치과 물리적으로 같은 공간에 있는 경우 피관리 장치의 콘솔에 직접 입력하거나
(2) 피관리 장치 사이의 텔넷(Telnet) 또는 SSH(secure shell) 연결을 통해 전달할 수 있다.

이 방법을 통해서는 대체로 오류가 발생하기 쉽고, 대규모 네트워크를 자동화하거나 효율적으로 관리하기 어렵다.


> 이 방식에서 네트워크 운영자는 `SNMP(Simple Network Management Protocol)`를 사용하여
> 장치의 `MIB(Management Information Base)`에 있는 데이터를 질의하거나 설정할 수 있다.

일부 MIB 데이터는 장치 및 공급업체에 따라 다르지만,

다른 MIB 데이터(e.g., IP 데이터그램 헤더의 오류 때문에 라우터에서 버려지는 IP 데이터그램의 개수, 호스트에서 수신하는 UDP 세그먼트 개수)는
**장치에 종속되지 않고 추상성과 일반성을 갖는다.**

일반적으로 네트워크 운영자는

1. 이 방식으로 동작 상태 및 장치 통계 정보를 질의 및 모니터링한 다음
2. 명령줄 인터페이스를 사용하여 장치를 실제로 제어하고 설정한다.

> 💡 CLI와 SNMP/MIB 모두 장치를 **개별적으로** 관리한다.

`SNMP/MIB`로도 장치 설정 및 대규모 네트워크 관리의 어려움이 존재한다.

이로 인해 `NETCONF`와 `YANG`을 사용하는 가장 최근의 네트워크 관리 방식이 나타났다.

> 이 방식은 네트워크 관리에 대해 좀 더 추상적이고 네트워크 전체를 아우르는 전체론적인 관점을 취하면서도,
> 정확성의 제약 정도를 구체화하고 여러 장치에 대한 세세한 관리 작업을 제공하는 등 설정 관리에 훨씬 더 중점을 둔다.

- `YANG` : 설정 및 동작 데이터를 모델링하는 데 사용되는 데이터 모델링 언어
- `NETCONF 프로토콜` : 원격 장치과 YANG 호환 작업 및 데이터를 주고받거나 원격 장치 간에 통신하는 데 사용됨


> `SNMPv3(Simple Network Management Protocol version 3)`는
> 관리 서버와 그 관리 서버를 대표하여 실행되고 있는 에이전트 사이에서 네트워크 관리 제어 및 정보 메시지를 전달하기 위해 사용된다.


이는 SNMP의 가장 흔한 사용 행태이다.

1. SNMP 관리 서버는 에이전트에게 `요청`을 송신하고
   - 일반적으로 요청은 피관리 장치과 관련된 MIB 객체 값들을 질의(검색) 또는 수정(설정)하기 위해 이용
2. 이를 받은 SNMP 에이전트는 이를 수행한 후 요청에 대한 `응답`을 보낸다.

SNMP의 두 번째로 일반적인 사용은
에이전트가 요구받지 않았더라도 `트랩 메시지`라는 이름의 메시지를 관리 서버에게 전송하는 것이다.

트랩 메시지들은 관리 서버들에게
MIB 객체 값들을 변화시킨 예외 사항(e.g., 링크 인터페이스의 활성 또는 비활성)의 발생을 통지하기 위해 이용된다.

---

아래 표는 SNMPv2에 대한 것이며, 일반적으로 `PDU(Protocol Data Unit)`으로 알려진 일곱 가지 타입의 메시지를 정의하고 있다.

- `GetRequest`, `GetNextRequest`, `GetBulkRequest` PDU들은 모두
  에이전트의 피관리 장치 내 하나 이상의 MIB 객체의 값을 요청하기 위해 **관리 서버로부터 에이전트로 전송된다.**

  - 이들은 데이터 요청들의 정밀도(granularity) 면에서 다르다.
  - 에이전트는 객체 식별자들과 그에 관련된 값들을 `Response` PDU에 담아 응답한다.

- `SetRequest` PDU는 관리 서버가 피관리 장치 안의 하나 또는 그 이상의 MIB 객체들의 값을 설정하기 위해 사용한다.

  - 에이전트는 값이 제대로 설정되었음을 알려주기 위해 ‘noError’라는 오류 상탯값을 `Response` PDU에 담아 응답한다.

- `SNMPv2-Trap`은 트랩 메시지로, 비동기적으로 발생한다.
  - 즉, 요청을 수신했을 때가 아니라 관리 서버가 통지를 요구한 이벤트가 발생했을 때 발생한다.
  - 수신된 트랩 요청은 관리 서버로부터 어떤 응답도 요구하지 않는다.

아래 그림은 SNMP PDU의 포맷을 나타낸 것이다.

---

> SNMP PDU들이 다른 많은 전송 프로토콜에 의해 운반될 수 있기는 하지만 **일반적으로는 UDP 데이터그램의 페이로드 부분에 실린다.**

그러나 UDP는 **신뢰성이 보장되지 않는** 전송 프로토콜이므로,
요청 또는 그에 대한 응답이 의도한 목적지에 도착한다는 보장이 없다.

따라서 아래처럼 `요청 ID 필드`는 관리 서버가 요청 또는 응답의 분실을 검출하는 데 이용될 수 있다.

- PDU의 요청 ID 필드는 관리 서버가 에이전트에 보내는 요청에 번호를 매기기 위해 사용된다.
- 에이전트의 응답은 수신된 요청으로부터 요청 ID 값을 취한다.


MIB 객체는 `SMI(Structure of Management Information, 관리 정보 구조)`라고 하는 데이터 기술 언어로 명세되는데,
_이 이름은 그 기능에 대한 아무런 힌트를 주지 않는 다소 엉뚱한 이름의 네트워크 관리 프레임워크 구성요소다._

`SMI`는 `SNMP`(네트워크 관리를 위해 관리 정보 및 정보 운반을 위한 프로토콜)에서 관리 정보의 구조를 말하며,
**MIB 객체를 정의하는 일반적인 규칙들의 모음**이다.

---

`MIB`는 **망관리 자원 정보를 구조화시킨, 대규모 관리 정보 집합**을 말한다.

앞에서 SNMP/MIB 방식의 네트워크 관리에서
**피관리 장치의 동작 상태 데이터가 해당 장치를 위한 MIB에 수집된 객체들로 표현된다**는 사실을 배웠다.

MIB 객체는 다음과 같은 정보일 수도 있다.

- IP 데이터그램 헤더의 오류로 인해 라우터에서 버려지는 데이터그램 개수
- 이더넷 엔터페이스 카드의 반송파 감지 오류 횟수를 세는 **카운터**
- DNS 서버에서 실행되는 소프트웨어 버전과 같은 **설명 정보**
- 특정 장치가 올바르게 작동하는지 여부와 같은 **상태 정보**
- 어떤 목적지로의 라우팅 경로 같은 프로토콜에 특정된 정보 등..

관련된 MIB 객체들은 MIB 모듈로 합쳐진다.


`NETCONF 프로토콜`은 관리 서버과 피관리 네트워크 장치 사이에서 동작하면서

1. 피관리 장치의 설정 데이터를 검색, 셋업, 수정하거나
2. 피관리 장치의 동작 데이터 및 통계를 질의하거나
3. 피관리 장치에서 생성된 알림을 구독하기 위한 메시지 전송 기능을 제공한다.

관리 서버는 피관리 장치를 제어하기 위해 **구조화된 XML 문서 형식의 설정 내용**을 보내 피관리 장치에서 활성화한다.

- NETCONF는 `원격 프로시너 호출(remote procedure call, RPC) 패러다임`을 사용한다.
- XML로 인코딩된 프로토콜 메시지는 TCP상의 `TLS(Transport Layer Security) 프로토콜`과 같은
  **안전한 연결 지향 세션**을 통해 관리 서버와 피관리 장치 사이에서 교환된다.

e.g., NETCONF `<get>` 명령

이 명령을 통해 서버는 장치의 설정에 대해 알 수 있다.

```xml
<?xml version="1.0" encoding="UTF-8"?>
<rpc message-id="101"
     xmlns="urn:ietf:params:xml:ns:netconf:base:1.0">
    <get/>
</rpc>
```

---

아래는 NETCONF 세션의 예다.

<p align="center"><img width="520" alt="NETCONF" src="https://user-images.githubusercontent.com/86337233/213753150-51b2a371-d411-44a2-bba2-98cd5f379c0a.jpg">

1. 관리 서버는 피관리 장치와 보안 연결을 설정한다.

2. 보안 연결이 설정되면 관리 서버와 피관리 장치는 `<hello>` 메시지를 교환하고,
   기본 NETCONF 명세를 보완하는 어떠한 추가 ‘기능’이 있는지를 알린다.

3. 관리 서버와 피관리 장치 간의 상호작용은 `<rpc>`와 `<rpc-reply>` 메시지를 사용하는 원격 프로시저 호출 형식을 갖는다.

   - 이러한 메시지는 장치 설정 데이터와 동작 데이터 및 통계를 검색, 설정, 질의, 수정하고 장치의 알림을 구독하는 데 사용된다.

4. `<close-session>` 메시지로 세션을 종료한다.

아래 표는 관리 서버가 피관리 장체에서 수행할 수 있는 여러 가지 중요한 NETCONF 작업을 보인다.

> `YANG`은 NETCONF가 사용하는 네트워크 관리 데이터의 구조, 구문 및 의미를 정확하게 표현하는 데 사용되는 **데이터 모델링 언어**다.

모든 YANG 정의는 모듈에 포함되고, 장치와 해당 기능을 설명하는 XML 문서는 YANG 모듈에서 생성할 수 있다.


링크 계층 프로토콜을 실행하는 장치

e.g. 호스트, 라우터, 스위치, AP(access point, 7장에서 설명) 등


통신 경로상의 인접한 노드들을 연결하는 통신 채널

데이터그램을 출발지 호스트에서 목적지 호스트로 이동시키기 위해서는 데이터그램을 종단 간 경로의 개별 링크들로 이동시켜야만 한다.

한 링크에서 전송 노드는 데이터그램을 `링크 계층 프레임(link-layer frame)`으로 캡슐화해서 링크로 전송한다.

위 그림에서는 6개의 링크를 거쳐간다.

- `프레임화(framing)`
  - 데이터그램을 링크상으로 전송하기 전에 링크 계층 프레임에 캡슐화한다.
  - 프레임은 데이터그램이 들어있는 데이터필드와 여러 개의 헤더 필드로 구성된다.
- `링크 접속(link access)`
  - `매체 접속 제어(medium access control, MAC)` 프로토콜은 링크상으로 프레임을 전송하는 규칙을 명시한다.
  - 단일 송신자와 단일 수신자의 점대점 링크에서의 `MAC`은 단순하며, 링크가 사용되지 않을 때마다 프레임을 전송할 수 있다.
  - 하나의 브로드캐스트 링크를 여러 노드가 공요하는 경우, MAC 프로토콜은 여러 노드로부터의 프레임 전송을 조정한다.
- `신뢰적 전달`
  - `TCP`와 마찬가지로 확인 응답과 재전송을 통해 서비스를 제공한다.
  - `TCP`에서는 종단 간에 데이터를 재선송 하는 것과는 달리 링크 계층 프로토콜은 오류가 발생한 링크에서 오류를 정정한다.
  - 무선 링크와 같은 높은 오류율을 가진 링크에서 주로 사용되며, 낮은 비트 오류율을 가진 링크에서는 불필요한 오버헤드가 될 수 있어 대다수 유선 링크 계층 프로토콜은 제공하지 않는다.
- `오류 검출과 정정`
  - 신호의 약화나 전자기 잡음 때문에 전송된 프레임 비트를 반대로 오인할 수 있다.
  - 오류가 있는 데이터그램은 전달할 필요가 없으므로 대부분의 링크 계층 프로토콜은 오류를 검출하는 방법을 제공한다.
  - 송신 노드에서 오류 검출 비트를 설정하게 하고 수신 노드에서 오류 검사를 수행하게 함으로써 가능해진다.
  - 트랜스포트 계층과 네트워크 계층의 오류 검출보다 일반적으로 더 복잡하며, 하드웨어로 구현된다.
  - 오류 정정은 오류 검출과 비슷하지만 프레임의 어느 곳에서 오류가 발생했는지 정확하게 찾아낼 수 있다.


호스트에서 대부분의 경우 링크 계층은 `네트워크 인터페이스 컨트롤러(network interface controller, NIC)`로 알려진 `네트워크 어댑터(network adapter)` 에 구현된다.

(라우터에서는 4장에서 봤듯이 라인 카드에 구현된다.)

`네트워크 어댑터`의 중심에 있다.

링크 계층 서비스의 대다수가 구현되어있는 단일의 특수 용도 칩으로 하드웨어로 구현된다.

송신 측의 컨트롤러는 호스트 메모리에 저장된 데이터그램을 링크 계층 프레임으로 캡슐화한 후 링크 접속 프로토콜에 따라 이 프레임을 통신 링크상으로 전송한다.

수신 측의 컨트롤러는 프레임을 수신한 후 네트워크 계층 데이터그램을 추출한다.


일부 링크 계층 기능이 호스트 `CPU`에서 실행되는 소프트웨어에 구현되어 있다.

상위 레벨의 링크 계층 기능은 링크 계층 소프트웨어 구성요소에 구현되어 있다.

e.g. 링크 계층 주소 정보 조립, 컨트롤러 하드웨어 활성화, 컨트롤러로부터의 인터럽트, 오류 처리, 데이터그램 전달 등

즉, **링크 계층은 하드웨어와 소프트웨어의 조합**이다.

비트 오류를 방지하기 위해 송신 노드에서 `데이터 D`에 `오류 검출 및 정정 비트들(EDC)`를 첨가한다.

송신되는 `데이터 D`와 `EDC`는 전송 도중 변경될 수 있다.

즉, 수신자는 변경의 가능성이 있는 비트로 오류 검출 여부를 확인하여야 한다.

오류 검출 및 정정 기술을 사용하더라도 여전히 미검출된 비트 오류(undetected bit error)가 있을 수 있다.

즉, 수신자는 잘못된 데이터그램을 네트워크 계층으로 전달할 수 있고, 프레임 헤더의 다른 필드의 내용이 잘못된 것을 모를 수도 있다.

따라서 오류를 감지하지 못할 확률이 낮은 기법을 선택해야한다. (대체로 확률이 낮을 수록 오버헤드가 크다.)


데이터 D가 d개의 비트를 갖고 있다고 가정하자.

짝수 패리티 기법에서는 단순히 D에 한개의 `Parity bit`를 추가하고, d+1개의 비트에서 1의 총개수가 짝수가 되도록 `Parity bit` 을 선택한다.

수신자는 수신된 d+1개의 bit에서 1의 개수가 짝수임을 확인한다.

(당연히 홀수라면 1의 개수를 홀수로 정한다.)

이 방법의 경우 홀수개의 비트 오류는 검출할 수 있지만 짝수개의 비트 오류는 검출할 수 없다.

측정에 의하면 오류는 종종 버스트(burst)의 형태로 몰려서 발생하기 때문에 위 방법은 50% 확률로 오류를 검출할 수 있다.


데이터 D에 있는 d 비트들은 i개의 행과 j개의 열로 나뉜다.

나뉜 각각의 행과 열에 대해 하나의 패리티 값이 계산된다.

2차원 패리티 기법에서는 반전된 비트를 포함하는 열과 행에 대한 패리티에 오류가 생긴다.

따라서 수신자는 단일 비트의 **오류 발생을 검출할 수 뿐만 아니라 열과 행의 인덱스 값을 통해 오류를 정정**할 수도 있다.

또, 단일 패리티와는 달리 임의의 2개의 오류도 검출할 수 있다. (그러나 정정할 수 없다.)

오류를 검출 및 정정하는 수신자의 능력을 `FEC`라고한다.

`FEC` 기술은 송신자에게 요구하는 재전송 횟수를 줄일 수 있다.

이를 통해 NAK 패킷을 수신하고 재전송된 패킷이 수신자로 되돌아가는 소요 시간이 왕복 지연 시간을 기다릴 필요가 없어진다.


d 비트들을 k 비트 정수처럼 다루어 이 k비트 정수들을 더해서 그 결괏값을 오류 검출 비트들로 사용한다.

`인터넷 체크섬(Internet checksum)`

1. 더한 값의 1의 보수가 인터넷 체크섬이 되며, 이것을 세그먼트 헤더에 넣어준다.
2. 수신자는 수신 데이터 합의 1의 보수를 취한 후 그 결과가 모두 1인 비트로 구성되어 있는지 계산함으로써 체크섬을 검사한다.
3. 그 결과가 모두 1인 비트로 구성되어 있는지 계산함으로써 체크섬을 검사한다.

체크섬 방법은 상대적으로 패킷 오버헤드가 적어 `TCP`와 `UDP`에서 사용된다. 그러나 `순환 중복 검사(CRC)`와 비교하면 오류면에서 취약하다.

`TCP`와 `UDP`에서 사용하는 이유는 `TCP`와 `UDP`는 소프트웨어로 구현되어 간단하고 빠른 오류 검출 기법이 필요한 반면 링크 계층은 네트워크 어댑터 안에 하드웨어로 구현되어 `순환 중복 검사(CRC)` 를 사용한다.


_오늘날 컴퓨터 네트워크에서 널리 사용되는 오류 검출 기술은 `순환 중복 검사(cyclic redundancy check, CRC) 코드` 를 사용한다._

CRC 코드는 전송되는 비트열에 있는 0과 1 값을 계수로 갖는 다항식처럼 비트열을 생각할 수 있고, 또한 비트열에 적용되는 연산을 다항식 연산으로 이해하는 것이 가능하기 때문에 `다항식 코드(polynomial code)`로도 알려졌다.

1. 먼저 송신자와 수신자는 G로 표기되는 생성자로 알려진 r+1 비트 패턴에 대해 합의한다. 이때 G의 최상위 비트는 1이어야 한다.
2. 송신자는 D에 r개의 추가 비트 R을 선택해서 D 뒤에 덧붙인다.
   - 일반 이진 연산에서 2^k을 곱하는 것은 비트 패턴을 k개의 위치만큼 왼쪽으로 이동하는 것과 같다. 즉, 위 그림의 식을 통해 d+r 패턴을 만들 수 있다.
   - 만들어진 d+r 비트 패턴은 모듈로 2 연산을 이용하면 G로 정확히 나누어진다.
3. 수신자는 d+r개의 수신 비트를 G로 나눈다. 만일 나머지가 0이 아니면 오류가 발생한 것이다.

모든 CRC 검사는 덧셈의 올림이나 뺄셈의 빌림이 없는 모듈로 2 연산을 사용한다.

즉, **이는 피연산자를 비트별로 XOR한 것과 같다.**

e.g.

```
1011 XOR 0101 = 1110
1001 XOR 1101 = 0100

1011 - 0101 = 1110
1001 - 1101 = 0100
```


먼저 다음과 같은 식을 만족하는 n이 있도록 하는 R을 구해야한다.

```
D x 2^r XOR R = nG
```

즉, `D x 2^r XOR R`을 나머지 없이 G로 나눌 수 있도록 R을 선택해야 한다. 이 식의 양쪽에 R을 XOR(즉, 올림 없는 모듈로 2 덧셈)하면 다음과 같다.

```
D x 2^r = nG XOR R
```

이 식은 `D x 2^r` 을 G로 나누면 나머지가 정확히 R이 되는 것을 뜻한다.

다시 말해, 다음 처럼 R을 계산할 수 있다.

```
R = 나머지 D x 2^r / G
```

e.g.

국제 표준으로는 8비트, 12비트, 16비트, 32비트의 생성자 G가 정의되어 있다.

각각의 CRC 표준은 r개 이하의 연속적인 비트 오류를 모두 검출할 수 있다.


- `점대점 링크(point-to-point link)`
  - 링크의 한쪽 끝에 한 송신자와 링크의 다른 쪽 끝에 한 수신자가 있다.
  - `PPP(point-to-point protocol)`과 `HDLC(high-level data link control)`이 여기에 속한다. (뒤에 다룬다.)
- `브로드캐스트 링크(broadcast link)`
  - 동일한 하나의 공유된 브로드캐스트 채널에 다수의 송신 노드 및 수신 노드가 연결된다.
  - 임의의 한 노드가 프레임을 전송하면 채널이 그 프레임을 브로드캐스트해서 다른 모든 노드가 그 프레임의 복사본을 수신하기 때문에 브로드캐스트 용어가 쓰인다.


모든 노드가 프레임을 전송할 수 있으므로 2개 이상의 노드가 브로드캐스트 채널에서 직접 통신할 수 있고, 이런 일이 발생하면 **모든 노드는 동시에 여러 개의 프레임을 받게 된다.**

즉, **전송된 프레임들이 각 수신자에서 충돌하게 되고 어떤 수신 노드도 전송된 프레임의 의미를 파악할 수 없게 된다.**

따라서 충돌에 관련된 모든 프레임은 손실되며, 다수의 노드가 빈번히 프레임을 전송하려 한다면 많이 충돌할 것이고 따라서 브로드캐스트 채널의 대역폭이 많이 낭비된다.

초당 R 비트의 전송률을 갖는 브로드캐스트 채널에 대한 다중 접속 프로토콜은 다음과 같은 특성을 지니는 것이 바람직하다.

1. 단 하나의 노드가 전송할 데이터가 있을 때는 그 노드가 R bps의 처리율을 갖는다.
2. M개의 노드가 전송할 데이터가 있을 때는 각 노드가 R/M bps의 처리율을 갖는다.
   - 항상이 아니며 각 노드가 정의된 시간 동안 R/M의 평균 처리율을 가짐을 의미한다.
3. 분산되어 있어 고장으로 인해 전체 시스템을 정지시킬 수 있는 마스터 노드가 없다.
4. 단순해서 구현하는 데 비용이 적게 든다.


채널이 N개 노드를 지원하고 채널 전송률이 R bps라고 하자.

TDM은 시간을 `시간 프레임(time frame)`으로 나누고 또한 각 시간 프레임을 N개의 `시간 슬롯(time slot)`으로 나눈다.

그 후 N개의 노드에게 시간 슬롯을 각각 할당한다.

노드는 전송할 패킷이 있을 때마다 **TDM 프레임에서 자신에게 할당된 시간 슬롯 동안 패킷을 전송**한다.

**장점**

- 충돌을 제거할 수 있다.
- 매우 공정하다.

**단점**

- 전송할 패킷이 있는 노드가 단 하나인 경우에도 노드 전송률이 R/N으로 제한된다.
- 노드가 전송 순서상 자신의 차례를 항상 기다려야 한다.


R bps의 채널을 R/N의 대역폭을 갖는 다른 주파수로 나눠서 각 주파수를 N개의 노드 중 하나에게 할당한다.

즉, 하나의 큰 R bps 채널로부터 N개의 R/N bps의 작은 채널을 만든다.

TDM과 같은 장단점을 갖는다.

CDMA는 다른 **코드**를 각 노드에게 할당한다.

노드는 **전송하는 데이터 비트들을 자신의 유일한 코드로 인코딩**한다.

**장점**

- CDMA 네트워크에서 코드들을 신중하게 선택하면 여러 노드들이 동시에 전송할 수 있다.
- 다른 노드들에 의해 전송이 간섭되더라도 각 수신자들이 송신자의 인코딩된 데이터 비트를 정확하게 수신할 수 있다.


랜덤 접속 프로토콜에서 전송 노드는 항상 채널의 최대 전송률인 R bps로 전송한다.

충돌이 생기면 충돌과 관련된 각 노드는 프레임이 충돌 없이 전송될 때까지 자신의 프레임을 계속해서 재전송한다.

프레임이 충돌했을 때 즉시 재전송하지 않고, 랜덤 지연 시간 동안 기다린 후 재전송 한다.

즉, 출동했던 노드 중 하나는 다른 노드가 선택한 지연 시간보다 충분히 작은 지연시간을 선택함으로써 충돌 없이 자신의 프레임을 채널로 전송할 수 있다.

**동작 과정**

1. 전송할 새 프레임이 있으면 다음 슬롯이 시작할 때까지 기다렸다가 그 슬롯에 전체 프레임을 전송한다.
2. 만약, 충돌하지 않으면 노드는 성공적으로 자신의 프레임을 전송한 것이다. 따라서 그 프레임을 재전송할 필요가 없다.
3. 만약 충돌하면, 노드는 그 슬롯이 끝나기 전에 충돌을 검출한다. 노드는 그 프레임이 충돌 없이 전송될 때까지 확률 p(0~1 사이)로 해당 프레임을 다음 슬롯들에서 재전송한다.
4. 충돌하지 않을 때까지 3번 과정을 반복한다.

**장점**

- 하나의 활성노드로 하여금 채널의 전속력 R로 계속해서 프레임을 전송할 수 있도록 허용한다.
- 노드가 충돌을 감지하고 언제 재전송할지 각자 결정하므로 분산되어있다.
- 매우 단순하다.

**단점**

- 노드는 슬롯이 언제 시작하는지 동기화되어있어야 한다.
- 활성 노드가 많이 있으면 일부 슬롯이 충돌로 인해 결과적으로 낭비 된다.
- 모든 활성 노드가 확률적인 전송 정책 때문에 전송을 억제하는 경우 일부 슬롯이 비게 된다.

낭비되지 않는 슬롯은 정확히 한 노드만 전송하는 슬롯이고, 이 노드를 `성공한 슬롯(successful slot)`이라 한다.

**효율성**

노드가 N개가 있을 때 하나의 슬롯이 성공적인 슬롯일 확률은 노드들 중 한 노드만 전송하고 나머지 N-1 개의 노드는 전송하지 않는 확률이다.

노드가 전송할 확률이 p라하면 해당 노드가 성공할 확률은 `p x (1-p)^(N-1)` 이다.

노드가 N개 있으므로 임의의 한 노드가 성공할 확률은 `N x p x (1-p)^(N-1)` 이다.

최대의 효율을 구하기 위해서는 이 식을 최대화 하는 p를 구해야 한다.

활성 노드가 많은 경우의 최대 효율을 구하기 위해 N이 무한대가 될 때의 극한값을 취한다.

이렇게 계산하면 최대 효율은 `p = 1/e = 0.37` 임을 알 수있다.

**즉, 많은 노드가 전송할 프레임이 많을 때 기껏해야 37%의 슬롯만 낭비되지 않는다.**


순수 알로하 프로토콜에서는 슬롯 개념이 없다.

**동작 과정**

1. 프레임이 도착하면 노드는 즉시 프레임 전체를 브로드캐스트 채널로 전송한다.
2. 만약 충돌하면, 노드는 확률 p로 즉시 재전송 한다.
3. 즉시 재전송하지 않는 경우, 노드는 프레임 전송 시간 동안 기다린다.
4. 기다리고 나서 확률 p로 전송하거나 아니면 1-p 확률로 또 다른 프레임 시간 동안 기다린다.

**효율성**

임의의 시점에 노드가 프레임을 전송할 확률은 p다.

시간 t0에 프레임 전송을 시작한다고 가정하자.

이 프레임이 성공적으로 전송되기 위해서는 `[t0-1,t0]` 동안 다른 노드들이 전송을 해서는 안된다. 만일 전송을 하게 되면 노드 i가 전송 시작 부분과 겹쳐 충돌하게 된다.

이 시간동안 다른 모든 노드가 전송을 시작하지 않을 확률은 `(1-p)^(N-1)` 이다.

마찬 가지로 노드 i가 전송하는 동안에 다른 노드가 전송을 시작해서는 안되고, 이 확률 또한, `(1-p)^(N-1)` 이다.

즉, 성공적으로 전송할 확률은 i가 전송 할 확률 p 를 포함해서 `p x (1-p)^(2(N-1))` 이다. 슬롯 알로하처럼 극한값을 취하면 최대 효율은 `p = 1/2e` 로 슬롯 알로하의 절반이다.

즉, 순수 알로하는 완전히 분산되어 동기화하는 것을 안하는 대신, 효율성을 포기한다.

위 두 프로토콜에서는 다른 노드가 전송하고 있건 말건 일단 보낸다.

즉, 충돌이 생기고 결과적으로 효율이 떨어진다.

이러한 충돌을 없애기 위한 규칙을 보자.

- 캐리어 감지(carrier sensing)
  - 만일 다른 노드가 프레임을 채널로 전송하고 있는 경우, 노드는 임의의 짧은 시간 동안 전송 중단을 감지하면 프레임을 전송하기 시작한다.
- 충돌 검출(collision detection)
  - 만일 다른 노드가 방해 프레임을 전송하고 있음을 검출하면, 자신의 전송을 중단하고 랜덤 시간 동안 기다린 후 유휴 시 감지 및 전송과정을 반복한다.

**CSMA에서 충돌이 발생하는 경우**

1. 시각 t0에 노드 B가 다른 노드가 아무도 전송하고 있지 않으므로 채널이 비어 있는 것으로 감지한다.
2. B는 전송을 시작하고, 전송한 비트들이 브로드캐스트 매체를 따라 양방향으로 전송된다.
   - 시간이 경과함에 따라 아래쪽으로 전파되는 것은 B의 비트들이 실제로 브로드캐스트 매체로 전파할 때 0보다 큰 시간이 필요하다는 것을 의미한다.
3. D가 t1 시점에 전송할 프레임이 생겼고, 노드 B가 t1에 전송을 하고 있음에도 불구하고, B에 의해 전송되는 비트들은 D에 도달하지 못했고, 따라서 D는 t1일 때 채널이 사용되지 않는 것으로 감지한다.
4. D가 전송을 시작하고, 약간의 시간 후에 B가 전송한 비트와 D의 전송한 비트가 간섭을 일으키기 시작한다.

즉, 브로드캐스트 `채널 종단 간의 채널 전파 지연(channel propagation delay)`이 길수록 다른 노드에서 이미 시작된 전송을 캐리어 감지 노드가 감지할 수 없는 경우가 증가하기 때문에 `채널 종단 간의 채널 전파 지연(channel propagation delay)` 는 CSMA의 성능을 결정하는데 중요한 역할을 한다.


CSMA는 충돌 검출을 수행하지 않는 반면, CSMA/CD는 충돌 검출을 수행한 후 즉시 전송을 취소한다.

**동작 과정**

1. 어댑터는 네트워크 계층으로부터 데이터그램을 받아서 링크 계층 프레임을 만든 후에 그 프레임을 어댑터 버퍼에 저장한다.
2. 어댑터는 채널이 유휴(idle) 상태임을 감지하면 프레임 전송을 시작한다.
   - 만일 어댑터가 채널이 바쁜(busy) 상태임을 감지하면, **어떤 신호 에너지도 감지되지 않을 때까지 더 기다렸다가 프레임을 전송하기 시작**한다.
3. 전송하는 동안 어댑터는 브로드캐스트 채널을 사용하는 **다른 어댑터로부터의 신호 에너지가 있는지 감시**한다.
4. 프레임 전체를 전송하는 동안 다른 어댑터로부터의 신호 에너지가 감지되지 않으면, 프레임 전송을 완료한다.
   - 감지되면 **자신의 프레임 전송을 취소**한다.
5. 전송 취소 후 **임의의 랜덤 시간**만큼 기다린 후 2단계로 돌아간다.
   - 만일 랜덤 시간이 아니라 고정 시간이라면 동시에 프레임을 전송했을 때 똑같은 시간을 기다린 후 전송을 하므로 계속해서 충돌하게 된다.

**랜덤 시간을 결정하는 알고리즘: 이진 지수적 백오프(binary exponential backoff)**

충돌을 n번 경험한 프레임을 전송할 때 노드는 `{0,1,2,…,2^n - 1}` 중에서 랜덤하게 K 값을 선택한 후 `K x 비트 시간` 만큼 기다린다.

이더넷의 경우 K x 512 비트 시간(이더넷으로 512 비트를 전송하는데 걸리는 시간 x K)가 되며 n의 최댓값을 10으로 제한한다.

즉, 충돌을 많이 경험할수록 K의 범위가 지수적으로 커지게 된다.

새 프레임을 준비할 때는 최근 발생한 충돌을 고려하지 않고 CSMA/CD를 수행하여 충돌을 경험한 노드보다 먼저 전송될 수도 있다.

**효율성**

```
d(prop) = 신호 에너지가 임의의 두 어댑터 사이에서 전파되는 데 걸리는 최대 시간
d(trans) = 최대 크기의 이더넷 프레임을 전송하는데 걸리는 시간

효율 = 1/(1+5d(prop)/d(trans))
```

전파 지연이 0이 되면 충돌한 노드는 채널을 장비하지 않고 즉시 취소하기 때문에 d(prop)이 0이되면 효율은 1에 근접한다.

d(trans)가 아주 크면 프레임이 채널을 한번 차지하면 아주 오랫동안 채널을 사용하기 때문에 효율은 1에 근접한다.

따라서 채널은 거의 모든 시간 동안 유용하게 쓰인다.

다중 접속 프로토콜에서 요구되는 두가지 특성은 다음과 같다.

1. 단 하나의 노드만이 활성이면 Rbps의 처리율을 갖는다.
2. M개의 노드가 활성이면 각 노드가 거의 R/M bps의 처리율을 갖는다.

알로하와 CSMA 프로토콜은 첫번째 특성은 지니고 있으나 두 번째 특성은 없다.

이것이 `순번 프로토콜(taking-turns protocol)` 을 개발하게된 동기다.


노드 중 하나를 마스터 노드로 지정한다.

**마스터 노드는 각 노드를 라운드 로빈 방식으로 폴링**한다.

특히, 마스터 노드는 먼저 노드 1에게 노드 1이 최대로 보낼 수 있는 프레임 수에 대한 메시지를 전송하고, 노드 1이 프레임을 전부 보낸 다음 다음 노드도 똑같이 수행하여 순환적으로 각 노드를 폴링하는 방식으로 이 과정을 계속한다.

**장점**

- 빈슬롯을 제거할 수 있다.

**단점**

- 폴링 지연이 있다.
  - 한 노드만 활성이면 활성 노드가 프레임을 최대 개수만큼 보낼 때마다 마스터 노드는 비활성 노드들을 차례로 폴링해야만한다.
- 마스터 노드가 고장나면 전체 채널이 동작하지 못한다.

`토큰(token)` 이라고 알려진 작은 특수 목적 프레임이 정해진 순서대로 노드 간에 전달된다.

예를 들어, 노드 1은 항상 노드 2에 노드 2는 노드 3에 노드 N은 노드 1에 토큰을 전송한다.

노드가 토큰을 수신하면, 전송할 프레임이 있을 때만 토큰을 붙잡고, 그렇지 않으면 토큰을 전달한다.

프레임을 최대 개수까지 전송한 뒤 토큰을 다음 노드로 전달한다.

**장점**

- 분산 방식으로 효율이 매우 높다

**단점**

- 노드 하나가 실패하면 채널이 동작하지 않는다.
- 노드가 토큰을 놓아주지 않으면, 토큰이 다시 돌 수 있도록 하는 회복 절차가 수행되어야 한다.


`DOCSIS(Data-over-Cable Service Interface Specificaitions)`는 케이블 데이터 네트워크의 구조와 프로토콜들을 정의한다.

DOCSIS는 하향 및 상향 네트워크 세그먼트들을 다수의 주파수 채널로 나누기 위해 FDM을 사용한다.

각 상향 및 하향 채널은 브로드캐스트 채널이다.

각 하향 채널은 24~192 MHz 대역에 약 1.6 Gbps의 최대 처리율을 제공한다.

CMTS에 의해 하향 채널로 전송된 프레임은 그 채널을 통해 수신하는 모든 케이블 모뎀에 의해 수신된다. (하향 채널로 전송하는 CMTS가 하나이기 때문에 다중 접속 문제는 발생하지 않는다.)

CMTS는 하향 채널상으로 MAP 메시지로 알려진 제어 메시지를 보냄으로써 어떤 케이블 모뎀이 MAP 메시지에서 명시한 시간 간격 동안 어떤 `미니슬롯(mini slot)`으로 전송할 수 있는지 알려준다.


상향 채널은 6.4~96 MHz 대역에 약 1 Gps의 최대 상향 처리율을 제공한다.

다수의 케이블 모뎀이 CMTS로의 동일한 상향 채널(주파수)을 공유하여 충돌이 발생할 수 있다.

상향 채널은 TDM처럼 시간 간격으로 나뉘어 있고, 각 시간 간격은 케이블 모뎀이 CMTS로 전송할 수 있는 일련의 `미니슬롯(mini slot)`들로 구성되어 있다.

`미니슬롯(mini slot)` 이 케이블 모뎀마다 명시적으로 할당되어 있기 때문에 CMTS는 `미니슬롯(mini slot)` 동안은 충돌이 발생하지 않는 것을 확신할 수 있다.

`미니슬롯(mini slot)`에는 `미니슬롯 요청(mini-slot-request) 프레임`을 CMTS에게 전송하기 위한 특정 `미니슬롯(mini slot)` 들이 있다.

각 케이블 모뎀은 `미니슬롯 요청(mini-slot-request) 프레임` 을 CMTS에게 전송하여 어떤 케이블 모뎀이 전송할 데이터가 있는지 알 수 있다.

`미니슬롯 요청(mini-slot-request) 프레임` 은 랜덤 접속 방식으로 전송되기 때문에 충돌이 발생할 수 있다.

케이블 모뎀은 충돌 검출을 수행하지 않고, 요청된 할당에 대한 응답을 다음 하향 제어 메시지에서 수신하지 못한다면 미니슬롯 요청 프레임이 충돌됐다고 추청한다.

이렇게 추정한 케이블 모뎀은 재전송을 지연시키기 위해 `이진 지수적 백오프`를 사용한다.

스위치는 링크 계층에서 동작하기 때문에 링크 계층 프레임을 교환한다.

또한, 네트워크 계층 주소를 인식하지 않으며, 2계층 스위치들로 구성된 네트워크에서 경로를 결정하는 데 OSPF 같은 라우팅 알고리즘을 사용하지 않는다.

즉, IP 주소가 아닌 **링크 계층 주소를 사용**한다.


네트워크 계층 주소 체계가 있는데도 링크 계층 주소를 갖는 이유

1. 랜은 IP와 인터넷만을 위해서가 아니라 임의의 네트워크 계층 프로토콜을 위해 설계되었기 때문이다.
2. 만일 어댑터가 MAC 주소 대신에 네트워크 계층 주소를 사용한다면, 네트워크 계층 주소를 어댑터 RAM에 저장하고 어댑터를 이동할 때마다 재구성해야 한다.

즉, 네트워크 구조에서 계층이 독립적인 구성요소가 되도록 하려면 각 계층은 자신만의 주소 기법을 가져야만 한다.


실제로 링크 계층 주소를 가진 것은 호스트나 라우터가 아닌 호스트나 라우터의 어댑터(네트워크 인터페이스)다.

즉, 다수의 네트워크 인터페이스를 갖고있으므로 여러 개의 링크 계층 주소를 갖게된다.

그러나 링크 계층 스위치는 호스트와 라우터 간에 데이터그램을 전달하는 일을 하기 때문에 호스트나 라우터를 연결해주는 인터페이스에 링크 계층 주소를 할당받지 않는다.

**MAC 주소 표기법**

MAC 주소는 링크 계층 주소로, 대부분의 랜의 경우 MAC 주소는 길이가 6바이트이며, 따라서 2^48개만큼의 사용 가능한 랜 주소가 있다.

위 그림처럼, 주로 각 바이트는 2개의 16진수로 표기된다.

본래 MAC 주소는 영구적으로 설계되었으나, 이제는 소프트웨어를 사용해서 어댑터의 MAC 주소를 변경할 수 있다.

IEEE가 MAC 주소 공간을 관리하여 모든 어댑터가 다른 주소를 갖게끔 한다.

즉, 어떤 회사가 어댑터를 제조하려면 2^24개의 주소로 이루어진 주소 영역을 구매 후 첫 24비트를 고정하고, 나머지 24비트는 회사로 하여금 각 어댑터에게 유일하게 부여하는 방식으로 2^24개 주소를 할당한다.

MAC 주소는 계층 구조가 아닌 평면 구조를 가지고, 위치가 변하더라도 바뀌지 않는다.

IP 주소가 마치 우편번호 처럼 쓰였다면 MAC주소는 주민등록번호처럼 사용되는 것이다.

**MAC 주소를 활용한 어댑터의 송수신**

1. 송신 어댑터는 프레임에 목적지 어댑터의 MAC 주소를 넣고 랜상으로 전송한다.
   - 스위치는 종종 프레임을 자신의 모든 인터페이스로 브로드캐스트한다.
   - 즉, 자신을 목적지로 하지 않는 프레임을 수신할 수도 있다.
2. 프레임을 수신한 어댑터는 프레임 안의 목적지 MAC 주소와 자신의 MAC 주소가 일치하는지 검사한다.
3. 일치하면 데이터그램을 추출하여 프로토콜 스택의 위쪽으로 전달한다.
4. 일치하지 않으면 폐기한다.

랜상의 다른 모든 어댑터가 자신이 전송한 프레임을 수신하고 처리하기를 원할 때 `MAC 브로드캐스트 주소(broadcast address)`를 넣는다.

이 주소는 모든 비트가 1로된 6바이트 주소이다.

네트워크 계층 주소와 링크 계층 주소가 있으므로 이들 주소 사이에 변환을 해주는 프로토콜을 `ARP(Address Resolution Protocol)` 이라고 한다.

`ARP 모듈`은 IP와 MAC 주소와 마찬가지로 인터페이스마다 존재한다.

위 그림에서 A에서 C로 데이터그램을 전송하려고 한다고 가정해보자.

데이터그램을 전송하기 위해 목적지 IP 뿐만 아니라 MAC 주소도 주어야만 랜이 적절하게 C로 전달할 수 있다.

송신 호스트 즉, A는 목적지 IP주소를 가진 호스트의 MAC 주소를 알아야하는데 이를 ARP가 해준다.

송신 호스트의 ARP 모듈은 입력값으로서 동일한 랜상의 임의의 IP 주소에 대해 대응되는 MAC 주소를 돌려준다.

이러한 면에서 DNS와 비슷한 면이 있다.

그러나 DNS는 인터넷의 임의의 장소에 있는 호스트의 호스트 네임을 해결하는 반면에, A**RP는 동일한 서브넷상에 있는 호스트나 라우터 인터페이스의 IP 주소만을 해결**한다.

**ARP 동작 과정**

각 호스트와 라우터는 자신의 메모리에 `ARP 테이블(ARP table)`을 갖고 있다.

이 테이블은 IP 주소와 MAC 주소 간의 매핑 정보를 포함하며, 테이블에서 각 매핑이 언제 삭제되는지를 나타내는 `TTL(time-to-live)` 값을 포함한다.

일반적으로 삭제 시간은 엔트리가 테이블에 들어간 후 20분이다.

테이블에 서브넷상의 모든 호스트와 라우터에 대한 엔트리를 갖고 있지 않아도 된다.

즉,데이터그램을 전송하려할 때, ARP 테이블에 목적지 노드에 대한 엔트리가 없을 수 있다.

다음 동작 과정을 보자.

1. 송신 노드는 MAC 주소를 해결하기 위해 ARP 프로토콜을 사용하여 `ARP 패킷`이라는 특수 패킷을 어댑터에 보낸다.
   - ARP 패킷은 송수신 IP주소와 MAC 주소를 포함하는 필드를 가지며 질의 패킷과 응답 패킷 모두 같은 형식을 갖는다.
   - 질의 패킷의 목적은 해결하려는 IP주소에 대응되는 MAC 주소를 결정하기 위해 서브넷의 다른 모든 호스트와 라우터들에게 질의하는 것이다.
   - 질의 패킷은 브로드캐스트 프레임으로 전송된다.
2. 어댑터는 ARP패킷을 링크 계층 프레임에 캡슐화하고, 목적지 주소를 MAC 브로드캐스트 주소(FF-FF-FF-FF-FF-FF)로 하여 패킷을 전송한다.
3. 이 질의는 서브넷 상의 다른 모든 어댑터에 의해 수신되며, 브로드캐스트 주소 때문에 각 어댑터는 프레임에 들어있는 ARP 패킷을 자신의 ARP 모듈로 전달한다.
4. ARP 모듈은 자신의 IP 주소가 ARP 패킷에 들어 있는 목적지 IP주소와 일치하는지 검사한다.
5. 일치하는 노드는 요구된 매핑 정보가 포함된 응답 패킷을 돌려보낸다.
   - 질의 패킷은 브로드캐스트 프레임으로 전송되는 반면 응답 패킷은 표준 프레임으로 전송된다.
6. 질의 호스트는 자신의 ARP 테이블을 갱신한다.

즉, 노드의 `ARP 테이블(ARP table)` 은 `플러그 앤 플레이(plug-and-play)`다. 즉, 관리자가 구성하지 않아도 자동으로 구축된다.

ARP는 링크 계층 주소도 포함하고, 네트워크 계층 주소도 포함하기 때문에 네트워크 계층과 링크 계층의 경계에 있는 프로토콜이다.


위 그림에서 호스트 `111.111.111.111`이 호스트 `222.222.222.222`로 IP 데이터그램을 전송하려한다고 가정하자.

라우터는 2개의 IP 주소, 2개의 ARP 모듈, 2개의 어댑터(어댑터는 고유한 MAC 주소를 가지고 있으므로 MAC주소도 2개다.)를 가지고 있다.

송신 호스트는 적절한 목적지 MAC 주소와 IP 주소가 포함된 데이터그램을 자신의 어댑터로 전달해야한다.

만약, 송신 어댑터가 목적지 MAC 주소를 `49-BD-D2-C7-56-2A` 를 사용한다면 목적지 주소는 `111.111.111.111` 호스트가 포함된 서브넷에 있는 어떤 어댑터의 MAC 주소와도 일치하지 않으므로 서브넷에 있는 어떤 어댑터도 IP 데이터 그램을 자신의 네트워크 계층으로 전달하지 않는다.

즉, 데이터그램은 전달되지 않고 사라진다.

데이터그램이 전달되기 위해서는 라우터 인터페이스 `111.111.111.110`으로 전달해야만 한다. 따라서 이 프레임에 대한 적절한 MAC 주소는 라우터 인터페이스의 `E6-E9-00-17-BB-4B` 이다.

**동작 과정**

1. 송신 호스트가 `111.111.111.110` 의 MAC 주소를 ARP를 사용하여 알게된다.
2. MAC주소를 알게 되면 송신 호스트는 IP 목적지 주소가 `222.222.222.222` 를 포함하는 **데이터그램을 알아낸 MAC 주소와 함께 서브넷으로 전송**하고 서브넷의 라우터 어댑터는 MAC 주소가 일치하므로 네트워크 계층까지 전달한다.
3. 라우터의 포워딩 테이블을 통해 라우터에게 데이터그램을 라우터 인터페이스 `222.222.222.220` 을 거쳐서 전달하도록 지시한다.
4. 인터페이스는 데이터그램을 자신의 어댑터로 전달하고 어댑터는 데이터그램을 새 프레임에 캡슐화하여 그 프레임을 다른 서브넷으로 전달한다.
   - 여기서의 목적지 MAC 주소는 당연히 ARP를 통해 알게된다.

오늘날 이더넷은 가장 우세한 랜 기술이다.

인터넷이 글로벌 네트워킹에 대한 것이라면, 이더넷은 근거리 네트워킹에 대한 것이다.

**발전 과정**

- 1980년대
  - 이더넷 랜은 노드를 연결하기 위해 동축 버스를 사용했다.
  - 버스 토폴로지의 이더넷은 브로드캐스트 랜으로, 전송되는 모든 프레임은 버스에 연결된 모든 어댑터를 거치며 이들에 의해 처리된다.
- 1990년대
  - 랜을 허브 기반의 스타 토폴로지를 사용하는 이더넷으로 대체
  - 꼬임쌍선을 사용해서 허브에 직접 연결된다.
  - `허브(hub)`는 프레임이 아닌 각각의 비트에 대한 처리를 하는 물리 계층 장치다.
  - `허브(hub)` 가 한 인터페이스로 비트를 수신하면 그 비트의 복사본을 다른 모든 인터페이스로 전송한다.
- 2000년대 초반
  - 중앙의 허브가 `스위치(switch)`로 대체되었다.
  - `스위치(switch)` 는 충돌 없는 장치일 뿐만 아니라 저장-후-전달 패킷 스위치이다.


- 데이터 필드(46~1500바이트)
  - 이 필드는 IP 데이터그램을 운반한다.
  - 1500바이트를 초과하면 호스트가 단편화해야한다는 것을 의미한다.
  - 46바이트보다 작으면 데이터 필드를 채워서 46바이트로 만들어야 한다. 채운 부분을 제거하기 위해 IP 데이터그램 헤더의 길이 필드를 사용한다.
- 목적지 주소(6바이트)
  - 목적지 MAC주소가 들어간다.
- 출발지 주소(6바이트)
  - 출발지 MAC주소가 들어간다.
- 타입 필드(2바이트)
  - 네트워크 계층 프로토콜을 이더넷으로 하여금 다중화하도록 허용한다.
  - 즉, IP 이외의 네트워크 계층 프로토콜을 사용할 수 있게끔 한다.
- 순환 중복 검사(CRC)(4바이트)
  - CRC 필드의 목적은 수신 어댑터가 프레임에 오류가 생겼는지 검출할 수 있게 한다.
- 프리앰블(8바이트)
  - 이더넷 프레임은 8바이트의 프리앰블(preamble) 필드로 시작한다.
  - 프리앰블의 첫 7바이트는 `10101010` 값을 갖고 마지막 바이트는 `10101011`이다.
  - 프리엠블의 첫 7바이트는 수신 어댑터를 깨우고, 수신자의 클록을 송신자의 클록과 동기화하는 역할을 한다.
  - 송신 어댑터는 이더넷 랜 종류에 따라 원하는 속도로 프레임을 전송하려 하지만 송신 어댑터는 목적지 속도에 정확히 맞게 전달할 수 없으므로 수신 어댑터는 단순히 프리앰블의 첫 7바이트에 있는 비트들에 맞춤으로써 송신 어댑터의 클록에 맞출 수 있다.
  - 8번째 바이트의 마지막 두비트는 수신 어댑터에게 중요한 것이 오고 있음을 알려준다.

송신 어댑터는 데이터그램을 전송할 때 핸드셰이킹 하지 않고 이더넷 프레임에 캡슐화해서 랜으로 전송한다.

수신 어댑터는 CRC 검사를 통해 프레임을 검사하지만 이에 대한 확인 응답 혹은 부정 확인 응답을 보내지 않는다.

그저, 실패하면 폐기한다.

애플리케이션이 UDP 또는 TCP를 사용하는지에 따라 데이터그램의 손실을 알 수 있음이 결정된다.

UDP의 경우 알 수 없고, TCP는 확인 후 재전송하게 할 것이다.

즉, 이더넷은 전송하고 있는 데이터그램이 재전송인지 새로운 데이터그램인지 구분할 수 없다.


이더넷은 수년에 걸쳐 진화해왔으며, 오늘날의 이더넷은 동축케이블을 사용하는 초기 버스 토폴로지 설계와 상당히 다르다.

요즘은 노드가 꼬임쌍선이나 광섬유 케이블로 만들어진 점대점 세그먼트를 통해 스위치에 연결된다.

이더넷이 발전하여도, 프레임 형식은 그대로 유지되어 사용된다.

버스 토폴로지와 허브 기반의 스타 토폴로지의 이더넷 표준은 노드들이 동시에 전송하면 프레임 충돌이 발생하는 브로드캐스트 링크였다.

이 충돌을 처리하기 위해 CSMA/CD 프로토콜이 포함되었다.

현재 많이 사용하는 이더넷은 `저장-후-전달 패킷 교환`을 하는 스위치 기반의 스타 토폴로지인데, 여전히 MAC 프로토콜이 필요할까?

스위치 기반 이더넷 랜에는 충돌이 없어 MAC 프로토콜이 필요하지 않다.

스위치의 역할은 들어오는 링크 계층 프레임을 수신해서 출력 링크로 전달하는 것이다.

스위치는 그 자체가 서브넷의 호스트와 라우터들에게 투명하다.

즉, 호스트/라우터는 프레임을 스위치가 아닌 다른 호스트/라우터를 목적지로해서 랜상으로 보내며, 중간에 스위치가 프레임을 받아서 다른 노드에게 전달하는 것을 알지 못한다.

프레임이 스위치 출력 인터페이스들 중 하나에 도착하는 속도가 그 인터페이스의 링크 용량을 일시적으로 초과할 수 있다.

이 문제를 해결하기 위해, 스위치 출력 인터페이스는 버퍼를 갖고 있다.


- `필터링(filtering)`
  - 프레임을 인터페이스로 전달할지 또는 폐기(drop)할지 결정하는 스위치의 기능
  - `스위치 테이블(switch table)`을 이용
- `포워딩(forwarding)`
  - 프레임이 전송될 인터페이스를 결정하고 프레임을 해당 인터페이스로 내보내는 기능
  - `스위치 테이블(switch table)`을 이용
- `스위치 테이블(switch table)`
  - 랜상의 모든 호스트와 라우터는 아니지만 일부 노드에 대한 엔트리가 포함되어 있다.
  - 스위치 테이블 엔트리 구성
    - MAC 주소
    - MAC 주소로 가게 하는 스위치 인터페이스
    - 해당 엔트리가 만들어진 시점

**스위치 테이블 엔트리의 동작**

목적지 주소를 가진 프레임이 스위치 인터페이스 x에 도달했다고 하자.

- 테이블에 **목적지 주소에 대한 엔트리가 없는 경우**
  - 스위치는 프레임의 복사본을 프레임이 수신된 인터페이스를 제외한 모든 인터페이스의 출력 버퍼로 전달한다.
  - 즉, 브로드캐스트한다.
- 테이블에 목적지 주소가 x **인터페이스에 연관된 엔트리**가 있는 경우
  - 프레임은 송신자 어댑터를 포함하는 랜 세그먼트로부터 왔다.
  - 프레임을 다른 인터페이스로 전달할 필요가 없으며, 프레임을 제거함으로써 필터링 기능을 수행한다.
- 테이블에 목적지 주소가 y≠x 인터페이스와 연관된 엔트리가 있는 경우
  - 프레임은 y 인터페이스에 접속된 랜 세그먼트로 전달되어야 한다.
  - 즉, 해당 인터페이스 출력 버퍼에 프레임을 넣음으로써 포워딩 기능을 수행한다.

스위치는 테이블을 자동으로, 동적으로, 자치적으로 `자가학습(self-learning)`하는 특징이 있다.

**동작 과정**

1. 스위치 테이블은 초기에 비어있다.
2. 인터페이스로 수신한 각 프레임에 대해 스위치는 다음과 같은 정보를 저장한다.
   - 프레임의 출발지 주소 필드에 있는 MAC 주소
     - 즉, 다음번 수신 때 다른 랜에서 목적지 주소 필드를 해당 MAC 주소를 갖게되면 프레임을 알맞게 전달할 수 있게 된다.
   - 프레임이 도착한 인터페이스
   - 현재 시간
3. 랜에 있는 모든 호스트가 프레임을 송신하면, 결국 모든 호스트에 대한 정보가 테이블에 기록된다.
4. `수명 시간(aging time)`이 지난 후에도 스위치가 해당 주소를 출발지 주소로 하는 프레임을 수신하지 못하면 테이블에서 이 주소를 삭제한다.
   - 즉, PC가 다른 PC로 대체되면 원래 PC의 MAC 주소는 스위치 테이블에서 삭제된다.

스위치는 네트워크 관리자나 사용자의 개입을 요구하지 않으므로 `플러그 앤 플레이 장치(plug-and-play device)`다.


- 충돌 제거
  - 스위치로 구축된 랜에는 충돌로 인해 낭비되는 대역폭이 없다.
  - 프레임을 버퍼링하며 어느 시점이든 세그먼트에 하나 이상의 프레임을 전송하지 않는다.
  - 브로드캐스트 링크를 사용하는 랜보다 성능이 월등히 향상된다.
- 이질적인 링크들
  - 링크들을 별개로 분리하기 때문에 랜의 각 링크는 상이한 속도로 동작할 수 있으며 상이한 매체를 사용할 수 있다.
- 관리
  - 스위치는 향상된 보안을 제공할 뿐만 아니라 네트워크 관리를 쉽게 할 수 있게 한다.
  - e.g. 케이블이 끊긴다면 그쪽 호스트의 연결만 끊어진다, 오동작으로 프레임을 계속 보내는 경우 이 문제를 감지하고 오동작하는 어댑터의 연결을 의도적으로 끊는다.
  - 대역폭 사용, 충돌률, 트래픽 종류에 대한 통계치를 수집하여 볼 수 있다.

- 스위치 테이블에 엔트리가 있을 때
  - 호스트가 스위치에 연결되면 보통 자신을 목적지로 해서 전송된 프레임만 수신하기 때문에 다른 호스트는 프레임을 훔쳐볼 수 없다.
- 스위치 테이블에 엔트리가 없을 때
  - 스위치가 프레임을 브로드캐스트하기 때문에 스니퍼는 자신을 목적지로 하지 않는 일부 프레임을 훔쳐볼 수 있다.
  - 이를 이용해 `스위치 독(switch poisoning)`이라는 공격 수법을 사용하여 프레임을 훔쳐본다.
    - `스위치 독(switch poisoning)` 은 여러 가짜 출발지 MAC 주소를 갖는 패킷을 상당수 보내 스위치 테이블을 가짜 엔트리로 가득채워 합법적인 호스트들의 MAC 주소를 넣을 공간을 없애는 것을 말한다.


- 라우터
  - 네트워크 계층 주소를 사용해서 패킷을 전달하는 저장 후 전달 패킷 스위치다.
  - 3계층 패킷 스위치이다.
- 스위치
  - 저장후 전달 패킷 스위치이지만 MAC 주소를 사용해서 패킷을 전달한다.
  - 2계층 패킷 스위치이다.

이 둘은 근본적으로 다르지만(MAC 주소, IP 주소를 사용한다는 점에서), 네트워크 관리자는 상호연결 장치를 설치할 때 종종 이들 중에서 선택해야만 한다.

실제로, 라우터는 충돌 없이 학과 간의 통신이 가능하게 할 수 있다.

**스위치의 장점**

- `플러그 앤 플레이 장치(plug-and-play device)` 로 관리자가 크게 신경쓸 필요가 없다.
- 높은 패킷 필터링 및 전달률을 갖는다.

**스위치의 단점**

- 브로드캐스트 프레임의 순환을 방지하기 위해 스위치 네트워크의 실제 사용되는 토폴로지는 스패닝 트리로 제한된다.
- 대규모 스위치 네트워크에서는 호스트와 라우터가 커다란 ARP 테이블을 갖게 되며 상당한 양의 ARP 트래픽이 생성되고 처리된다.
- 브로드캐스트 트래픽의 폭주에 대비한 방안을 제공하지 않는다.

**라우터의 장점**

- 계층구조이므로, 네트워크에 중복된 경로가 있을 때 조차도 패킷은 라우터를 따라 순환하지 않는다. 즉, 스패닝 트리로 제한받지 않고 최상의 경로를 사용할 수 있다.
- 제한이 없으므로 인터넷 토폴로지가 자유롭게 구축될 수 있게 한다.
- 브로드캐스트 폭풍에 대비한 방화벽 보호기능이 있다.

**라우터의 단점**

- `플러그 앤 플레이 장치(plug-and-play device)` 가 아니다.
- 스위치보다 패킷당 처리 시간이 더 크다.

일반적으로, 작은 네트워크는 트래픽이 지역적으로 제한되어 있고 IP 주소의 구성을 요구하지 않으면서도 총 처리율을 증가시키므로 스위치로도 충분하다.

그러나 보통 수천 개의 호스트로 구성된 큰 네트워크에서는 라우터도 포함한다.

위 구조에서 스위치는 계층적으로 구성되어있는데, 이러한 구성의 단점은 다음과 같다.

- 트래픽 격리의 부족
  - 계층 구조는 그룹 트래픽을 단일 스위치 내로 격리해주지만, 브로드캐스트 트래픽은 여전히 전체 네트워크로 전달되어야만 한다.
  - 즉, 브로드캐스트의 범위를 제한하면 랜 성능을 향상할 수 있다.
- 스위치의 비효율적인 사용
  - 기관에 그룹이 3개가 아닌 10개가 있는 경우 첫 단계 스위치가 10개가 필요하다.
  - 그룹 내 인원수가 10명보다 작으면 96 포트 스위치 하나로 모든 사람을 수용할 수 있지만 스위치 하나로는 트래픽 격리를 할 수 없다.
- 사용자 관리
  - 사원이 한 그룹에서 다른 그룹으로 이동하는 경우 이 사원을 다른 스위치에 연결하기 위해 물리적 케이블 연결을 변경해야만 한다.

위와 같은 단점을 `가상 근거리 네트워크(virtual local area network, VLAN)`를 지원하는 스위치를 사용해서 해결할 수 있다.

VLAN을 지원하는 스위치는 하나의 물리적 근거리 네트워크 인프라스트럭처상에서 여러 개의 가상 근거리 네트워크들을 정의할 수 있게한다.

VLAN에 속한 호스트들은 마치 스위치에 자신들만(다른 호스트들은 없이) 연결된 것처럼 서로 통신한다.

포트 기반 VLAN에서는 네트워크 관리자가 스위치 포트(인터페이스)를 그룹으로 나눈다.

나뉜 각 그룹은 하나의 VLAN을 구성하며, 한 VLAN 포트들은 하나의 브로드캐스트 도메인을 형성한다.

즉, 같은 그룹의 다른 포트에만 브로드캐스트 트래픽을 전달할 수 있다.


위 그림은 16개의 포트를 갖고 있는 단일 스위치를 보여준다.

포트 `2~8`은 EE VLAN이고, `9~15`는 CS VLAN에 속한다.

- VLAN은 각각의 프레임을 서로 격리해준다.
- 그룹을 변경하려면 관리자가 포트가 속한 그룹이 바뀌도록 재구성한다.
- 2개의 그룹을 위해 있던 2개의 스위치가 하나의 스위치로 대체되었다.

즉, 위의 단점을 모두 해결한다.

VLAN 스위치는 포트-VLAN 매핑 테이블을 관리하고 네트워크 관리자가 스위치 관리 소프트웨어를 사용해서 이를 바꿀 수 있다.

또한, 스위치 하드웨어는 같은 VLAN에 속한 포트들 간에만 프레임을 전달한다.

EE VLAN과 CS VLAN은 물리적으로는 붙어있지만 논리적으로는 다른 LAN이기 때문에 트래픽 전송이 다른 스위치나 라우터를 거쳐야만 한다.

- VLAN 스위치 포트(미사용 포트, e.g. 위 그림에서 1번 포트)를 외부 라우터에 연결한다.
- VLAN 스위치 포트를 두개의 LAN 모두에 속하게 한다.
- 데이터그램이 먼저 CS VLAN(스위치 포트)를 통과해서 라우터에 도달한다.
- 라우터에 의해 CS VLAN을 통해 CS 호스트로 전달된다.

스위치 생산자들은 VLAN 스위치와 라우터를 모두 포함시켜 네트워크 관리자가 위 과정을 쉽게할 수 있도록 한다.


스위치에 N개의 VLAN이 있다고 하면 N개의 포트를 N개의 VLAN에 속하게 하고, 외부 스위치에 하나씩 연결해주면 외부 스위치도 VLAN 스위치와 같이 일할 수 있다.

그러나 N개의 VLAN에는 N개의 포트가 필요하므로 확장에 문제가 있다.

위 방법은 `VLAN 트렁킹(VLAN Trunking)` 방식이다.

스위치 마다 하나의 특수 포트가 2개의 VLAN을 연결하는 `트렁크 포트(trunk port)`로 구성되어있다.

`트렁크 포트(trunk port)` 는 모든 VLAN에 속하며 한 VLAN에서 전송한 프레임들을 트렁크 링크를 통해 다른 스위치로 전달해준다.

이때 어떤 트렁크 포트로 온 프레임이 어떤 VLAN에 속하는지 알 수 없다.

이를 위해 IEEE는 VLAN 트렁크를 통과하는 프레임을 위한 확장된 형태의 이더넷 프레임 형식을 정의했다.

확장된 이더넷 프레임 형식은 VLAN을 식별해주는 4바이트 `VLAN 태그(VLAN Tag)`를 헤더에 갖고 있다.

`VLAN 태그(VLAN Tag)` 는 당연하지만, 송신 측의 스위치에 의해 추가되고, 수신 측에 있는 스위치에 의해 파싱되고 제거된다.

`VLAN 태그(VLAN Tag)` 구성

- 2바이트 태그 프로토콜 식별자(Tag Protocol Identifier, TPID) 필드
- 2바이트 태그 제어 정보(Tag Control Information) 필드
  - 12비트의 VLAN 식별자(identifier) 필드 <- 추가 필요
  - 3비트 우선순위(priority) 필드

> 💡 MPLS의 목표는 고정 길이 레이블과 가상 회선을 기반으로 데이터그램을 전달하기 위해 목적지 기반 IP 데이터그램 인프라스트럭처를 포기하는 것이 아니라, 가능한 경우 데이터그램을 선택적으로 레이블링해서 **라우터로 하여금 고정 길이 레이블을 기반으로 데이터그램을 전달할 수 있도록 목적지 기반 IP 데이터그램 전달 하부구조를 확장**하는 것이다.


MLPS가능 라우터에 의해 처리되는 링크 계층 프레임의 형식은 2계층 헤더와 3계층 헤더 사이에 작은 MPLS 헤더를 가진다.

MPLS 헤더에는 레이블, 실험을 위해 예약된 3개의 비트, 일련의 스택된 MPSL 헤더들의 끝을 나타내는 1개의 S 비트, TTL 필드가 있다.

**MPLS 헤더는 MPLS 가능 라우터들 사이에서만 전송될 수 있다.**

MPLS 가능 라우터는 MPLS 레이블을 포워딩 테이블에서 찾아 적당한 출력 인터페이스로 데이터그램을 전달하여 MPLS 프레임을 전달하므로 종종 레이블 스위치 라우터(label-switched router)라고 부른다.

즉, MPLS 가능 라우터는 목적지 IP 주소를 꺼내 볼 필요도 없고, 포워딩 테이블에서 최장 프리픽스 대응을 찾을 필요도 없다.

R1에서 R4 까지만 MPLS 기능이 있을 때 어떻게 상호 동작하는지 알아보자.

1. R1은 자신이 A까지 라우팅할 수 있고 MPLS 레이블 6을 포함하는 프레임을 목적지로 보낼 수 있음을 R2 R3에게 광고한다.
2. R3는 자신이 목적지 A,D까지 라우팅할 수 있고, MPLS 레이블 10과 12를 포함하는 입력 프레임을 각각 이들 목적지를 향해 스위칭할 수 있음을 R4에게 광고한다.
3. …

이를 반복하여 R4는 3개의 MPLS 경로를 갖게 된다.

MPLS 가능 라우터는 **패킷의 IP 헤더를 건드리지 않고 동작**한다.

즉, MPLS는 IP 주소를 고려하지 않고 레이블 기반으로 스위칭하여 스위칭 속도를 향상시켰다.

MPLS는 또한 트래픽을 관리하는데, IP 라우팅 프로토콜은 최소 비용 경로 하나만 지정하는 반면, MPLS는 표준 IP 라우팅 프로토콜을 사용해서는 불가능한 경로까지 제공한다.

이는 MPLS를 사용해서 **트래픽 엔지니어링(traffic engineering)** 을 제공하는 간단한 하나의 방식이다.


데이터 센터는 인터넷에 연결되어 있을 뿐만 아니라 내부 호스트들 간 상호연결을 위해 자체 `데이터 센터 네트워크(data center network)`를 갖고 있다.

데이터 센터의 3가지 목적

1. 웹 페이지, 검색 결과, 전자메일, 스트리밍 비디오와 같은 콘텐츠 제공
2. 검색 엔진을 위한 분산 인덱스 계산과 같은 특정 데이터 처리 작업이 가능한 대량 병렬 컴퓨팅 인프라스트럭처 역할
3. 다른 회사에게 `클라우드 컴퓨팅(cloud computing)`을 제공


데이터 센터에서 작업을 수행한다.

피자 박스 모양의 `블레이드(blade)`라고도 불린다.

CPU, 메모리, 디스크 저장장치를 갖고 있는 범용 호스트다.

호스트들은 20~40대의 블레이드를 적재할 수 있는 `랙(rack)`에 적재된다.

데이터 센터 내부에서 사용되는 자신만의 IP 주소를 할당 받는다.

랙의 맨 위에는 TOR스위치라고 불리는 스위치가 있다.

TOR 스위치는 네트워크 인터페이스 카드를 통해 랙에 있는 호스트들을 연결해준다.

그 외의 다른 포트들을 통해 데이터 센터의 다른 스위치들과 연결된다.


외부 클라이언트와 내부 호스트 간 트래픽 플로우를 처리하기 위해 하나 이상의 경계 라우터를 갖는다.

경계 라우터는 데이터 센터 네트워크를 공중 인터넷으로 연결해준다.

1. 외부 클라이언트의 요청을 지원하기 위해, 애플리케이션에는 공용 IP 주소가 할당되며 클라이언트는 이 IP 주소로 요청을 보내고 응답을 받는다.
2. 요청을 `로드 밸런서`로 보낸다.
   - 일반적으로 여러 `로드 밸런서`를 갖고 있으며, 각 `로드 밸런서`는 특정 클라우드 애플리케이션을 위해 사용된다.
   - `로드 밸런서` 는 목적지 IP 주소 뿐만 아니라 목적지 포트를 보고 결정하기 때문에 4계층 스위치라고도 한다.
3. `로드 밸런서`는 요청을 호스트로 분배하고 호스트의 현재 부하 상태에 따라서 호스트 간의 부하를 균등하게 한다.
   - `로드 밸런서` 는 호스트의 공용 외부 IP 주소를 내부 IP 주소로 변환해주고 그 반대 변환도 해주기 때문에 NAT과 유사한 기능을 제공한다.

클라이언트가 호스트와 직접 통신하지 못하게 하여 내부 구조를 숨기고 보안을 제공한다.


1. 계층 구조의 최상단에서는 경계 라우터가 접속 라우터들에 연결된다.
2. 접속 라우터는 최상단 스위치와 연결된다.
   - 접속 라우터 아래에는 총 세 단의 스위치들이 있다.
3. 최상단 스위치는 여러 개의 두 번째 단 스위치들과 로드 밸런서에 연결된다.
4. 두 번째 단 스위치는 랙의 TOR 스위치(세 번째 단)를 통해 여러 랙으로 연결 된다.
5. 호스트들은 랙에 연결되어 하나의 서브넷을 형성한다.
   - ARP 브로드캐스트 트래픽을 지역 내로 한정하기 위해 서브넷은 다시 작은 VLAN 서브넷들로 분할된다.

클라우드 애플리케이션 제공자 입장에서는 애플리케이션 가용성을 높게 유지하는 것이 중요하기 때문에 데이터 센터 설계에 여분의 네트워크 장비와 링크를 포함시킨다.

맨 위 데이터센터 그림에서 랙 1에 있는 10대의 호스트가 랙 5의 대응되는 호스트로 플로우를 보낸다고 하자.

마찬가지로 랙 2에서 6, 랙 3에서 7, 랙 4에서 8로 플로우를 보낸다고 하자.

하나의 링크를 지나가는 플로우들이 공평하게 링크 용량을 나눠서 사용하면 A에서 B로의 링크를 거쳐 가는 40개의 플로우는 각각 `n Gps/40` 만 수신하게 된다.

네트워크 인터페이스 카드의 전송률이 `n Gps/40` 보다 크다면 이는 문제가 생기고, 위쪽을 거쳐가는 호스트 간 플로우의 경우 훨씬 더 심각해진다.


- 고속 스위치와 라우터를 사용한다.
  - 이는 비용이 많이 나간다.
- 2단 또는 1단 스위치를 경유하는 렉 간 통신이 최소화되도록 서로 관련된 서비스와 데이터를 가능한 한 같은 곳에 위치시킨다.
  - 데이터 센터의 주요 요구사항인 계산과 서비스를 융통성 있게 배치해야 한다는 것 때문에 제한적이다.
- TOR 스위치들과 2단 스위치들 간, 2단 스위치들과 1단 스위치들 간 연결성을 증가시킨다.
  - 예를 들어, 하나의 TOR 스위치를 2개의 2단 스위치에 연결함으로써 랙 간에 여러 개의 링크 `비결합(link-disjoint)`, 스위치 비결합 경로를 제공할 수 있다.
  - 단 간의 연결성(경로의 다양성)을 증가시킴으로써 스위치 간 용량 및 신뢰성 증가라는 두 가지 이득을 얻게 된다.


데이터 센터 네트워킹에서 가장 중요한 동향은 계층적으로 단을 구성해서 데이터 센터 호스트들을 상호 연결해주는 것이다.

즉, 데이터 센터의 호스트는 다른 어떤 호스트와도 통신할 수 있게 한다.

데이터 센터 상호연결 네트워크는 다수의 소규모 스위치들로 구성된다.

데이터 센터는 단일 기관에 의해 관리되기 때문에 다수의 대규모 센터 운영자들은 SDN과 같은 논리적 중앙 집중형 제어라는 개념을 쉽게 받아들이게 된다.

SDN의 데이터 평면과 소프트웨어 기반 제어 평면에 대한 명확한 분리가 데이터 센터 구조에도 반영된다.


`가상 머신(virtual machine,VM)`은 소프트웨어를 실행하는 애플리케이션을 물리 하드웨어로부터 분리시켰다.

이렇게 분리하여 VM을 상이한 랙에 위치한 물리 서버들 간에 문제없이 마이그레이션할 수 있게 했다.

표준 이더넷과 IP 프로토콜은 서버들 간 활성화된 네트워크 연결을 유지한 채로 VM들을 이동시키는 것을 제한한다.

이를 해결하는 방법은 전체 데이터 센터 네트워크를 단일, 평면, 2계층 네트워크로 다루는 것이다.

모든 호스트가 단일 스위치에 연결된 것과 유사한 효과를 얻기 위해 브로드캐스트 대신 DNS 형태의 질의 시스템을 사용하도록 ARP를 수정하고 디렉토리에 VM에 할당된 IP 주소와 데이터 센터 네트워크에서 VM이 현재 연결된 물리 스위치 간 매핑 정보를 관리한다.

광역 인터넷과 달리 데이터 센터 네트워크는 고용량, 초 저지연 환경에서 동작한다.

따라서 데이터 센터의 경우 버퍼 크기가 작으면 TCP 등과 같은 혼잡 제어 프로토콜이 효율적으로 동작하지 못한다.

손실복구와 타임아웃은 데이터 센터를 매우 비효율적으로 만들기 때문에 혼잡 제어 프로토콜은 반응이 빠르고 초 저지연으로 동작해야한다.

이러한 문제를 해결하기 위해 데이터 센터에 적합하도록 TCP를 변형한 방법부터 표준 이더넷에 RDMA(Remote Direct Memory Access)를 구현한 방법이 제안 및 적용되었다.


또 다른 주요 동향은 `선박 컨테이너(shipping container)` 기반의 `모듈화된 데이터 센터(modular data center, MDC)`다.

MDC에서는 표준 12m 선박 컨테이너에 미니 데이터 센터를 구축한 후 컨테이너를 데이터 센터의 위치로 이동시킨다.

컨테이너에는 수십 개의 렉에 최대 수천 개의 호스트들이 촘촘히 포장되어 들어 있다.

데이터 센터 위치에는 여러 컨테이너들이 서로 연결되어 있고 인터넷도 연결되어 있다.

미리 제작된 컨테이너를 데이터 센터에 설치한 후에는 컨테이너에 대한 서비스를 하기 어려울 수 있다.

따라서 컨테이너 성능은 점진적으로 저하되도록 설계하고, 여러 구성요소가 고장나고 성능이 임계치 이하로 떨어지면 컨테이너를 제거하고 교체한다.

MDC에는 각 컨테이너의 내부 네트워크와 컨테이너들을 연결하는 코어 네트워크, 두 종류의 네트워크가 있다.

그러나 일상적인 작업 부하를 처리할 수 있도록 컨테이너들 간에 고속의 호스트-호스트 대역폭을 제공하면서도 수십 만대의 컨테이너들을 상호 연결해주는 코어 네트워크를 설계하는 것은 아직 난제로 남아있다.

대규모 클라우드 제공자가 네트워크 어댑터, 스위치, 라우터, TOR, 소프트웨어, 네트워킹 프로토콜 등 데이터 센터에 있는 모든 것을 계속해서 구축하거나 커스터마이징 한다.


근처 건물들에 데이터 센터를 복제하여 가용 구역을 확보하여 신뢰성을 높인다.

학생 밥이 학교의 이더넷 스위치에 랩톱을 연결하고 `www.google.com`을 다운로드 하는 과정을 보자.


밥은 랩톱을 켠 후 학교 이더넷 스위치에 연결되어 있는 이더넷 케이블에 연결한다.

학교 라우터는 ISP `comcast.net`에 연결되어 있고, `comcast.net` 은 이 학교에 DNS 서비스를 제공하며, DNS 서버는 학교 네트워크가 아닌 컴캐스트 네트워크에 있고 DHCP 서버는 라우터에서 실행되고 있다고 가정하자.

1. 밥의 랩톱 운영체제는 **DHCP 요청 메시지**를 만들어서 이 메시지를 목적지 포트 67(DHCP 서버)과 출발지 포트 68(DHCP 클라이언트)을 갖는 UDP 세그먼트에 넣는다.
   이 UDP 세그먼트는 **브로드캐스트** `IP 목적지 주소(255.255.255.255)`와 출발지 `IP 주소 0.0.0.0`(랩톱이 아직 IP가 없기 때문에)을 갖는 IP 데이터그램에 들어간다.

2. DHCP 요청 메시지를 포함한 IP 데이터그램은 이더넷 프레임에 들어간다.
   스위치에 연결된 모든 장치에 이 프레임이 **브로드캐스트될 수 있도록 이더넷 프레임의 목적지 MAC 주소는** `FF:FF:FF:FF:FF:FF`**로 설정**된다.
   이 프레임의 출발지 MAC 주소는 밥 랩톱의 MAC 주소인 `00:16:D3:23:68:8A` 가 된다.

3. DHCP 요청 메시지를 포함한 브로드캐스트 이더넷 프레임은 밥의 랩톱이 처음으로 이더넷 스위치에 전송한 프레임이다. **스위치는 자신의 모든 출력 포트로 브로드캐스트** 한다.
   - 이때, **자가학습**을 통해 스위치 테이블을 갱신한다.
4. 라우터는 MAC 주소 `00:22:6B:45:1F:1B` 인 인터페이스로 DHCP 요청 메시지가 포함된 브로드캐스트 이더넷 프레임을 수신하고, 이더넷 프레임으로부터 IP 데이터그램을 추출한다.
   데이터그램의 브로드캐스트 IP 목적지 주소는 이 IP 데이터그램이 노드의 상위 계층 프로토콜에 의해 처리되어야함을 의미한다.
   이렇게 함으로써 데이터그램의 UDP 세그먼트가 UDP로 역다중화되고, UDP 세그먼트로부터 DHCP 요쳥 메시지가 추출되고 DHCP 서버는 요청 메시지를 갖게된다.

5. 라우터에서 실행되고 있는 DHCP 서버가 CIDR 블록 `68.85.2.0/24` 에 있는 IP 주소들을 할당할 수 있다고 하자.
   DHCP 서버는 밥의 랩톱에게 주소 `68.85.2.101`을 할당했다고 가정하자.
   DHCP 서버는 이 IP 주소와 DHCP 서버의 IP 주소, 디폴트 게이트웨이 라우터의 IP 주소,서브넷 블록을 포함하는 **DHCP ACK 메시지**를 만든다.
   이 메시지는 UDP 세그먼트에 들어가고 세그먼트는 IP 데이터그램으로 들어가고 데이터그램은 이더넷 프레임으로 들어간다.
   이더넷 프레임은 출발지 MAC 주소로 홈 네트워크로의 라우터 인터페이스의 MAC 주소로, 목적지 MAC 주소로 밥 랩톱의 MAC 주소를 갖는다.

6. DHCP ACK 메시지를 포함한 이더넷 프레임은 라우터에 의해 스위치로 전송된다(유니캐스트).
   스위치는 **자가학습**을 하며 밥의 랩톱으로부터 DHCP 요청 메시지를 포함한 이더넷 프레임을 수신했었기 때문에 `00:16:D3:23:68:8A`를 목적지로 하는 프레임을 밥의 랩톱으로 가는 출력 포트로 전달할 수 있다.

7. 밥의 랩톱은 DHCP ACK 메시지를 수신한 후 이더넷 프레임으로부터 UDP 세그먼트를 추출하고 DHCP ACK 메시지를 추출한다.
   밥의 DHCP 클라이언트는 자신의 IP 주소와 DNS 서버의 IP 주소를 기록한다. 또한 **IP 포워딩 테이블**에 디폴트 게이트웨이의 주소를 저장한다.
   밥의 랩톱은 자신이 속한 서브넷의 외부를 목적지 주소로 하는 모든 데이터그램을 디폴트 게이트웨이로 보내게된다.

`www.google.com` IP주소 알아내기

1. 랩톱 운영체제는 **DNS 질의 메시지**를 생성하며, 이때 DNS 질의 메시지의 질문 부분에 `www.google.com`을 넣는다.
   DNS 질의 메시지는 목적지 포트가 53(DNS 서버)인 UDP 세그먼트에 들어간다.
   UDP 세그먼트는 목적지 IP 주소 `68.87.71.226`(DHCP ACK 메시지에 들어 있던 DNS 서버의 주소)로 하여 IP 데이터그램에 들어간다.

2. 만들어진 이더넷 프레임은 밥의 학교 네트워크에 있는 게이트웨이 라우터로 보내진다.
   밥의 랩톱이 학교 게이트웨이 라우터의 IP 주소를 DHCP ACK 메시지를 통해 알고 있긴 하지만 MAC 주소는 모르므로 **ARP 프로토콜**을 사용한다.

3. 밥의 랩톱은 목표 IP주소 `68.87.2.1` 을 포함한 ARP 질의 메시지를 생성하며 이 메시지는 브로드캐스트 목적지 주소 `FF:FF:FF:FF:FF:FF`를 갖는 이더넷 프레임에 포함되어 스위치로 전송된다.
   스위치는 게이트웨이 라우터를 포함한 모든 연결된 장치로 프레임을 전달한다.

4. 게이트웨이 라우터는 학교 네트워크로의 인터페이스를 통해 프레임을 수신하고, ARP 메시지로부터 목표 IP 주소 `68.85.2.1`을 찾아서 자신의 인터페이스의 IP 주소와 일치하는 것을 알게 된다.
   따라서 게이트웨이 라우터는 `68.85.2.1` 에 대응하는 **MAC주소를 포함하는 ARP 응답 메시지**를 만든다.
   목적지 주소를 랩톱의 MAC주소로 하여 이더넷 프레임에 넣어 스위치로 보내며, 스위치는 이를 랩톱으로 전달한다.
5. 밥의 랩톱은 프레임을 수신해서 게이트웨이 라우터의 MAC주소를 추출한다.
6. 랩톱은 DNS 질의 메시지를 **목적지 MAC주 소를 게이트웨이 라우터의 MAC 주소**로, **IP 목적지 주소로 DNS 서버**로 하여 스위치로 보내고 스위치는 프레임을 게이트웨이 라우터로 전달한다.


1. 게이트웨이 라우터는 프레임을 받아서 DNS 질의가 포함된 IP 데이터그램을 추출한다.
   라우터는 데이터그램의 목적지 주소 `68.87.71.226` 를 **포워딩 테이블**에서 찾아 데이터그램을 컴캐스트의 라우터로 보내야 한다는 사실을 알게되고, 학교 라우터를 컴캐스트의 라우터로 연결해주는 링크에 적합한 링크 계층 프레임에 IP 데이터그램을 넣은 후, 프레임을 해당 링크로 전송한다.
2. 컴캐스트의 좌측 상단 라우터는 프레임을 수신한 후, IP 데이터그램을 추출해서 데이터그램의 목적지 주소와 **포워딩 테이블**(인터넷의 인터 도메인 프로토콜인 **BGP**와 **RIP**,**OSPF**, **IS-IS** 같은 컴캐스트 의 인트라 도메인 라우팅 프로토콜에 의해 결정됨)로 부터 데이터 그램을 DNS 서버로 전달할 출력 인터페이스를 결정한다.
3. IP 데이터그램이 DNS 서버에 도착하고, DNS 서버는 DNS 질의 메시지를 추출한 후 DNS 데이터베이스에서 `www.google.com` 에 해당하는 IP주소를 포함하는 **DNS 자원 레코드**를 찾는다.
   DNS 서버는 DNS 응답 메시지를 만들어서 UDP 세그먼트를 만들고 데이터그램을 만들어 밥의 랩톱을 목적지로 하여 보낸다,
   - DNS 서버에 캐싱되어 있다고 가정하자. google.com에 대해 책임 DNS 서버가 캐싱 데이터를 준 것이다.
4. 밥의 랩톱은 DNS 메시지로부터 `www.google.com` IP 주소를 추출한다.

1. 밥의 랩톱은 먼저 목적지 포트 **80(HTTP)을 갖는 TCP SYN 세그먼트를 생성**하고, TCP 세그먼트를 목적지 주소가 `64.233.169.105`(`www.google.com`)인 IP 데이터그램에 넣은 후 MAC 주소가 게이트웨이 라우터인 프레임에 넣어서 이 프레임을 스위치로 전송한다.
2. 학교 네트워크, 컴캐스트 네트워크, 구글 네트워크에 있는 라우터들은 TCP SYN 세그먼트를 포함하는 데이터그램을 14~16단계 처럼 자신의 포워딩 테이블을 사용해서 `www.google.com` 쪽으로 전달한다.
   - 컴캐스트와 구글 네트워크 사이의 도메인 간 링크상으로 패킷을 전달하는 데 사용되는 라우터의 포웓ㅇ 테이블 엔트리는 BGP 프로토콜에 의해 결정된다.
3. TCP SYN 세그먼트를 포함하고 있는 데이터그램이 `www.google.com` 에 도착한다. TCP SYN 메시지는 포트 80과 연관된 **환영 소켓으로 역다중화** 된다.
   연결 소켓은 구글 HTTP 서버와 밥 랩톱 사이의 TCP 연결을 위해 생성된다.
   **TCP SYNACK 세그먼트를 생성**해서 밥의 랩톱을 목적지로 하는 데이터그램에 넣은 후 `www.google.com` 을 첫 홉 라우터로 연결해주는 링크에 적합한 링크 계층 프레임에 넣는다.
4. TCP SYNACK 세그먼트가 포함된 데이터그램은 구글, 컴캐스트, 학교 네트워크를 통해 밥 랩톱의 이더넷 컨트롤러에 도착한다. 이 데이터 그램은 **18단계에서 생성된 TCP 소켓으로 역다중화**된다.
5. 밥의 브라우저는 가져올 URL이 포함된 HTTP GET 메시지를 생성하고 이를 소켓으로 보내며 이 메시지는 TCP 세그먼트의 페이로드가 된다.
   이 TCP 세그먼트를 데이터그램에 넣어 18~20단계에서처럼 `www.google.com` 로 전달한다.
6. `www.google.com` 에 있는 HTTP 서버는 TCP 연결 소켓으로부터 HTTP GET 메시지를 읽고 HTTP 응답 메시지를 생성하고 요청된 웹 페이지의 콘텐츠를 HTTP 응답 메시지 body에 포함시켜서 TCP 소켓으로 보낸다.
7. HTTP 응답 메시지는 밥의 랩톱에 전달되고, 밥의 웹 브라우저 프로그램은 소켓에서 HTTP 응답 메시지를 읽어서, body로부터 웹페이지에 대한 html을 추출한 후 마침내 웹 페이지를 출력한다.


무선 네트워크는 다음과 같은 구성 요소로 이루어진다.


`무선 호스트(wireless host)`는 유선 네트워크의 경우처럼 **애플리케이션을 실행하는 종단 시스템 장치**다.

e.g., 스마트폰, 태블릿, 랩톱, 센서 등의 IoT(Internet of Things) 장치, 가전제품, 자동차, 그 외 인터넷에 연결된 무수히 많은 장치

호스트는 `무선 통신 링크(wireless communication link)`를 통해 기지국(base station)이나 다른 무선 호스트에 연결된다.

위 그림에서 무선 링크는 네트워크 가장자리에 있는 호스트를 코어에 있는 네트워크 인프라스트럭처로 연결해준다.

무선 링크는 때로는 네트워크 코어에서도 라우터, 스위치 등 네트워크 장치들 사이를 연결해주는 데 사용될 수 있다.


`기지국(base station)`은 기지국에 결합된 무선 호스트와의 **데이터(e.g., 패킷) 송수신에 대한 책임**을 진다.

즉, 자신과 결합되어 있는 다수의 무선 호스트들 사이의 전송을 중재하고 조정한다.

`무선 호스트가 어떤 기지국에 ‘결합(association)되어 있다’`는 것은 아래 두 가지를 의미한다.

1. 호스트가 해당 기지국의 무선 통신 영역 안에 있다.
2. 호스트가 자신과 네트워크 간의 데이터 중계(relay)를 위해 해당 기지국을 사용한다.

기지국의 예

- 셀룰러 네트워크에서의 `셀 타워(cell tower)`
- 무선 네트워크에서의 `AP(access point)`

기지국에 접속된 호스트는 `인프라스트럭처 방식(infrastructure mode)으로 동작한다`고 한다.

이는 주소 할당이나 라우팅 등 기존의 **모든 네트워크 서비스가 기지국을 통해** 네트워크에 연결된 호스트에게 제공되기 때문이다.

이에 반해 `애드혹 네트워크(ad hoc network)`의 경우 무선 호스트는 연결할 수 있는 이런 인프라스트럭처가 없다.

이때 호스트는 스스로 라우팅, 주소 할당, DNS 방식의 이름-주소 변환 등의 서비스를 수행해야 한다.


이동 호스트가 한 기지국 영역을 벗어나 **다른 기지국 영역으로 이동하는 경우**, 중심부에 있는 큰 네트워크로의 접속점을 변경(결합된 기지국을 변경)해야 한다.

이 과정을 `핸드오프(handoff)` 또는 `핸드오버(handover)`라고 한다.

무선 호스트가 통신하고자 하는 큰 네트워크다.


무선 네트워크를 이루는 요소들은 다양한 방식으로 결합되어 여러 가지 형태의 무선 네트워크를 형성할 수 있다.

우리는 다음의 두 가지 기준에 따라 무선 네트워크를 크게 몇 종류로 분류할 수 있다.

1. 무선 네트워크 내의 패킷이 `하나의 홉`만을 거치는가 `여러 홉`을 거치는가?
2. 기지국과 같은 네트워크 `인프라스트럭처`가 있는가, 없는가?

- 좀 더 큰 **유선 네트워크와 연결된 기지국**을 갖고 있다.
- 모든 통신은 이 기지국과 무선 호스트 사이에 **단일 무선 홉**으로 이루어진다.
- e.g.,
  - `802.11 네트워크` : 교실, 음식점, 도서관 등에서 사용
  - `4G LTE 네트워크`


- 유선 네트워크가 연결된 기지국이 없다.
- **단일 홉 네트워크 안의 하나의 노드가 다른 노드들의 전송을 중재, 조정할 수 있다.**
- e.g., `블루투스 네트워크` : 키보드, 스피커, 헤드셋 등 작은 무선 장비들을 연결

- **좀 더 큰 네트워크와 연결된 기지국**이 존재해야 한다.
- 일부 노드들은 기지국와 통신하기 위해 다른 무선 노드들의 중계를 거쳐야 한다.
- e.g.,
  - `일부 무선 센터 네트워크(wireless sensor network)`
  - `무선 메시 네트워크(wireless mesh network)`


- **기지국이 없다.**
- 노드들은 메시지를 목적지에 보내기 위해 여러 노드들의 중계를 거칠 수 있다.
- 노드들은 **이동성**이 있어 노드들 간의 연결성이 변화할 수 있다.
- 이러한 형태의 네트워크는 `이동 애드혹 네트워크(mobile ad hoc network, MANET)`라고 한다.

_책에서는 주로 단일 홉 네트워크와 인프라스트럭처가 있는 네트워크에 논의를 한정한다._

무선 링크는 유선 링크와 다르게 추가로 고려해야 하는 것들이 존재한다.


- 전자기파는 물체를 통과함에 따라 약화된다.
- 자유 공간에서도 전자기파 신호는 분산되고,
  송신자와 수신자 사이의 거리가 증가함에 따라 신호의 세기가 감소한다.

이런 현상을 `경로 손실(path loss)`이라고도 한다.

- **동일 주파수 대역으로 전송되는** 무선 신호들은 서로 `간섭`하게 된다.
- 이러한 송신자 간의 간섭 외에 주변의 전자기 잡음(e.g., 근처의 모터 또는 전자레인지로 인한) 등도 간섭을 일으킬 수 있다.

이런 이유로 최근의 802.11 표준들은 5 GHz 대역에서 동작한다.


송신자와 수신자 간에 전송되는 전자기파의 일부가 물체나 지표에 부딪혀서
서로 길이가 다른 여러 개의 경로를 겨처갈 때 `다중 경로 전파(multipath propagation) 현상`이 생긴다.

이는 수신 측에서 감지되는 신호를 또렷하지 않게 만든다.

이들을 통해 알 수 있듯이, 유선 링크보다는 **무선 링크에서 비트 오류가 더 자주 발생한다.**

따라서 802.11을 포함한 무선 링크 프로토콜은 `강력한 CRC 오류 검출 코드`를 사용할 뿐만 아니라
손상된 프레임을 재전송해주는 `링크 레벨의 신뢰성 있는 데이터 전송 프로토콜`을 사용한다.


> 측정된 수신 신호의 세기와 **잡음**의 상대적인 비율

- 단위 : 데시벨(dB)
  (수신 신호의 진폭과 잡음의 진폭에 각각 밑이 10인 로그함수를 취한 비율의 20배)
- **SNR 값이 커질수록 수신 측에서는 잡음에도 불구하고 원하는 신호를 추출하기 쉬워진다.**

> 송신된 비트가 수신 측에서 오류로 검출될 확률

아래 그림은 이상적인 무선 채널에서 세 가지 변조(modulation) 기법의 비트 오류율을 나타내는 BER 값과 SNR 값의 관계를 보여준다.


이는 송신자가 **출력 세기를 높이면** SNR 값이 커지고,
동시에 수신된 비트에서 오류가 발생할 확률은 낮아지기 때문이다.

그러나 출력 세기를 어느 임계점 이상으로 높이는 것은 이득이 없다.

출력 세기를 높이는 것의 단점은 다음과 같다.

- 출력 세기를 높일수록 송신 장치에서 더 많은 에너지가 소모되며, 이는 배터리를 사용하는 이동 통신 사용자에게는 중요한 문제다.
- 출력 세기를 높이면 다른 송신자의 전송과 더 많은 간섭이 생길 수 있다.

위 그림에서 **SNR 값이 10 dB일 때**를 보자.

- 1 Mbps 전송률의 `BPSK 변조 기법`의 BER 값 = 10^(-7) 이하
- 4 Mbps 전송률의 `QAM16 변조 기법`의 BER 값 = 10^(-1)

10^(-1)는 실제 사용하기에는 지나치게 높은 오류율이기 때문에, 이 환경에서는 `BPSK 변조 기법`이 더 선호된다.

반대로, **SNR 값이 20 dB일 때**를 보자.

- 1 Mbps 전송률의 `BPSK 변조 기법`의 BER 값은 표시되지도 않을 정도로 낮다.
- 4 Mbps 전송률의 `QAM16 변조 기법`의 BER 값 = 10^(-7)

만약 10^(-7) 정도의 BER 값이 별문제가 없다면 이 환경에서는 높은 전송률을 갖는 `QAM16 변조 기법`이 더 선호된다.

_이러한 고찰을 기반으로 다음에 기술한 마지막 특성이 도출된다._


SNR 및 BER 값은 이동성의 결과 또는 환경의 변화로 인해 바뀔 수 있다.

따라서 802.11 와이파이 또는 4G/5G 네트워크 기반의 `셀룰러 데이터 전송 시스템`에서는
주어진 채널 환경에서 적당한 BER를 만족하는 동시에 최고의 전송률을 제공하는 적응적인 변조 기법을 선택할 수 있도록 허용한다.

아래의 상황에서 A가 B로, C가 B로 데이터를 전송한다고 가정하자.

이때 A와 C의 전송 신호가 실제로 목적지 B에서 간섭됨에도 불구하고
산이나 건물 등의 환경적인 장애물로 인해 **A와 C는 서로 상대방의 전송을 인지하지 못하는** 일이 생긴다.

이를 `숨은 터미널 문제(hidden terminal problem)`한다.


신호가 무선 매체를 통과함에 따라 신호 세기가 약해지는 현상을 말한다.

위 그림에서 A와 C가 서로의 전송을 검출하기에는 충분하지 않은 세기의 신호를 수신하는 거리에 있으나,
이들 신호가 중간에 있는 B에서는 간섭된다.

`코드 분할 다중 접속(code division multiple access, CDMA)`은 **채널 분할 접속 프로토콜**의 하나로서,
무선 랜 및 셀룰러 기술에서 아주 많이 사용되고 있다.

<details>
<summary>채널 분할 접속 프로토콜</summary>
공유 매체를 통해 호스트들이 통신할 때, 여러 송신자에 의해 전송된 신호가 수신 측에서 간섭되지 않게 해주는 프로토콜
</details>

CDMA 프로토콜에서는 송신자가 전송하는 각 비트를 확장해서
애초의 데이터 비트열보다 훨씬 빠른 속도(`칩 속도(chipping rate)`)로 변화되도록 하는 신호(코드)를 곱하는 방식으로 인코딩한다.

아래의 간단하고 이상적인 CDMA 인코딩/디코딩 시나리오를 보자.

데이터 비트들이 **CDMA 인코더에 도착하는 속도에 의해** 시간의 단위가 정의된다고 가정하자.

즉, 전송되는 각각의 원래 데이터 비트는 한 `비트 슬롯` 시간이 필요하다.

i번째 비트 슬롯의 데이터 비트값을 `di`라고 하자.

계산의 편의상, 1 값을 갖는 데이터 비트는 `1`로, 0 값을 갖는 데이터 비트는 `-1`로 표시한다.

각 비트 슬롯은 M개의 미니슬롯들로 더 분할된다. (그림에서는 M = 8)

- 송신자가 사용하는 **CDMA 코드**는 일련의 연속된 M개의 값, `Cm(m = 1, … , M)`으로 구성된다.
- 각각의 Cm 값은 1 또는 - 1 값을 갖는다.


CDMA의 동작을 구체적으로 알아보기 위해, i번째 데이터 비트인 `di`에 대해 살펴보자.

수신자는 `인코딩된 바이트열 Zi,m`을 수신해서 다음과 같이 합성함으로써 `원래의 데이터 비트 di`를 생성한다.

위의 시나리오 그림에서 해당 식을 통해 원래 데이터 비트가 수신자에 의해 정확히 얻어지는 것을 확인할 수 있다.

현실에서는 서로 간섭하는 다수의 송신자가 존재한다.

이 경우, CDMA 수신자는 다른 송신자들이 전송한 비트들과 섞여 있는 상황에서 내 송신자의 원래 데이터 비트를 어떻게 다시 생성할 수 있을까?

> CDMA는 **동시에 전송되어 간섭하는 비트 신호들을 더할 수 있다**는 전제하에 동작한다.

e.g., 같은 미니슬롯에서 3명의 송신자가 1의 값을 전송하고 4번째 전송자가 -1의 값을 전송한다면,
그 미니슬롯에서 모든 수신자가 수신하는 신호는 2(= 1+1+1-1)가 된다.

다수의 송신자가 있는 경우에도 송신자 s는 아래 식을 사용해서 자신의 인코딩된 전송 비트열을 정확히 계산한다.
_(위에서의 식과 동일)_

i번째 비트 슬롯의 m번째 미니슬롯은 그 미니슬롯 동안 모든 N개의 송신자가 전송한 비트들의 `합`이 된다.

만약 송신자의 코드가 조심스럽게 선택되었다면,
수신자는 다수 송신자로부터의 혼합된 신호로부터 원하는 송신자가 전송한 데이터만을 아래 식과 같이 특정 송신자 코드를 사용해서 쉽게 추출해낼 수 있다.

아래는 **두 송신자**가 존재할 때, 수신자가 위쪽 송신자로부터의 원래 데이터 비트열을 구하는 과정을 나타낸다.

수신자는 아랫쪽 송신자의 간섭에도 불구하고 첫 번째 송신자의 데이터를 추출할 수 있다.

> 💡 CDMA는 (시간이나 주파수가 아닌) <b>코드를 분할(partitioning)</b>해서 각 노드에게 적당한 코드를 할당하는 분할 프로토콜이다.

위에서는 CDMA에 대한 필수적인 설명만 했지만, 실제로는 많은 어려운 문제들이 있다.

1. CDMA 수신자가 특정 송신자의 신호를 추출해낼 수 있도록 CDMA 코드를 조심스럽게 선택해야 한다.
2. 앞에서는 여러 송신자로부터의 신호 세기가 수신자 쪽에서 동일하다고 가정했으나, 실제 상황에서 이런 경우는 드물다.


1990년대 다양한 `무선 랜(wireless LAN)` 관련 기술 및 표준이 개발되었으나
그중 가장 성공적인 기술, <b>와이파이(WiFi)</b>라고 알려진 `IEEE 802.11 무선 랜`이 관련 기술들을 통합하게 되었다.


- 일반적으로 거리가 70m 미만인 영역에서 동작하는 WLAN 용도
- 이전 표준과의 `역방향 호환성`을 갖는다.
  즉, 802.11g 기능만을 갖는 이동 단말도 802.11ac 또는 802.11ax 기지국과의 상호작용이 가능하다.
- 모두 `CSMA/CA`라는 동일한 매체 접속 프로토콜을 사용한다.

- IoT, 센서 네트워크, 측정 애플리케이션을 활용하기 위한 용도 (좀 더 먼 거리에서 동작)


802.11 무선 랜 장치들은 두 종류의 주파수 영역에서 동작한다.

- 5.1~5.8 GHz 주파수 영역
- 비허가(unlicensed) 주파수 대역
- 이 영역에서 802.11 장치들은 2.4 GHz 무선 전화 및 가전제품과 주파수 경쟁을 하게 된다.


- 전력 수준이 동일할 경우 전송 거리가 더 짧고 다중 경로 전파의 영향을 더 많이 받는다.

`802.11n, 802.11ac, 802.11ax 표준`은 `MIMO(multiple input multiple-output) 안테나`를 사용한다.

이는 송신과 수신 측에 각각 2개 이상의 안테나가 있어 각기 다른 신호를 송수신하는 방식이다.

`802.11ac, 802.11ax 기지국`은 여러 개의 스테이션을 동시에 전송할 수 있으며,
목적지에 따라 동적으로 수신자의 방향을 향해 전송할 수 있는 `스마트 안테나`를 사용한다.

이는 간섭을 줄이고, 동일한 데이터 전송률에서의 도달 거리를 향상하는 기능을 한다.


다음은 802.11 무선 랜 구조의 핵심적인 구성요소를 보여준다.

- 802.11 구조의 가장 근본적인 구성 단위
- 구성
  - 하나 이상의 `무선 단말기`
  - 하나의 기지국(base station) 즉, `AP(access point)`
- 전형적인 홈 네트워크에서는 BSS를 인터넷으로 연결하는 AP와 라우터가 각각 필요하다.


- **802.11 무선 기지국**은 6바이트의 MAC 주소를 가진다.
  - MAC 주소는 스테이션의 어댑터(802.11 네트워크 인터페이스 카드) 펌웨어에 저장되어 있다.
- **각각의 AP**도 자신의 무선 인터페이스에 대한 MAC 주소를 갖는다.
- MAC 주소는 IEEE에 의해 관리되며, 이론적으로는 전 세계에서 유일성을 갖는다.

- AP를 가진 무선 랜
- `네트워크 인프라스트럭처` : AP, 그리고 AP를 인터넷 라우터와 연결해주는 유선 이더넷 구조를 통칭한다.


- **중앙 제어나 외부 네트워크로의 연결 인프라가 없는 경우**를 말한다.
  - e.g., 랩톱을 가진 사람들이 중앙 제어되는 AP가 없는 환경(회의실, 기차, 자동차 등)에서 만나 데이터를 교환할 때
- 네트워크는 근접한 이동 장치들 사이의 연결을 통해 즉흥적으로 형성된다.
  - 이미 존재하는 다른 네트워크 인프라스트럭처에 기댈 수가 없고 따라서 가까이 있는 장치들이 서로 찾아서 통신해야 하기 때문이다.

아래 그림은 IEEE 802.11 스테이션들이 `애드혹 네트워크`를 형성하기 위해 서로를 그룹으로 연결하는 상황을 보여준다.

802.11에서 개별 무선 단말기는 네트워크 계층 데이터를 송신 또는 수신하기 전에 **하나의 AP와 결합(association)되어 있어야 한다.**

_모든 802.11 표준에서 결합을 사용하고 있지만, 특히 `IEEE 802.11 b, g, n, ac, ax 환경`에서 이 주제를 논의하겠다._

- 네트워크 관리자가 AP를 설치할 때 AP에서 하나 또는 두 단어로 된 `SSID(Service Set Identifier)`를 할당한다.
- 관리자는 AP에게 `채널 숫자`를 할당해야 한다.
  - 802.11은 2.4~2.4835 GHz 주파수 범위에서 동작한다.
  - 이 80여 MHz 주파수 대역에서 11개의 일부가 겹치는 채널들을 정의하고 있기에
    서로 다른 2개의 채널은 **4개 채널 이상의 간격으로 분리되어 있어야만 겹치지 않는다.**


> `무선 스테이션`이 **둘 이상의 AP로부터** 충분히 강한 신호를 받을 수 있는 모든 지역

이러한 AP들은 각기 다른 IP 서브넷에 있을 수 있고, 독립적으로 채널을 할당했을 수도 있다.

무선 스테이션이 인터넷에 접속하기 위해서는 정확히 하나의 서브넷에 들어가야 하므로 **단 하나의 AP와 결합되어야 한다.**

(결합 = 무선 스테이션이 AP와 가상 회선을 만드는 것)

1. 802.11 표준은 AP가 주기적으로 `비컨 프레임(beacon frame)`을 전송할 것을 요구한다.

   - 비컨 프레임(beacon frame)에는 AP의 `SSID`와 `MAC 주소`가 포함된다.

2. 무선 스테이션은 주변 AP로부터의 비컨 프레임을 찾기 위해 11개 채널을 살펴본다.

3. **비컨 프레임으로부터 사용 가능한 AP들의 정보를 얻은** 무선 스테이션은 결합을 맺을 AP를 하나 선택한다.
   - 802.11 표준은 사용 가능한 AP 중 어떤 것을 선택할 것인지를 정하는 알고리즘을 정의하지 않고 있으며,
     이는 무선 스테이션의 펌웨어 또는 소프트웨어 설계자에 의해 결정된다.
   - 일반적으로는 비컨 시그널의 세기가 가장 강한 AP를 선택한다.

`수동적 스캐닝(passive scanning)` : **비컨 프레임의 수신을 통해** 채널을 찾는 과정

1. AP들로부터 비컨 프레임이 전송된다.
2. H1에서 선택된 AP로 결합 요청 메시지를 전송한다.
3. 선택된 AP에서 H1으로 결합 수락 메시지를 전송한다.

무선 호스트는 능동적 스캐닝 과정을 수행할 수 있다.

`능동적 스캐닝(active scanning)` : 무선 스테이션이 영역 안에 있는 AP들에게 **탐사용 프로브(probe) 프레임을 방송**하는 방식

1. `탐사용 프로브 프레임`이 H1으로부터 방송된다.
2. AP들로부터 `프로브 응답 메시지`가 도착한다.
3. H1에서 선택된 AP로 결합 요청 메시지를 전송한다.
4. 선택된 AP에서 H1으로 결합 수락 메시지를 전송한다.

스테이션의 첫 번째 프로브 요청에 응답한 AP는 여러 개의 응답한 AP 중 어떤 것이 선택될지 모르기 때문에 두 번째 `요청/수락 핸드셰이킹 통신`이 필요하다.

AP와의 결합 단계가 끝난 후, 무선 스테이션은 `AP의 서브넷 IP 주소`를 얻기 위해서 결합된 AP를 통해 서브넷으로 ‘`DHCP 발견 메시지`’를 전송한다.

서브넷 주소를 얻으면 인터넷의 나머지 노드는 이 무선 스테이션을 선택된 AP의 서브넷 내부의 IP 주소를 지닌 한 호스트로 여기게 된다.

무선 스테이션이 특정 AP와 결합하기 위해서는 해당 AP에게 자신을 `인증(authentication)`해야 할 때도 있다.

- e.g., 스테이션의 MAC 주소를 기반으로 무선 네트워크로의 접근을 허용 / 사용자 이름과 암호를 입력
- AP는 `인증 서버`와 통신하며, 무선 종단 스테이션과 인증 서버 사이에서 RADIUS DIAMETER 같은 프로토콜을 사용해서 정보를 중계한다.


무선 스테이션이 AP와 결합되면 AP와 데이터 프레임을 송수신할 수 있다.

그러나 AP 자신을 포함한 **여러 스테이션이 동시에 동일한 채널로 데이터 프레임을 전송할 수 있으므로**
전송을 조정하기 위해 `다중 접속 프로토콜`이 필요하다.

다중 접속 프로토콜은 크게 세 가지 방법으로 분류된다.

- 채널 분할 (e.g., CDMA)
- **랜덤 접속**
- 순번제

이더넷에서 랜덤 접속 프로토콜이 커다란 성공을 함에 따라 무선 랜에서도 랜덤 접속 프로토콜이 사용된다.

802.11 무선 랜에서 사용되는 랜덤 접속 프로토콜은 `CSMA/CA(carrier sense multiple access with collision avoidance)`다.

즉, 스테이션이 전송하기 전에 채널 상태를 감지하고(sense), 만일 채널이 사용 중이면 전송하지 않는다.

이더넷과 802.11 모두 채널을 감지하는 랜덤 접속 프로토콜을 사용하지만,
이들 `MAC(Medium Access Control, 매체 접속 제어) 프로토콜`에는 차이가 있다.

1. 802.11은 충돌 검출(collision detection)을 사용하지 않고 `충돌 회피(collision avoidance)` 기술을 사용한다.

   - 이유
     - 충돌 검출을 하려면 (스테이션 자신의 신호) 송신과 (다른 스테이션의 전송 여부 결정을 위한) 수신이 동시에 가능해야 한다.
       일반적으로 802.11 어댑터에서 **수신 신호의 세기는 송신 신호의 세기에 비해 아주 약하므로**, 송수신을 모두 고려하여 충돌을 검출할 수 있는 하드웨어를 만드는 데는 많은 비용이 든다.
     - 동시에 송수신이 가능하고 다른 스테이션에 의한 채널 사용을 감지했을 때 전송을 중단할 수 있다고 하더라도,
       `숨은 터미널 문제`와 `페이딩` 때문에 충돌을 검출하지 못할 수도 있다.
   - 따라서 802.11 무선 랜은 일단 스테이션이 프레임을 전송하기 시작하면 **그 프레임을 모두 전송하고, 이를 중단할 수 없다.**
     - 충돌이 빈번할 때 프레임 전체를 전송하면 다중 접속 프로토콜의 성능이 상당히 저하될 수 있기 때문에 몇 가지 충돌 회피 기술을 사용한다.

2. 802.11에서는 `링크 계층 ARQ(ACK/재전송) 방식`을 사용한다.

무선 랜에서 송신 스테이션이 전송한 프레임은 여러 가지 이유(숨은 터미널 문제, 페이딩 등)로 목적지 스테이션에 제대로 도달하지 못할 수 있으며,
이를 해결하기 위해 802.11 MAC에서는 `링크 계층 ACK(link-layer acknowledgment)`를 사용한다.

1. 목적지 스테이션은 **CRC 검사를 통과한 프레임을 수신하면**
   `SIFS(Short Inter-Frame Spacing)`라는 짧은 시간을 기다린 후에 `ACK 프레임`을 송신 스테이션에게 보낸다.

2. (1) 만일 송신 스테이션이 주어진 시간 동안에 ACK를 수신하지 못하면, 송신 스테이션은 오류가 발생했다고 가정한다.

   (2) 송신 스테이션은 다시 `CSMA/CA 프로토콜`을 사용해서 채널 접속을 한 후 프레임을 재전송한다.

3. 일정 횟수만큼의 재전송 후에도 ACK를 수신하지 못하면, 송신 스테이션은 포기하고 프레임을 폐기한다.


스테이션(무선 장치나 AP)이 전송할 프레임을 갖고 있다고 가정하자.

1. 스테이션은 **채널이 사용되지 않음을 감지하면** `DIFS(Distributed Inter-frame Space)`라는 짧은 시간 동안 기다린 후에 프레임을 전송한다.

2. 그렇지 않고 **채널이 사용 중이면** 스테이션은 `백오프 방식`에 따라 선택된 임의의 시간 동안 대기한다. (6.3.2절 참고)

   - DIFS 시간 이후에 **채널이 사용되지 않음을 감지하면** 선택된 시간의 카운터값은 감소하며,
     **채널 사용이 감지되면** 카운터값을 그대로 고정한다.

3. **카운터가 0에 도달하면 스테이션은 프레임 전체를 전송한 후에 ACK를 기다린다.**

   - 카운터가 0에 도달하는 것은 채널이 사용되지 않을 때만 가능하다.

4. (1) **ACK를 수신하면** 송신 스테이션은 프레임이 목적지 스테이션에 의해 제대로 수신되었음을 알게 된다.
   → 만일 스테이션에 전송할 프레임이 또 있다면 2단계의 CSMA/CA 프로토콜을 수행한다.

   (2) **ACK를 수신하지 못하면** 송신 스테이션은 좀 더 증가된 임의의 시간값을 선택한 후, 2단계의 백오프 과정을 수행한다.

---

- 이더넷의 `CSMA/CD(collision detection) 다중 접속 프로토콜`
  : 채널이 사용되지 않는 유휴 상태임을 감지한 스테이션은 바로 전송을 시작한다.

- 802.11의 `CSMA/CA(collision avoidance) 프로토콜`
  : 채널이 사용되지 않는 상태임을 감지하더라도 스테이션은 임의의 백오프값을 선택하여 **카운트다운 과정**을 거치므로 전송을 지연시킨다.

> 각각 전송할 프레임을 가진 2개의 스테이션이 **또 다른 제3의 스테이션이 이미 전송하고 있음을 감지했기 때문에 바로 전송하지 않는 상황**을 생각해보자.

이더넷 `CSMA/CD`에서는 전송 중이었던 스테이션이 전송을 마치면 이 두 스테이션이 바로 전송을 시작한다.

- 이 경우에 충돌이 발생하며, CSMA/CD에서는 두 스테이션 모두 **전송을 즉시 중단한다.**
- **충돌을 겪은 프레임의 나머지 부분을 전송하지 않음**으로써 불필요한 전송을 피하므로 문제가 심각해지지 않는다.

  802.11은 충돌을 검출하지 않으며 전송을 중단하지도 않는다.

- 이에 충돌을 겪은 프레임이라도 전체를 다 전송하기 때문에, **802.11의 목표는 가능한 한 충돌을 회피하는 것이다.**

- **두 스테이션이 채널이 현재 사용 중임을 감지하면** 아래와 같은 방식으로 충돌을 회피한다.

  1. 이들은 `랜덤 백오프(random backoff) 기법`을 수행하여 임의의 백오프값을 선택한다.
  2. 선택된 백오프 시간이 다른 경우, 채널이 사용되지 않는 유휴 상태에 도달했을 때
     1. 경쟁 중인 두 스테이션 중 하나가 다른 스테이션보다 먼저 전송을 시작하며,
     2. ‘경쟁에서 진 스테이션’은 ‘이긴 스테이션’의 신호를 감지하고 자신의 카운터를 멈춘 후
     3. 경쟁에서 이겨 전송 기회를 획득한 스테이션이 전송을 완료할 때까지 기다린다.

- 이 상황에서도 두 스테이션이 서로 숨은 터미널이거나 두 스테이션이 선택한 임의의 백오프값이 너무 가까울 경우 충돌이 생길 수 있다.

802.11 MAC 프로토콜은 `숨은 터미널`이 존재하더라도 충돌을 회피할 수 있는 예약 방법을 선택할 수 있도록 제공한다.

아래의 상황에서는 2개의 무선 스테이션(H1, H2)과 하나의 AP가 있다.

두 무선 스테이션은 동일한 AP의 영역 내에 있으며 이 AP와 결합되어 있는데,
`페이딩` 때문에 **각 무선 스테이션은 AP로부터는 잘 보이지만 그들 서로 간에는 숨어 있다.**

_숨은 터미널이 왜 문제일까?_

스테이션 H1이 프레임을 AP로 전송하고 있고, H1이 전송하는 도중에 스테이션 H2가 AP로의 전송을 원한다고 가정하자.

H1의 전송을 듣지 못한 H2는 임의의 시간(DIFS)을 기다린 후에 DATA 프레임을 전송하며 충돌이 발생하게 되고,
이에 H1의 전체 전송 시간과 H2의 전체 전송 시간 동안 채널이 낭비된다.

이 문제를 해결하기 위해 IEEE 802.11 프로토콜에서는
스테이션들이 짧은 `RTS(Request to Send) 제어 프레임`과 짧은 `CTS(Clear to Send) 제어 프레임`을 주고받게 함으로써 채널 접속을 **예약**할 수 있게 한다.

1. 송신자는 DATA 프레임을 전송하고 싶으면, 먼저 `RTS 프레임`을 **AP에게 보냄**으로써
   DATA 프레임과 ACK 프레임을 전송하는 데 필요한 전체 시간을 알려준다.

2. AP가 RTS를 수신하면 이에 대한 응답으로 `CTS 프레임`을 **영역 내의 모든 스테이션에게 전송한다.** (송신 스테이션 포함)
   - 송신자에게는 전송할 수 있다는 허가를 알려준다.
   - 다른 스테이션들에게는 예약된 시간 동안 전송하지 못하게 한다.

RTS와 CTS 프레임을 사용하면 다음과 같이 두 가지 측면에서 성능이 향상된다.

- 채널을 예약한 다음에만 길이가 긴 DATA 프레임을 전송하기 때문에 숨은 스테이션 문제가 완화될 수 있다.
- RTS와 CTS 프레임은 길이가 짧으며, RTS/CTS 프레임에 의한 충돌은 짧은 RTS/CTS 프레임이 전송되는 동안에만 발생한다.
  일단 RTS와 CTS 프레임이 제대로 전송되면, 그 뒤에 오는 DATA와 ACK 프레임은 충돌 없이 전송된다.

하지만 이들로 인해 지연과 채널 자원의 낭비가 생긴다.

따라서 실제로 무선 스테이션에서는 `RTS 임계치`를 설정하여,
**임계치보다 긴 DATA 프레임을 전송할 때만 RTS/CTS 교환을 통해 채널을 예약할 수 있도록 한다.**


만일 두 노드가 `지향성 안테나(directional antenna)`를 갖고 있다면
**지향성 안테나로 상대방을 가리킴으로써 지점 간의 링크를 형성**하고, 이 링크에 대해 802.11 프로토콜을 실행할 수 있다.

비용이 저렴한 802.11 하드웨어에 지향성 안테나와 증가된 전송 전력(power)을 사용함으로써
802.11은 수십 km 거리의 무선 지점 사이에 연결을 제공하는 저렴한 수단으로 사용될 수 있다.

802.11 프레임은 이더넷 프레임과 유사하지만, 무선 링크 사용에 특화된 몇 개의 필드를 갖고 있다.

아래 그림은 802.11 프레임을 표시한 것인데,
프레임의 각 필드 위의 숫자는 필드 길이를 **바이트** 단위로 나타낸 것이다.

`Frame Control 필드`의 서브필드(subfield) 위의 숫자는 서브필드의 길이를 **비트** 단위로 나타낸 것이다.


- `페이로드(payload)`는 보통 하나의 IP 데이터그램이나 ARP 패킷이다.
  (최대 2,312바이트까지 허용, 하나의 데이터그램이나 ARP 패킷을 포함함)

- 32비트의 `CRC`를 통해 802.11 프레임은 **수신자가 수신한 프레임의 비트 오류를 검출할 수 있다.**
  (비트 오류는 유선 랜보다 무선 랜에서 훨씬 많이 발생하므로 CRC 기법은 무선 랜에서 더 유용함)

802.11 프레임의 가장 큰 차이점은 **4개의 주소 필드**를 갖고 있다는 것이다.

각 주소 필드는 6바이트의 MAC 주소를 포함할 수 있다.

왜 주소 필드가 4개나 필요할까?

- `네트워크 연동(internetworking)`을 위해서는 3개의 주소가 필요하다.
  - e.g., 무선 스테이션에서 AP를 통해 라우터 인터페이스로 네트워크 계층 데이터그램을 전송하는 경우
- 네 번째 주소는 `애드혹 네트워크 모드`에서 사용된다.

  802.11 표준에서는 처음 3개의 주소 필드를 다음과 같이 정의한다.


- **프레임을 전송하는** 스테이션의 MAC 주소
- e.g.,
  - 무선 스테이션이 프레임을 전송하면 그 스테이션의 MAC 주소가 이 필드에 삽입된다.
  - AP가 프레임을 전송하면 AP의 MAC 주소가 이 필드에 삽입된다.

- **프레임을 수신하는** 무선 스테이션의 MAC 주소다.
- e.g.,
  - 이동 무선 스테이션이 프레임을 전송하면 Address 1에는 목적지 AP의 MAC 주소가 삽입된다.
  - AP가 프레임을 전송하면 Address 1에 목적지 무선 스테이션의 MAC 주소가 삽입된다.


- AP와 무선 기지국들로 구성된 BSS는 서브넷의 일부이고, 이 서브넷은 라우터 인터페이스를 통해 다른 서브넷으로 연결된다.
- Address 3은 이 **라우터 인터페이스**의 MAC 주소를 포함한다.

> 💡 Address 3은 BSS를 유선 랜과 연동하는 데 핵심적인 역할을 한다.

아래의 예시를 보자.

- 2개의 AP가 있으며, 각 AP는 다수의 무선 스테이션들을 책임진다.
- 각 AP는 라우터에 직접 연결되어 있으며, 라우터는 글로벌 인터넷에 연결되어 있다.
- **AP는 링크 계층 장치이기에 네트워크 계층인 IP 기능을 갖지 않으며, IP 주소를 이해하지도 못한다.**

> 1️⃣ `라우터 인터페이스 R1`로부터 `무선 스테이션 H1`로 데이터그램을 전달한다고 하자.

라우터는 자신과 H1 사이에 AP가 존재한다는 사실을 알지 못하며, H1을 자신에게 연결된 서브넷 중 하나에 대한 호스트 정도로 생각한다.

1. (1) 데이터그램의 목적지 주소로부터 H1의 IP 주소를 알게 된 라우터는 `ARP`를 사용해서 H1의 MAC 주소를 결정한다.

   (2) H1의 MAC 주소를 획득한 라우터 인터페이스 R1은 `이더넷 프레임` 내에 데이터그램을 캡슐화한다.

   - 출발지 주소 필드 : R1의 MAC 주소
   - 목적지 주소 필드 : H1의 MAC 주소

2. 이더넷 프레임이 AP에 도착하면
   AP는 이 프레임을 무선 채널로 전송하기 전에 **802.3 이더넷 프레임을** `802.11 프레임`**으로 변환한다.**
   - Address 1 필드 : H1의 MAC 주소
   - Address 2 필드 : AP 자신의 MAC 주소
   - Address 3 필드 : R1의 MAC 주소

따라서 H1은 Address 3으로부터 데이터그램을 서브넷으로 전송한 라우터 인터페이스의 MAC 주소를 알 수 있다.

> 2️⃣ `무선 기지국 H1`이 응답으로 R1에게 데이터그램을 전송한다고 하자.

1. H1은 `802.11 프레임`을 생성한다.

   - Address 1 필드 : AP의 MAC 주소
   - Address 2 필드 : H1의 MAC 주소
   - Address 3 필드 : R1의 MAC 주소

2. AP가 이 802.11 프레임을 수신하면 이것을 `이더넷 프레임`으로 변환한다.
   - 출발지 주소 필드 : H1의 MAC 주소
   - 목적지 주소 필드 : R1의 MAC 주소

따라서 AP가 이더넷 프레임을 구성할 때 Address 3으로부터 목적지 MAC 주소를 결정할 수 있게 해준다.

802.11에서는 한 스테이션이 다른 스테이션으로부터 프레임을 제대로 수신할 때마다 ACK를 보낸다.

ACK가 손실될 수 있으므로 송신 스테이션은 같은 프레임을 여러 번 보낼 수도 있는데,
`Sequence Number 필드`로 순서 번호를 사용함으로써 수신자는 **새로 전송된 프레임과 재전송된 프레임을 구분**할 수 있다.

802.11 프로토콜에서 송신 스테이션은 데이터 프레임을 전송하는 시간과 ACK를 전송하는 시간을 포함한 시간 동안 **채널을 예약**할 수 있다.

데이터 프레임과 RTS 및 CTS 프레임 모두에 대해 이 시간값은 해당 프레임의 `Duration 필드`에 포함된다.

`Frame Control 필드`는 여러 개의 서브필드로 구성된다.

- `Type 필드`와 `Subtype 필드` : 결합, RTS, CTS, ACK, 데이터 프레임을 구분하는 데 사용된다.

- `To 필드`와 `From 필드` : 주소 필드들의 의미를 정의하는 데 사용된다.

  - 주소 필드가 갖는 의미는
    (1) 애드혹 또는 인프라스트럭처 방식의 사용 여부에 따라서,
    (2) 인프라스트럭처 방식의 경우는 프레임을 무선 기지국이 전송하는지, AP가 전송하는지 여부에 따라서 달라진다.

- `WEB 필드` : 암호화 사용 여부를 나타낸다.


무선 랜의 물리적 영역을 증가시키기 위해 동일한 IP 서브넷에 여러 개의 BSS를 설치하기도 한다.

따라서 무선 스테이션이 기존 TCP 세션을 유지한 채로 어떻게 한 BSS에서 다른 BSS로 매끄럽게 이동할 수 있는가 하는 이동성 문제가 발생한다.

위 그림에서 두 BSS를 연결하는 장치는 라우터가 아니며, 두 BSS에 있는 AP를 포함한 모든 기지국은 동일한 IP 서브넷에 속한다.

따라서 호스트 H1이 BSS1에서 BSS2로 이동할 때 H1의 IP 주소는 동일하게 유지되며, 현재 진행 중인 TCP 연결도 유지될 수 있다.

만약 연결 장치가 라우터인 경우, H1은 자신의 IP 주소를 새로 진입한 서브넷에 맞게 변경하기 위해
현재 진행 중인 TCP 연결을 잠시 중단하거나 종료해야할 수도 있다.

→ 이동 IP(mobile IP)와 같은 네트워크 계층의 이동성 프로토콜을 사용

1. H1은 AP1에서 떠나면서 그의 신호가 약해지는 것을 감지하고, 더 강한 신호를 찾기 시작한다.
2. H1은 AP2로부터 `비컨 프레임`을 수신하면, 자신의 IP 주소와 진행 중인 TCP 세션을 유지한 채로 AP1과의 결합을 끊고 AP2와 새로운 결합을 만든다.


스위치는 ‘자가학습’을 하고 자동으로 포워딩 테이블을 구성할 수 있지만,
TCP 연결을 유지한 채로 BSS들 사이의 이동을 하는 사용자는 지원하지 못한다.

- H1이 BSS1에 있으면 H1의 데이터그램은 AP1로 전달되어야 한다.
- H1이 BSS2에 있으면 H1의 데이터그램은 AP2로 전달되어야 한다.

1. H1이 BSS2와 결합을 새로 설정한 다음에
2. AP2로 하여금 **출발지 주소가 H1인** `이더넷 프레임`**을 스위치로 브로드캐스트**하게 만든다.
3. 이 프레임을 수신한 스위치는 포워딩 테이블을 갱신함으로써 AP2를 통해 H1에 도달할 수 있다.


앞서 보았듯이, 상이한 SNR 환경에 따라 전송률의 차이가 있는 각각 다른 변조 기법이 적합할 수 있다.

기지국으로부터 20 m 떨어져 있고 **높은 SNR**을 갖는 802.11 이동 사용자를 가정해보자.

- 빠른 전송률을 갖는 물리 계층 변조 기법을 사용하면서도 BER를 낮게 유지할 수 있다.
- 하지만 사용자가 기지국으로부터 멀어지는 방향으로 걸어감에 따라 SNR가 낮아지는 경우라면 BER가 허용할 수 없을 만큼 높아질 것이다.

따라서 일부 802.11 구현은 `전송률 적응(rate adaptation)` 기능을 갖고 있다.

이는 현재 또는 최근의 채널 상황에 맞추어 물리 계층 변조 기법을 적응적으로 선택할 수 있게 한다.

(TCP 혼잡 제어 기법과 유사)

802.11 표준은 노드가 신호 감지와 송수신 기능 및 다른 전력 소모가 많이 필요한
기능을 수행하는 데 사용되는 시간을 최소화할 수 있도록 하는 `전원 제어 방법`을 제공한다.

1. 노드는 명시적으로 `수면 상태(sleep state)`와 `동작 상태(wake state)`를 오가며 상태를 변화시킨다.

2. 노드는 802.11 프레임의 `전력 제어 비트`를 1로 세팅함으로써 AP에게 자신이 수면 모드로 돌입할 것임을 알린다.

3. 이때 노드 내의 타이머가 AP가 비컨 신호를 보내기 직전에 노드가 깨어날 수 있도록 설정된다.

4. AP는 수면 상태의 노드로 프레임을 전송하지 않으며, 해당 호스트에게 향하는 프레임을 나중에 전송하기 위해 버퍼에 저장한다.

5. 수면 상태의 노드는 **AP로부터 비컨 신호가 전송되기 직전에** 깨어나 재빨리(250 µs) 완전한 `활성 상태(active state)`로 전환한다.
   - AP로부터 전송되는 비컨 신호에는 AP에 버퍼링 되어 있는 프레임들을 전달받아야 할 노드 목록이 포함되어 있다.
   - 만약 깨어난 노드가 버퍼링 목록상에 없다면 그 노드는 다시 수면 상태로 들어갈 수 있다.
   - 그렇지 않다면 해당 노드는 AP에게 폴링(polling) 메시지를 전송함으로써 저장되어 있는 프레임의 전송을 요구하게 된다.


`블루투스(Bluetooth) 네트워크`는 수십 미터 이하의 단거리에서 저전력, 저비용으로 동작한다.

따라서 `WPAN(wireless personal area network)` 또는 `피코넷(piconet)`이라고도 한다.

블루투스 네트워크에는 많은 `링크 레벨 네트워킹 기술`로 가득 차 있다.

- 시분할 다중화(TDM) 및 주파수 분할
- 랜덤 백오프
- 폴링
- 오류 검출과 정정
- ACK/NAK을 이용한 신뢰성 있는 전송

`무선 ISM(Industrial, Scientific, Medical) 밴드`로서, 허가가 필요 없는 `2.4 GHz 대역`에서 동작한다.

즉, 같은 주파수 대역을 사용하는 가전제품들(전자레인지, 가정용 무선전화 등)과 경쟁하기 때문에 **명시적으로 소음과 간섭 현상을 염두에 두고 설계되었다.**


블루투스 무선 채널은 **625마이크로초의 시간 슬롯**을 가진 `TDM 방식`으로 동작한다.

- 각 시간 슬롯마다 송신자는 79개 채널 중의 하나로 전송하며 슬롯마다 주파수 채널을 변경한다.
- 변경할 주파수 채널 선택은 난수에 의한 `의사 무작위 추출(pseudo-random) 방식`을 사용한다.

이런 형태의 주파수 변경 또는 주파수 도약 기법은 `주파수 도약 확산 스펙트럼(frequency-hopping spread spectrum, FHSS) 방식`으로 알려져 있다.

이를 통해 ISM 대역을 사용하는 다른 장치나 가전과의 간섭 현상이 일부 시간 슬롯으로 한정될 수 있다.

블루투스 네트워크는 인프라스트럭처(e.g., AP)가 없는 `애드혹 네트워크`다.

대신에 이들은 아래 그림과 같이 그들 **스스로** 최대 8개의 활성화된 노드로 구성된 피코넷을 형성해야 한다.

- 노드들 중 1개의 장치가 `중앙 집중형 제어 노드`로 지정되며, 나머지 장치들은 클라이언트가 된다.

- 피코넷 안에는 8개의 활성화된 장치 외로, 최대 255개의 `‘주차’된 장치`가 있을 수 있다.
  - 이들은 절전을 위해 수면 상태인 경우가 많다.
  - 수면 상태의 장치들은 스케줄링에 따라 `중앙 집중형 제어 노드로부터의 비컨 메시지`를 수신하기 위해 주기적으로 깨어난다.
  - 중앙 집중형 제어 노드에 의해 활성화된 장치로 변경되기 전에는 통신을 할 수 없다.


- 피코넷 내부의 다른 노드들을 제어한다.

  - 시간 슬롯의 경게를 결정하는 클록의 관리
  - 주파수 도약 순서 제공
  - 피코넷으로의 클라이언트 진입 제어
  - 클라이언트 장치의 전송 전력 제어(100 mW, 2.5 mW, 1 mW)

- 네트워크 진입이 허용된 클라이언트에게 `폴링 방식`**을 사용하여 전송 권한을 부여한다.**

블루투스 애드혹 네트워크는 AP 없이 **스스로** 네트워크를 구성해야 한다.

1. `중앙 집중형 제어 노드`가 블루투스 네트워크를 형성하려면 먼저 **영역 내에 다른 어떤 블루투스 노드가 존재하는지 결정해야 한다.**

   - 중앙 집중형 제어 노드는 `연속적인 32개의 조회 메시지`를 각기 다른 채널을 통해 브로드캐스트함으로써 이를 수행한다.
   - 클라이언트 장치는 이 조회 메시지를 수신하기 위해 주파수 중 하나를 선택해 수신을 기다린다.

2. (1) `클라이언트 장치`가 조회 메시지를 수신하면
   (2) 다른 응답 노드와의 충돌을 피하기 위해 0~0.3초 사이의 임의의 시간 동안 대기한 후
   (3) 자신의 ID를 포함하는 응답 메시지를 중앙 집중형 제어 노드에게 전송한다.

3. `블루투스 페이징(Bluetoothe paging)`
   - 중앙 집중형 제어 노드가 주변의 가능한 클라이언트 노드들을 모두 발견했다면, 그중 피코넷에 가입을 원하는 클라이언트 노드들을 초대한다.
   - 과정
     1. 중앙 집중형 제어 노드는 또다시 `32개의 동일한 페이징 초대 메시지`를 각각의 클라이언트 주소로 전송하는 것으로 페이징 단계를 시작한다.
        - 아직 클라이언트가 주파수 도약을 배우지 않았기 때문에, 메시지는 각기 다른 주파수를 통해 전송된다.
     2. 클라이언트가 초대 메시지에 대해 ACK로 응답하면 중앙 집중형 제어 노드는 아래의 정보들을 클라이언트들에게 전송한다.
        - 주파수 도약 정보
        - 클록 동기화 정보
        - 활성화된 멤버의 주소
     3. 이후 중앙 집중형 제어 노드는 각 클라이언트를 폴링하여 클라이언트가 네트워크에 연결되어 있음을 확인하고
        `주파수 도약 패턴`을 사용한 통신을 시작한다.


- `셀룰러(cellular)`라는 용어는 셀룰러 네트워크의 영역이 전파 도달 능력에 따라 **여러 개의 지리적 영역, 즉** `셀(cell)`**로 나뉜다**는 사실에서 비롯되었다.
- 각각의 셀은 셀 영역 안의 `이동 장치(mobile device)`와 신호를 주고받는 `기지국(base station)`을 갖고 있다.
- 하나의 셀이 담당하는 영역의 넓이는 여러 요소에 의해 영향을 받는다.
  - 기지국과 단말기의 송신 강도
  - 셀 내의 방해가 되는 건물
  - 기지국 안테나의 설치 높이와 종류


아래 그림은 `4G LTE(Long-Term Evolution) 네트워크` 구조의 주요 요소를 보여준다.

> 셀룰러 통신 사업자의 네트워크에 연결되는 스마트폰, 태블릿, 랩톱 또는 IoT 장치 등이며, (고정된 온도 세선 또는 감시 카메라도 포함)
> 웹 브라우저, 지도 앱, 음성 및 화상회의 앱, 모바일 결제 앱 등이 실행되는 곳이다.

- `UE(User Equipment)`
- 전체 `5계층 인터넷 프로토콜 스택`을 구현한다.
- NAT을 통해 얻을 수 있는 `IP 주소`를 갖고 있는 **네트워크의 종단점**이다.
- 전 세계적으로 고유한 `IMSI(International Mobile Subscriber Identity)`라는 64비트의 식별자가 있다.
  - 가입자가 속한 국가 및 홈 네트워크를 포함하여 전 세계의 셀룰러 사업자 시스템에서 가입지를 식별한다. (MAC 주소와 유사함)
  - 이는 `SIM(Subscriber Identity Module) 카드`에 저장된다.
    - SIM 카드는 가입자가 접속할 수 있는 서비스에 대한 정보와 해당 가입자의 키 정보를 암호화한다.


> 셀룰러 통신 사업자 네트워크의 가장자리에 위치하며, 무선 전파 자원 및 담당 영역에 속한 **이동 장치를 관리할 책임이 있다.**

- 이동 장치는 기지국과 상호작용함으로써 사업자의 네트워크에 접속된다.
- 무선 접속 네트워크에서 장치의 인증 및 자원(무선 채널)의 할당 기능을 조정한다.
- 무선 랜의 AP와는 다르게, 셀룰러 기지국에서만 수행하는 역할들은 다음과 같다.
  - AP 이동 장치에서 게이트웨이까지 장치 `고유의 IP 터널`을 생성하고, 셀 간의 장치 이동성을 처리하기 위해 상호작용한다.
  - 인접한 기지국들은 셀 사이의 간섭을 최소화하기 위해 무선 스펙트럼을 관리하기 위한 상호 조정 기능을 수행한다.

> HSS의 네트워크를 홈 네트워크로 사용하는 이동 장치에 대한 정보를 저장하는 데이터베이스

- 제어 평면의 요소
- 이동 장치의 인증을 위해 `이동성 관리 개체(MME)`와 함께 사용된다.


`S-GW`와 `PDN 게이트웨이(P-GW)`는 이동 장치와 인터넷 사이에 위치하는 2개의 라우터다.

- 이동 장치에 `NAT IP 주소`를 제공하고 `NAT 기능`을 수행한다.
- 외부 세계에서 P-GW는 다른 게이트웨이 라우터와 마찬가지로 보인다.
- 셀룰러 사업자의 LTE 네트워크 안에서의 이동 노드의 이동성은 P-GW 뒤에 있는 바깥 세상에는 감추어진다.

이러한 게이트웨이 라우터 외에도 셀룰러 사업자의 `all-IP 코어`에는 전통적인 라우터 기능을 수행하는 라우터들이 존재한다.


- 제어 평면의 요소
- HSS와 함께 네트워크에 접속하려는 장치를 **인증**하는 데 중요한 기능을 수행한다.
- 이동 장치와 PDN 인터넷 게이트웨이 간의 데이터 경로에 터널을 설정하고, 사업자의 셀룰러 네트워크 안에서 활성화된 이동 장치의 셀 위치 정보를 유지 관리한다.
  그러나 이동 장치의 데이터그램이 인터넷으로 전송되거나 들어오는 전달 경로상에 있지 않다. (아래 그림에서 확인 가능)

LTE 데이터 평면과 제어 평면의 요소

<p align="center"><img width="700" alt="LTE 데이터 평면" src="https://user-images.githubusercontent.com/86337233/216772889-58669886-55d9-429f-978b-f05a5ed5e59d.jpg">

- 네트워크와 네트워크에 부착된 이동 장치 간의 **상호** 인증
  - 네트워크는 부착된 장치가 실제로 주어진 IMSI와 연관된 장치라는 것을 알아야 한다.
  - 이동 장치는 자신이 부착하고 있는 네트워크가 또한 합법적인 셀룰러 사업자 네트워크라는 것을 알아야 한다.
- `MME`가 이동 홈 네트워크에서 이동 장치와 `홈 가입자 서버 HSS` 사이의 중재자 역할을 한다.
  1. 로컬 MME는 이동 장치로부터 접속 요청을 수신하고, 이동 장치의 홈 네트워크 HSS에 접촉한다.
  2. 이동 장치의 홈 HSS는 로컬 MME에 암호화된 정보를 충분히 반환한다.


> **이동 장치로부터 게이트웨이 라우터로의 데이터 경로**는
> 이동 장치와 기지국 사이의 무선 첫 번째 홉(first hop), 기지국과 서빙 게이트웨이(S-GW) 사이의 연결된 `IP 터널, 서빙 게이트웨이, PDN 게이트웨이`로 구성된다.

- `터널`은 MME의 제어하에 설정된다.
- **장치가 다른 기지국으로 이동했을 때에 기지국에서 종료하는 터널 종단점만 변경되며,** 다른 터널 종단점 및 터널과 관련된 서비스 품질은 변경되지 않는다.

이동 장치가 셀들 사이를 이동함에 따라, 기지국들은 이동장치의 위치에서 MME를 갱신할 것이다.

하지만 이동 장치가 수면 모드에 있지만 그럼에도 불구하고 셀 사이를 이동하는 경우, 기지국은 더 이상 해당 장치의 위치를 추적할 수 없다.

이 경우 `페이징`이라고 하는 프로세스를 통해 **깨어난 장치를 찾는 것은** `MME`**의 책임이다.**
4G LTE는 `all-IP 네트워크 구조`이다.
따라서 LTE 프로토콜 스택의 상위 계층은 IP, TCP, UDP, 그리고 다양한 애플리케이션 계층 프로토콜들로 구성된다.
아래 그림은 LTE 이동 노드, 기지국, 서빙 게이트웨이에서의 `사용자 평면 프로토콜` 스택을 보여준다.
여기서 볼 수 있듯, 사용자 평면 프로토콜 활동의 대부분은 이동 장치와 기지국 사이의 무선 링크에서 발생한다.
LTE는 이동 장치의 `링크 계층`을 3개의 부계층으로 나눈다.
- `PDCP(Packet Data Convergence Protocol)`는 무선 링크를 통해 전송되는 비트 수를 줄이기 위해 IP 헤더 압축을 수행한다.
- LTE 이동 장치가 네트워크에 처음 연결될 때
  이동 장치와 이동성 관리 개체(MME) 사이의 시그널링 메시지 교환을 통해 설정된 키를 사용한 암호화/복호화 기능을 수행한다.
- 링크 계층 프레임에 적용하기에는 너무 큰 `IP 데이터그램`의 송신 시 **단편화** 및 수신시 **재조립**을 수행한다.
- `ACK/NAK 기반 ARQ 프로토콜`의 사용을 통한 링크 계층에서의 **신뢰성 있는 데이터 전송**을 수행한다.
- **전송 스케줄링**을 수행한다. 이는 무선 전송 슬롯의 요청 및 사용 제어를 의미한다.
- MAC 부계층은 추가적인 오류 감지/정정 기능을 수행하는데, 여기에는 **중복 비트 사용을 통한 순방향 오류 정정 기능**이 포함된다.
위의 그림은 또한 사용자 데이터 경로에서 `터널`의 사용을 보여준다.
1. 터널은 **MME 제어하에** 이동 장치가 처음으로 네트워크에 연결될 때 설정된다.
2. 두 종단점 사이의 각 터널에는 고유한 `터널 종단점 식별자(tunnel endpoint identifier, TEID)`가 있다.
   (1) 기지국은 이동 장치에서 데이터그램을 수신하면 TEID를 포함한 `GPRS 터널링 프로토콜`을 사용하여 데이터그램을 캡슐화하고
   (2) UDP 세그먼트로 터널의 다른 쪽 끝에 있는 `서빙 게이트웨이`로 보낸다.
3. (1) 수신 측에서 `기지국`은 터널링된 UDP 데이터그램을 캡슐 해제하고
   (2) 이동 장치로 향하는 IP 데이터그램을 추출하여
   (3) 무선 홉을 통해 해당 IP 데이터그램을 이동 장치로 전달한다.
LTE는 `다운스트림 채널`에서 **주파수 분할 다중화와 시분할 다중화를 조합한 기술**을 사용하는데,
이 기술은 `직교 주파수 분할 다중화(frequency division multiplexing, OFDM)`로 알려져 있다.
LTE에서 활성화된 각 이동 장치에는 **하나 이상의 채널 주파수에서 / 하나 이상의 0.5 ms 시간 슬롯이 할당된다.**
아래 그림은 4개의 주파수에서 8개의 시간 슬롯을 할당한 것을 보여준다.
- 각 주파수마다 10 ms 프레임 안에 구조화된 20개의 0.5 ms 슬롯
- 음영 표시 : 20 개의 슬롯 중 8개 슬롯의 할당된 모습
- 동일한 주파수에 있든 다른 주파수에 있든, **점점 더 많은 시간 슬롯을 할당함으로써 이동 장치는 점점 더 높은 전송 속도를 달성할 수 있다.**
- 이동 장치 간의 슬롯 (재)할당은 밀리초마다 한 번씩 수행될 수 있다.
- 다른 변조 방식을 사용하면 전송률을 변경할 수도 있다.
`이동 장치에 대한 특정 타임 슬롯의 할당`은 LTE 표준에 의해 의무화되어 있지 않으나,
`어떤 이동 장치가 주어진 주파수에서 주어진 시간 슬롯에 전송하도록 허용될 것인지`에 대한 결정은 LTE 장비 공급자 또는 네트워크 운영자가 제공하는 스케줄링 알고리즘에 의해 결정된다.
이동 장치가 셀룰러 사업자의 네트워크의 접속하는 절차는 세 단계로 나뉜다.
2. 기본 동기화 신호가 발견되면 이동 장치는 해당 주파수를 유지하고 `보조 동기화 신호`를 찾는다.
   - 보조 동기화 신호에서 찾은 정보와 몇 가지 추가 단계를 거쳐서
     이동 장치는 채널 대역폭, 채널 구성 및 해당 기지국의 셀룰러 사업자 정보화 같은 추가 정보를 찾을 수 있다.
3. 위 과정에서 찾은 정보로 무장한 이동 장치는 연결한 `기지국`을 선택하고, 해당 기지국과의 `무선 홉`을 통해 제어 평면의 신호 연결을 설정할 수 있다.
- 기지국이 `MME(Mobility Management Entity)`에 접속하여 상호 인증을 수행한다. (이는 8.8.2절에서 자세히 살펴봄)
- 상호 인증을 통해 네트워크는 접속하려는 장치가 실제로 주어진 **IMSI와 연관된 장치**이며,
  이동 장치는 접속 시도 중인 네트워크가 **합법적인 셀룰러 사업자 네트워크**임을 알 수 있다.
- 상호 인증 단계가 완료되면 MME와 이동 장치가 서로 상호 인증되고, MME도 이동 장치가 연결된 `기지국의 ID`를 알게 된다.
- `MME`는 PDN 게이트웨이(이동 장치에 대한 NAT 주소도 제공함), 서빙 게이트웨이, 기지국에 연결하여 아래 그림에 포시된 *2개의 터널*을 설정한다.
- 이 단계가 완료되면 이동 장치는 기지국과 연결된 이 터널을 통해 인터넷과 IP 데이터그램을 송수신할 수 있다.
무선 장치는 전력 소모를 최소화하기 위해 (= 데이터 송수신 및 채널 감지를 위해 이동 장치의 회로가 켜져 있어야 하는 시간을 최소화하고자)
송수신하지 않을 때는 `수면 상태`로 들어갈 수 있다.
4G LTE에서 잠자고 있는 이동 장치는 두 가지 수면 상태 중 하나에 있을 수 있다.
- `불연속 수신 상태(discontinuous reception state)`
- `유휴 상태(idle state)`
- ‘약한 수면’
- 일반적으로 수백 밀리초의 비활성 기간 이후에 시작되는 단계이다.
- 이동 장치와 기지국은 이동 장치가 깨어나기 위한 주기적인 시간을 미리 예약한 후,
  주기적으로 기지국에서 이동 장치로의 다운스트림 전송을 위해 **채널을 능동적으로 모니터링한다.**
  - 그러나 이 예정된 스케줄링 시간과는 별개로 이동 장치의 무선 부분은 수면 상태일 수 있다.
- ‘깊은 수면’
- 이 상태의 잠은 너무 깊어, 이동 장치가 수면 상태인 동안 통신 사업자 네트워크의 새로운 셀로 이동하는 경우 **이전에 결합되었던 기지국에 알릴 필요가 없다.**
- 따라서 이 깊은 잠에서 깨어날 때 이동 장치는
  MME가 이동 장치가 과거에 마지막으로 결합했던 기지국 근처의 다른 기지국들로 브로드캐스트하는 `페이징 메시지`를 확인하기 위해 (잠재적으로 새로운) 기지국과의 결합을 재설정해야 한다.
  - 이러한 `제어 평면 페이징 메시지`는 기지국에 의해 해당 셀 내의 모든 이동 장치로 브로드캐스트된다.
  - 이는 **어떤 이동 장치가** 패킷을 수신하기 위해 완전히 깨어나야 하고 기지국에 대한 새로운 데이터 평면 연결을 재성정해야 하는지를 나타낸다.
‘네트워크들의 네트워크’인 `글로벌 셀룰러 네트워크`는 어떻게 구성될까?
아래 그림은 사용자의 스마트폰이 **4G 기지국**을 통해 `홈 네트워크(home network)`에 연결되는 모습을 보여준다.
- 사용자 홈 네트워크는 홈 네트워크에 있는 하나 이상의 `게이트웨이 라우터`를 통해 다른 셀룰러 통신 사업자들의 네트워크와 글로벌 인터넷으로 연결된다.
- 모바일 네트워크 자체는 공용 인터넷 또는 `IPX(Internet Protocol Packet eXchange) 네트워크`를 통해 상호연결된다.
  - `IPX`는 특히 ISP 간 네트워크를 연결하고 데이터를 교환하는 피어링을 위한 인터넷 교환 지점과 유사하게
    셀룰러 통신 사업자를 상호연결하기 위한 관리 네트워크다.
- 사용 주파수
  - FR1(450 MHz~6 GHz)
  - FR2(24 GHz~52 GHz) : `밀리미터파 주파수(millimeter wave frequency)`
    - 장점 : 훨씬 빠른 데이터 속도를 허용한다.
    - 단점
      - 기지국에서 수진기까지의 도달 범위가 훨씬 짧기에 농촌 지역에 부적합하며, 도시 지역에는 더 밀집된 기지국 배치를 필요로 한다.
      - 대기 간섭에 매우 취약하다.
- 5G의 `물리 계층(즉, 무선)` 측면은 LTE와 같은 **4G 이동 통신 시스템과 역방향 호환이 되지 않는다.**
  - 기지국 업그레이드나 소프트웨어 업그레이드를 통해 기존 스마트폰을 지원할 수가 없어,
    5G로의 전환을 위해 이동 통신 사업자는 물리적 인프라에 상당한 투자를 해야 한다.
- 증가된 대역폭과 적당한 지연 시간 감소를 제공한다. (4G LTE와 비교할 때 더 높은 다운로드 및 업로드 속도를 위함)
- 지연 시간에 매우 민감한 애플리케이션을 대상으로 한다. (e.g., 공장 자동화 및 자율 주행)
- 1 ms의 지연 시간을 목표로 한다.
- 감지, 측정 및 모니터링 애플리케이션을 위한 협대역 접속 유형이다.
- IoT 장치의 네트워크 연결 장벽을 낮추기 위해 전력 요구사항을 줄이는 데 중점을 두고 있다.
`24 GHz~52 GHz 대역의 밀리미터파 주파수`는 4G에 비해 데이터 용량이 100배 증가할 수 있는 잠재력을 제공한다.
 `데이터 용량(capacity)`
 = `셀 밀도`(cell density, 셀/km^2 단위)
 × `가용 스펙트럼`(available spectrum, Hz 단위)
 × `스펙트럼 효율`(spectral efficiency, 각 기지국이 사용자와 얼마나 효율적으로 통신할 수 있는지, bps/Hz/셀 단위)
- 밀리미터 주파수는 4G LTE 주파수보다 범위가 훨씬 짧기에 더 많은 기지국이 필요하다. → **셀 밀도 증가**
- 5G FR2는 4G LTE(최대 약 2 GHz)보다 훨씬 더 큰 주파수 대역(52 - 24 = 24 GHz)에서 작동하기 때문에 **사용 가능한 스펙트럼이 더 많다.**
- 스펙트럼 효율성을 두 배 늘리기 위해 17배의 전력 증가가 필요하지만, 5G는 그 대신 각 기지국에서 다중 안테나를 사용하는 `MIMO 기술`을 사용한다.
  - 신호를 모든 방향으로 브로드캐스트하는 대신, 각 MIMO 안테나는 빔 형성을 통해 사용자에게 신호를 직접 전송한다.
  - 이를 통해 동일한 주파수 대역에서 동시에 10~20명의 사용자에게 전송할 수 있다.
그러나 밀리미터파 신호는 건물과 나무에 의해 쉽게 차단되기 때문에
기지국과 사용자 간의 범위 간격을 메우기 위해서 `스몰 셀 스테이션(small cell station)`이 필요하다.
> 5G 모바일 음성, 데이터 및 인터넷 연결을 모두 관리하는 데이터 네트워크
- 인터넷 및 클라우드 기반 서비스와 더 잘 통합되도록 재설계되었다.
- 네트워크 전체에 분산 서버와 캐시를 포함하여 지연 시간을 줄였다.
- 새로운 5G 코어 사양은 **모바일 네트워크가 다양한 성능으로 다양한 서비스를 지원하는 방식**에 주요한 변화를 도입했다.
  - 종단점 장비로부터의 데이터 트래픽을 중계
  - 장치를 인증
  - 장치의 이동성을 관리
- 모든 네트워크 요소(이동 장치, 셀, 기지국, MME, HSS, 서빙 게이트웨이, PDN 게이트웨이)를 포함한다.
5G 코어는 **제어 평면과 사용자 평면의 완전한 분리**를 위해 설계되었고, 이는 순전히 가상화된 소프트웨어 기반 네트워크 기능으로 구성된다.
따라서 사업자가 다양한 5G 애플리케이션의 다양한 요구사항을 충족할 수 있는 유연성을 제공한다.
제어와 사용자 평면 분리를 통해 패킷 처리를 네트워크 가장자리로 보내 분산시킬 수 있다.
5G 코어는 기본적으로 4G MME를 AMF와 SMF의 두 가지 기능 요소로 분리한다.

AMF는 최종 사용자 장치로부터 모든 연결 및 세션 정보를 수신하지만, 연결 및 이동성 관리 작업만 처리한다.


세션 관리는 SMF에 의해 처리된다.

제어와 분리된 데이터 평면과의 상호작용을 담당하며, IP 주소 관리를 담당하고 `DHCP 역할`을 수행한다.

---

2020년을 기준으로, 5G는 적용 초기 단계이며 많은 5G 표준들이 아직 확정되지 않았다.

5G가 궁극의 광역 무선 서비스를 향한 커다란 발걸음이 될지는 시간이 지나야 알 수 있을 것이다.

> 💡 이동 장치 = 시간에 따라 네트워크로의 접속점을 변경하는 노드


물리적인 이동 장치가 네트워크 접속점을 이동할 때 **그 장치가 얼마나 활성화된 상태인가에 따라** 다양한 문제들을 네트워크 계층에 제기한다.


이곳에는 네트워크 사이를 물리적으로 이동하지만 이때 이동 장치의 전원을 끄고 움직이는 이동 사용자가 위치한다.

전원이 켜져 있는 동안 하나의 네트워크에만 접속하며 이동하지 않고 머물기 때문에, 네트워킹 관점에서 이 장치는 이동 중인 것, 즉 `모바일`이 아니다.

이동 장치는 물리적으로 이동 가능하지만 동일한 접속 네트워크에 연결된 상태를 유지한다.

이러한 장치도 네트워크 계층 관점에서는 모바일이 아니다.

또한 장치가 동일한 802.11 AP 또는 LTE 기지국과 연결된 상태로 유지되는 경우, 해당 장치는 링크 계층 관점에서도 모바일이 아니다.

_네트워크 관점에서 장치 이동성에 대한 관심은 여기서부터 시작한다._


1. 이동 장치는 TCP와 같은 상위 레벨 연결을 유지하고, IP 데이터그램을 계속 보내고 받는 상태에서
2. 접속 네트워크(802.11 WLAN 또는 LTE 셀)를 변경한다.

여기서 네트워크는 장치가 WLAN 또는 LTE 셀 간에 이동할 때 `핸드오버(handover)`를 제공해야 한다.
(하나의 AP/기지국에서 다른 AP/기지국으로 데이터그램을 책임지고 전달하는 것)

이동 장치가 여러 사업자 네트워크들 사이를 로밍하는 경우이다.

이때 사업자들은 핸드오버를 함께 협력해서 처리해야 하므로 핸드오버 절차가 상당히 복잡해진다.


모든 셀룰러 사용자는 자신이 가입한 통신 사업자라는 '집'이 있으며,
`HSS(Home Subscriber Service)`가 아래와 같은 가입자들에 대한 다양한 정보들을 저장하고 있음을 앞서 배웠다.

- 가입자가 접속할 수 있는 서비스에 대한 정보
- 통신에 사용되는 암호화 키
- 요금 청구 및 과금 정보

> 이동 장치가 홈 네트워크(home network)가 아닌 다른 셀룰러 네트워크와 연결되면,
> 그 장치는 `방문 네트워크(visited network)`에서 `로밍(roaming)` 중이라고 한다.

이때 홈 네트워크와 방문 네트워크 간의 조정 작업이 필요하다.

`이동 장치가 홈 네트워크를 갖는다`는 개념은 중요한 장점 두 가지를 제공한다.

1. 홈 네트워크는 해당 장치에 대한 정보를 제공할 수 있는 단일한 위치를 제공한다.
2. 로밍 중인 이동 장치와의 통신을 위한 **조정 지점**의 역할을 수행할 수 있다.

이동 네트워크 구조의 요소는 다음과 같다.

이를 통해 인터넷에 연결된 한 호스트가 직면한 난제를 살펴보자.
(장치 이동성을 지원하기 위한 근본적인 문제와 기본적인 해결방안들은 셀룰러 네트워크와 인터넷 모두에 동일하게 적용할 수 있음)

호스트는 `통신자(correspondent)`라고 불리며,
홈 네트워크에 있거나 방문 네트워크에 로밍 중인 어떤 이동 장치와 통신하기를 원한다.

모든 이동 장치에는 고유한 식별자가 있다고 가정한다.

- 4G LTE 셀룰러 네트워크에서 이 식별자는 `IMSI(International Mobile Subscriber Identity)`와 관련 전화번호가 될 것이고,
  이 정보는 SIM 카드에 저장된다.
- 인터넷 사용자의 경우 이 식별자는 이동 IP 구조와 마찬가지로 홈 네트워크의 주소 범위에 있는 영구적인 IP 주소가 될 것이다.

통신자가 보낸 데이터그램이 해당 이동 장치에 도달할 수 있도록 하기 위해서 네트워크 구조에서는 세 가지의 기본적인 접근 방법이 있다.

이 중 후자의 두 가지 방법은 실제로 채택되어 사용되고 있다.

- 기존 IP 주소 인프라 활용
- 이동 장치로의 간접 라우팅
- 이동 장치로의 직접 라우팅


방문 네트워크에 있는 이동 장치로 라우팅하는 가장 간단한 방법은 `기존의 IP 주소체계`를 사용하는 것이다.

1. `방문 네트워크`는 이동 장치의 영구적인 32비트 IP 주소를 광고하여
   데이터그램을 해당 이동 장치로 전달하는 데 사용할 경로가 있음을 다른 네트워크들에게 알린다.

   - `ISP`는 `BGP`를 통해 도달 가능한 네트워크의 CIDR화된 주소 범위를 열거하여 목적지 네트워크에 대한 경로를 광고한다.
   - 이때 방문 네트워크는 매우 구체적인 주소를 광고함으로써 **특정 이동 장치가 자신의 네트워크에 존재한다는 사실을 다른 모든 네트워크에게 알릴 수 있다.**

2. 인접 네트워크들은 라우팅 정보 및 포워딩 테이블을 갱신하는 일반적인 BGP 절차를 사용해 **네트워크 전체에 이 정보를 전파한다.**


네트워크 계층 인프라를 전혀 변경할 필요가 없다.

다른 네트워크들은 이동 장치의 위치를 알고 있으며,
포워딩 테이블들이 데이터그램을 방문 네트워크로 안내하기 때문에 데이터그램을 그 이동 장치로 쉽게 라우팅할 수 있다.

확장성

네트워크 라우터는 잠재적으로 수십억 개의 이동 장치에 대한 포워딩 테이블 항목을 유지 관리해야 하고,
다른 네트워크로 로밍할 때마다 장치 관련 항목을 갱신해야 한다.


좀 더 실용적이며 실제로 채택되고 있는 접근 방법은
이동 장치의 홈 네트워크를 통하여 `이동성 관리 기능`을 네트워크 코어에서 **네트워크 가장자리**로 밀어내어 옮기는 것이다.

이동 장치의 홈 네트워크에 있는 이동성 관리 개체인 `MME`는 이동 장치가 위치한 방문 네트워크를 추적할 수 있다.
(이 정보는 `HSS`의 데이터베이스에 있을 수 있음)

이동 장치가 위치한 네트워크를 갱신하기 위해서는 방문 네트워크와 홈 네트워크 사이에서 동작하는 프로토콜이 필요하다.

이동 장치는 `방문 네트워크의 IP 주소`가 필요하다.

여기에는
(1) 이동 장치의 홈 네트워크와 연결된 영구적인 IP 주소,
(2) 방문 네트워크의 주소 범위에서 새로운 주소의 할당
(3) NAT를 통한 IP 주소의 제공 등이 포함된다.

- (2), (3)의 경우, 이동 장치는 홈 네트워크의 HSS에 저장된 영구적인 식별자 외에 임시 식별자(새로 할당된 IP 주소)를 갖게 된다.
- NAT 주소를 사용하는 경우,
  이동 장치로 향하는 데이터그램은 방문 네트워크의 NAT 게이트웨이 라우터에 도달하게 되면 NAT 주소 변환을 거쳐 해당 이동 장치로 전달된다.

_그렇다면 `데이터그램`은 어떻게 주소를 찾아서 이동 장치로 전달될 수 있을까?_

네트워크의 모든 라우터가 아닌 **홈 네트워크의 HSS만이 이동 장치의 위치를 알고 있기 때문에,**
단순히 목적지 이동 장치의 영구 주소를 데이터그램의 목적지로 지정하는 것은 안 된다.

이것에 대한 해결책으로는 `직접 라우팅`과 `간접 라우팅`이 있다.

`간접 라우팅(indirect routing)` 방식에서 통신자는 이동 노드가 홈 네트워크에 있는지 또는 방문 네트워크에 있는지 모르는 상태로
**데이터그램의 목적지 주소를 단순히 이동 노드의 영구적인 주소로 설정한 후 네트워크로 전송한다.**

즉, 송신하는 통신자는 이동 장치의 현재 이동 상태를 몰라도 되며, 이는 통신자에게 이동성에 대한 완전한 투명성을 제공한다.


1. `데이터그램`은 **이동 장치의 홈 네트워크**로 전달된다.

2. (1) `홈 네트워크 게이트웨이`는 데이터그램을 가로채서 `HSS`와 상의하여 이동 장치가 있는 방문 네트워크를 결정한 후
   (2) 해당 데이터그램을 방문 네트워크의 `게이트웨이 라우터`로 전달한다.

   - `HSS` : 방문 네트워크와 상호작용하여 이동 장치의 위치를 추적하고 홈 네트워크의 게이트웨이 라우터를 관리한다.
   - `게이트웨이 라우터` : 해당 네트워크에 집이 있지만 현재 방문 네트워크에 위치해있는 장치를 목적지 주소로 하는 데이터그램이 도착하는지 확인한다.

3. 방문 네트워크의 `게이트웨이 라우터`는 데이터그램을 이동 장치로 전달한다.
   - NAT 변환이 사용된다면 방문 네트워크 게이트웨이 라우터가 NAT 변환을 수행한다.

아래의 두 가지 목표는 **홈 네트워크 게이트웨이가 통신자의 원래 데이터그램을 캡슐화하여** 더 큰 데이터그램에 넣게 함으로써 충족될 수 있다.

- `홈 네트워크 게이트웨이`는 도착한 데이터그램을 `방문 네트워크 게이트웨이 라우터`에게 전달해야 한다.
- 데이터그램을 수신하는 애플리케이션 입장에서는 데이터그램이 홈 네트워크를 통해 전달되었다는 사실을 인식하지 않는 것이 좋기에
  **통신자의 데이터그램을 원래 그대로 두는 것이 바람직하다.**

더 큰 데이터그램은 주소가 지정된 방문 네트워크의 게이트웨이 라우터에 전달되고,
이후 캡슐화를 해제하여 더 큰 데이터그램 내에서 **원래의 데이터그램을 복원하여 이동 장치로 전달된다.** (이는 위 3단계에서 진행됨)

---

> 이동 장치가 통신자에게 데이터그램을 보내는 것을 고려해보자.

그림의 맥락에서 이동 장치는 NAT 변환을 수행하기 위해 방문 게이트웨이 라우터를 통해 데이터그램을 전달해야 하는데,
방문 게이트웨이 라우터는 어떻게 데이터그램을 통신자에게 전달할까?

여기에는 아래처럼 두 가지 옵션(4a, 4b)가 있다.

- 4a : 데이터그램을 홈 게이트웨이 라우터로 다시 터널링하여 거기에서 다시 통신자에게 전달할 수 있다.
- 4b : 데이터그램은 방문 네트워크에서 통신자로 직접 전달될 수 있다. (`로컬 브레이크 아웃(local breakout)`)

> ✅ 이동 장치에서 방문 네트워크로의 프로토콜

`이동 장치`는 `방문 네트워크`와 **결합**해야 하며, 마찬가지로 방문 네트워크를 떠날 때 결합을 해제해야 한다.

> ✅ 방문 네트워크에서 홈 네트워크로의 HSS 등록 프로토콜

`방문 네트워크`는 `홈 네트워크의 HSS`에 이동 장치의 위치를 등록해야 하며,
HSS에서 얻은 정보를 **장치 인증**을 수행하는 데 사용해야 한다.

> ✅ 홈 네트워크 게이트웨이와 방문 네트워크 게이트웨이 라우터 사이의 데이터그램 터널링 프로토콜

송신 측은 통신자의 원래 데이터그램을 새로운 데이터그램 내에 **캡슐화**한 후 목적지로 전달한다.

수신 측에서는 게이트웨이 라우터에서 **캡슐화 해제 및 NAT 변환**을 거쳐 원래 데이터그램을 이동 장치로 전달하는 작업을 수행한다.


간접 라우팅 방식은
이동 장치를 목적지로 하는 데이터그램은 통신자와 로밍 중인 이동 장치 사이에 훨씬 더 효율적인 경로가 있는 경우에도
**일단 먼저 홈 네트워크로 전달된 다음 방문 네트워크로 전달되어야 하기 때문에** 비효율성을 가지고 있다.

`직접 라우팅(direct routing)` 방식은 간접 라우팅 방식의 삼각 라우팅 문제를 해결할 수 있으나, 추가적인 복잡도가 발생한다.

- 1, 2단계 : 통신자는 먼저 이동 장치가 위치해 있는 방문 네트워크를 발견한다.

  - 이는 `이동 장치의 홈 네트워크 HSS`에 질의함으로써 수행되고,
    이동 장치의 방문 네트워크가 HSS에 등록되어 있는 것으로 가정한다.

- 3단계 : 통신자는 데이터그램을 이동 장치의 방문 네트워크로 **직접** 터널링해서 전달한다.


1. 통신자가 HSS에게 이동 장치의 방문 네트워크를 질의하기 위해서(1, 2단계), `이동 사용자 위치 파악 프로토콜`이 필요하다.

2. 이동 장치가 이동할 때마다 통신자를 미리 갱신해주려면 추가적인 프로토콜 매커니즘이 필요하다.

   > 이동 장치가 한 방문 네트워크에서 다른 방문 네트워크로 이동하면
   > 통신자는 데이터그램을 새로운 방문 네트워크로 전달해야 한다는 것을 어떻게 알 수 있을까?

   - `간접 라우팅`에서는 홈 네트워크 HSS를 갱신하고, 터널의 종단점을 새로운 방문 네트워크의 게이트웨이 라우터로 변경함으로써 문제를 쉽게 해결한다.
   - `직접 라우팅`에서 통신자는 세션이 시작될 때 HSS에게 단 한 차례만 문의하며 이후에 변화된 정보를 알기 어렵기에 문제의 해결이 쉽지 않다.


> 오늘날의 4G/5G 네트워크에서의 이동성을 지원하기 위해 어떤 요소들이 어떻게 상호 협력하면서 동작하는지 알아보자.

차량에 탑승한 이동 사용자가 스마트폰으로 4G/5G 방문 네트워크에 접속하여 원격 서버로부터 HD 비디오 스트리밍을 시작한 후,
**하나의 4G/5G 기지국 셀 영역으로부터 다른 셀 영역으로 이동**하는 시나리오를 생각해보자.

<p align="center"><img width="600" alt="이동성 시나리오" src="https://user-images.githubusercontent.com/86337233/216887701-4c7e6f31-d870-4879-8be4-9bb5396a54e3.jpg">

1. 이동 장치와 기지국 결합

   - 이동 장치는 방문 네트워크의 기지국과 결합한다.

2. 이동 장치에 대한 네트워크 요소의 제어 평면 구성

   - 방문 네트워크 및 홈 네트워크는 이동 장치가 방문 네트워크에 존재함을 나타내는 제어 평면 상태를 설정한다.

3. 이동 장치에 대한 포워딩 터널의 데이터 평면 구성

   - 방문 네트워크와 홈 네트워크는 홈 네트워크의 PDN 게이트웨이를 통한 간접 라우팅을 사용하여,
     이동 장치와 스트리밍 서버가 IP 데이터그램을 송수신할 수 있는 터널을 설정한다.

4. 한 기지국에서 다른 기지국으로의 이동 장치 핸드오버
   - 이동 장치는 한 기지국에서 다른 기지국으로 핸드오버를 통한 방문 네트워크 결합 지점을 변경한다.

1. 이동 장치는 점차 이러한 기지국에 대한 더 많은 정보를 획득한다.

   - 이동 장치는 해당 지역의 기지국에서 전송되는 기본 신호에 대해 모든 주파수 영역에서 수신한다.

2. 이동 장치는 궁극적으로 **결합**할 기지국을 선택하고, 해당 기지국과 제어 신호 채널을 초기 설정한다.
   - 결합의 일부로서 이동장치는 홈 네트워크 및 다른 가입자 정보, IMSI(고유 식별자)를 기지국에 제공한다.


이동 장치와 기지국 간 신호 채널이 설정되면 기지국은 방문 네트워크의 `MME`와 접촉할 수 있다.

MME는 이동 노드를 대신하여 상태를 설정하기 위해 홈 네트워크 및 방문 네트워크 모두에서 여러 가지 4G/5G 요소들을 참고하고 구성한다.

- MME는 IMSI 및 이동 장치에서 제공한 다른 정보를 사용하여 해당 가입자에 대한 인증, 암호화, 가용한 네트워크 서비스 정보를 검색한다.
  - 해당 정보는 MME의 로컬 캐시에 있거나, 이동 장치가 최근에 접속한 다른 MME에서 검색되거나, 이동 장치의 홈 네트워크에 있는 HSS에서 검색될 수 있다.
- MME는 이동 장치가 현재 방문 네트워크에 존재함을 홈 네트워크에 있는 `HSS`에 알리고, HSS는 데이터베이스를 갱신한다.
- 기지국과 이동 장치는 둘 사이에 설정될 데이터 평면 채널에 대한 매개변수를 선택한다. (제어 평면 시그널링 채널이 이미 작동 중임)

MME는 아래 그림과 같은 `이동 장치에 대한 데이터 평면`을 구성한다.

<p align="center"><img width="600" alt="터널링" src="https://user-images.githubusercontent.com/86337233/216887710-4548ee72-10d6-45bd-8f32-2d6f666a7339.jpg">

2개의 터널

1. 기지국과 방문 네트워크의 서빙 게이트웨이 사이
2. 해당 서빙 게이트웨이와 **이동 장치의 홈 네트워크**에 있는 PDN 게이트웨이 라우터 사이

→ 4G LTE는 이런 형태의 대칭 간접 라우터를 구현한다.

이동 장치에서 들어오고 나가는 모든 트래픽은 장치의 홈 네트워크를 통해 `터널링`된다.

4G/5G 터널은 `GPRS 터널링 프로토콜(GPRS Tunneling Protocol, GTP)`를 사용한다.

GTP 헤더의 `TEID(Tunnel Endpoint ID)`는 데이터그램이 속한 터널을 나타내므로, 터널 종단점 간에 GTP에 의해 여러 개의 흐름이 다중화 및 역다중화될 수 있다.


`핸드오버(handover)`는 이동 장치가 한 기지국에서 다른 기지국으로 **결합을 변경할 때** 발생한다.

- 이동 장치가 송수신하는 데이터그램은 초기에(핸드오버 전에) 연결된 현 기지국(**출발지** 기지국)을 통해 이동장치로 전달된다.
- 핸드오버 이후에는 또 다른 기지국(**목적지** 기지국)을 통해 이동 장치로 라우팅된다.

기지국 간의 핸드오버는 이동 장치가 새로운 기지국과 송수신하게 될 뿐만 아니라
기지국 축면에서 서빙 게이트웨이-기지국 간 터널의 변경을 초래한다.

이동 장치는 주기적으로 `현재 기지국의 비컨 신호`와 `들을 수 있는 주변 기지국의 신호 특성`을 측정한다.

측정 결과는 이동 장치의 현 기지국(출발지 기지국)에 초당 한 번 또는 두 번 보고되는데,
**측정 결과와 주변 셀의 이동 통신 부하 및 기타 요인에 기초하여 현재 기지국은 핸드오버를 시작하도록 요구할 수 있다.**

아래 그림은 이동 장치의 출발지 기지국에서 목적지 기지국으로의 핸드오버 절차를 나타낸다.

<p align="center"><img width="600" alt="핸드오버" src="https://user-images.githubusercontent.com/86337233/216887712-02ebc640-42fc-4dfa-98ab-172886039029.jpg">

1. 현 기지국(출발지 기지국)은 목적지 기지국을 선택하고, 목적지 기지국으로 `핸드오버 요청 메시지`를 보낸다.

2. (1) 목적지 기지국은 해당 이동 장치와 그 서비스 품질 요구사항을 지원하기 위한 충분한 자원이 있는지 확인한다.

   (2) 존재한다면 해당 이동 장치를 위한 무선 접속 네트워크의 채널 자원(e.g., 시간 슬롯) 및 기타 자원을 미리 할당한다.

   (3) 목적지 기지국은 출발 기지국에게 `핸드오버 요청 승인 메시지`로 응답하는데, 여기에는 이동 장치가 새로운 기지국과 결합하는 데 필요한 모든 정보가 포함되어 있다.

3. 출발지 기지국은 핸드오버 요청 승인 메시지를 수신하고, `목적지 기지국의 ID 및 채널 접속 정보`를 이동 장치에게 알려준다.

   - 이 시점에서 이동 장치는 새로운 목적지 기지국과 데이터그램을 송수신하기 시작할 수 있다. (즉, 이동 장치의 입장에서는 핸드오버가 완료된 것)
   - 네트워크 입장에서는 해야 할 일이 좀 더 남아 있다.

4. (1) 출발지 기지국은 데이터그램을 이동 장치로 전송하는 것을 중지하고, 대신 수신한 터널링된 데이터그램을 목적지 기지국으로 전달한다.

   (2) 목적지 기지국은 이들 데이터그램을 나중에 이동 장치로 전달한다.

5. (1) 목적지 기지국은 MME에게 자신이 이동 장치를 서비스하는 새로운 기지국이 될 것임을 알린다.

   (2) MME는 다시 서빙 게이트웨이와 목적지 기지국에 차례로 신호를 보내
   이전 기지국(출발지 기지국)이 아닌 새로운 기지국(목적지 기지국)에서 종료하도록 서빙 게이트웨이-기지국 터널 종단점을 재설정한다.

6. 목적지 기지국은 터널이 재구성되었음을 이전 기지국(출발지 기지국)으로 다시 확인해주어,
   이전 기지국이 해당 이동 장치와 관련된 자원을 해제할 수 있게 한다.

7. 이 시점에서 목적지 기지국도 이동 장치에 데이터그램 전달을 시작할 수 있다.
   (핸드오버 기간에 출발지 기지국에서 목적지 기지국으로 전달된 데이터그램을 포함함)

   또한 이동 장치로부터 외부로 나가는 데이터그램을 수신하여 이를 터널을 통해 서빙 게이트웨이로 보낼 수 있다.

오늘날의 4G LTE 네트워크의 로밍 구성은 미래의 5G 네트워크에서도 사용될 전망이지만,
5G 네트워크는 훨씬 더 작은 셀 크기로 조밀해질 것이다.

따라서 많은 실시간 5G 애플리케이션에서 **작은 핸드오버 시간**이 매우 중요해질 것이다.

셀룰러 네트워크 제어 평면을 `SDN 프레임워크`(5장)로 변경한다면 고용량, 저지연의 5G 네트워크 제어 평면을 구현할 수 있을 것으로 믿어진다.

오늘날의 인터넷에는 4G/5G 셀룰러 네트워크에서 접했던 것 같은 **‘이동 중인’ 사용자를 위한** 서비스 유형을 제공하는 널리 사용되는 인프라는 없다.

그러나 `이동 IP 구조 및 프로토콜`은 20년 이상 인터넷 RFC로서 표준화되어 왔으며, 새롭고 더 안전하며 일반화된 이동성 지원에 대한 연구가 계속되고 있다.


> ✅ 에이전트 발견

이동 IP는 `외부 에이전트`가 네트워크에 결합하려는 이동 장치에게 이동성 지원 서비스를 광고하는 데 사용하는 프로토콜을 정의한다.

이러한 서비스에는 이동 장치가 외부 네트워크에서 사용하기 위한 `COA(care-of-address)` 제공,
이동 장치의 홈 네트워크에 있는 홈 에이전트에 이동 장치 등록, 이동 장치로의 데이터그램 송수신 등과 기타 서비스가 포함된다.

> ✅ 홈 에이전트와의 등록

이동 IP는 이동 장치의 홈 에이전트에 COA를 등록 및 취소하기 위해 이동 장치 및 외부 에이전트에서 사용하는 프로토콜을 정의한다.

> ✅ 데이터그램의 간접 라우팅

이동 IP는 데이터그램이 홈 에이전트에 의해 이동 장치로 전달되는 방식을 정의한다.

여기에는 데이터그램을 전달하고 오류를 처리하기 위한 규칙과 여러 형태의 터널링이 포함된다.


이 장에서는 `링크 계층(페이딩이나 다중 경로, 숨은 터미널 등과 같은 무선 채널의 특성)`과
`네트워크 계층(네트워크 접속점이 동적으로 바뀌는 이동 사용자의 존재)`에서 무선 네트워크와 유선 네트워크 간에 상당한 차이가 있음을 알았다.

그렇다면 `트랜스포트 계층`과 `애플리케이션 계층`에도 차이가 있을까?

어떤 면에서는 무선 링크가 존재하는 네트워크에서 TCP와 UDP가 사용될 수 있다는 생각이 맞을 수도 있다.

그러나 특히 `TCP 트랜스포트 프로토콜`은 유선 네트워크와 무선 네트워크에서 전혀 다른 성능을 보이는 경우가 많으며, 성능 면에서 그 차이가 뚜렷하다.

TCP는 송신자와 수신자 간의 경로에서 손실되거나 오류가 생긴 세그먼트를 `재전송`한다.

이동 사용자의 경우 아래의 상황 때문에 손실을 겪을 수 있다.

- 네트워크 혼잡 (라우터의 버퍼 오버플로)
- 핸드오프 (이동 노드의 새 네트워크 접속점으로 세그먼트를 재라우팅해주기 위한 지연 때문)

어떤 경우든지 간에 TCP의 수신자에서 송신자로 전송되는 ACK는 세그먼트가 성공적으로 수신되었는지 여부만을 알리며,
세그먼트가 손실된 경우에는 그것이 어떤 이유 때문인지 송신자는 알지 못한다.

어떤 이유든 송신자는 해당 세그먼트를 재전송한다.

TCP의 `혼잡 제어 메커니즘`도 이유와는 관계없이, 무조건 **혼잡 윈도를 감소**시키는 것으로 반응한다.

하지만 무선 네트워크에서는 비트 오류가 훨씬 많이 발생하는데,
**비트 오류나 핸드오프로 인해 손실이 생겼을 경우 TCP 송신자는 혼잡 윈도를 감소(즉, 송신율 감소)시킬 필요가 없다.**

실제로는 패킷이 혼잡을 겪지 않고 종단 간의 경로를 따라 여유 있는 라우터 버퍼를 이용해 제대로 전달되고 있을 수도 있다.

따라서 1990년대 초중반에 연구자들은 무선 링크의 높은 비트 오류율과 핸드오프로 인해
무선 환경에서는 **혼잡 제어와 관련된 TCP의 무조건적인 반응**이 문제가 될 수 있음을 알게되었다.

이 문제를 해결하기 위해 다음 세 가지 접근 방법을 사용할 수 있다.

> ✅ 지역 복구(local recovery)

비트 오류가 발생했을 때 **오류 발생 지점(e.g., 무선 링크)에서 복구**해주는 것이다.

이런 방법으로는 802.11 ARQ 프로토콜 또는 ARQ와 FEC를 모두 사용하는 방법이 있다.

하지만 이 방식에서 TCP 송신자는 세그먼트가 무선 링크를 거쳐서 전달되고 있음을 전혀 알지 못한다는 문제점이 있다.

> ✅ TCP 송신자의 무선 링크 인지

지역 복구에서의 문제점을 해결하기 위한 한 가지 대안으로서 **TCP 송신자와 수신자가 무선 링크를 인지하게 해서**
유선 네트워크에서의 혼잡으로 인한 손실과 무선 링크에서의 오류나 핸드오프로 인한 손실을 구분하게 하는 방법이 있다.

즉, 유선 네트워크에서의 혼잡으로 인한 손실에 대해서만 혼잡 제어를 하는 것이다.

> ✅ 연결 분리 방법(split-connection approach)

무선 사용자의 종단 간 연결을 **2개의 트랜스포트 계층 연결**(하나는 무선 사용자와 AP 간에, 다른 하나는 AP와 목적지 종단점 간에 설정)로 분리한다.

따라서 종단 간 연결은 무선 부분과 유선 부분으로 분리된다.

무선 구간의 트랜스포트 프로토콜은 표준 TCP 연결 또는 UDP 위에서 동작하도록 고안된 복구용 프로토콜일 수 있다.

이 방법은 셀룰러 네트워크에서 널리 사용되고 있고, 이 방법을 통해 많은 성능 향상이 있었다.


무선 스펙트럼의 공유 특성으로 인해
무선 링크(특히 셀룰러 무선 링크)를 통해 동작하는 응용에게 **대역폭은 매우 부족한 자원이다.**

비록 무선 링크 환경이 애플리케이션 계층의 개발에 해결해야 할 어려운 문제를 주기는 하지만,
무선 링크가 제공하는 이동성 덕분에 다양한 종류의 위치 인식 또는 문맥 인식 애플리케이션이 가능해졌다.

또한 무선 이동 네트워크는 향후 유비쿼터스 컴퓨팅 환경 실현에서 아주 핵심적인 역할을 하게 될 것이다.


- 기밀성
  - 송신자와 지정된 수신자만이 전송되는 메시지 내용을 이해할 수 있어야 한다.
  - 도청자가 메시지를 가로챌 수도 있으므로 도청자가 해석할 수 없도록 메시지를 어떠한 방식으로 암호화해야한다.
- 메시지 무결성
  - 통신하는 내용이 전송 도중에 변경되지 않아야 한다.
- 종단점 인증
  - 통신에 참여하는 상대방이 누구인지 확인하기 위해 상대방의 신원을 확인할 수 있어야 한다.
- 운영 보안
  - 오늘날 대부분 기관들의 네트워크는 공공 인터넷에 연결되어 있다.
  - 따라서 외부로부터의 공격을 받을 수 있는 위험을 갖고 있고 대비하여 방화벽이나 보안 체계를 갖고 있어야 한다.

- 송신자와 수신자
  - 데이터 일부 혹은 전부를 암호화하여 안전한 통신을 하려고 할 것이다.
- 침입자
  - 채널상의 제어 메시지 및 데이터 메시지를 스니핑하거나 기록
  - 메시지 혹은 메시지 내용의 조작, 삽입 혹은 삭제


송신자가 보내는 원래 형태의 메시지를 **평문** 또는 **원문**이라고 한다.

송신자는 평문을 **암호화 알고리즘**을 사용해서 암호화하며, 암호화된 메시지인 암호문은 다른 침입자가 해석할 수 없다.

이 **암호화 알고리즘**은 모든이에게 알려져있고, 누구나 쉽게 사용할 수 있다.

즉, 전송한 데이터를 침입자가 복원할 수 없게 해주는 비밀 정보가 필요한데 이것이 바로 **키**이다.

1. 앨리스는 숫자나 문자의 열인 키 A를 암호화 알고리즘의 입력값으로 사용하여 암호화된 메시지 `A(m)`을 완성한다.
2. 밥은 키 B와 암호문 `A(m)`을 복호화 알고리즘에 입력값으로 넣어 `B(A(m)) = m` 의 출력을 받는다.


앨리스와 밥의 키가 동일하며 이 키는 둘만의 비밀이다.

키 중 하나는 세상 모두에게 알려져있고 다른 키는 앨리스 밥 중 한명만 알고 있다.


영어로된 원문에 대해 평문의 각 철자를 알파벳 순서로 k번째 뒤에 오는 철자로 대치한다. (철자들의 순환을 가정. z의 1번째 뒤에 오는 철자는 a다.)

여기서는 k의 값이 암호화 키가 된다.

하지만 카이사르 암호인 것을 알고 있다면 금방 암호문을 복호화할 수 있을 것이다.


카이사르 암호처럼 일정한 규칙에 따라 대치하는 대신 아무 규칙 없이 각 철자들을 고유한 대응 글자로 변환한다.

26! 정도의 문자 대응쌍이 가능하여 더 안전하다.

그러나 e나 t가 흔하게 나타나거나 3개 혹은 3개의 특정 문자가 함께 나오거나 하는 특성 탓에 암호를 해독하기 쉬워진다.

예를들어 암호문을 사용하는 사람의 이름이 평문에 들어가있다는 것을 안다면 즉시 알파벳 중 몇쌍을 확정 지을 수 있다.

**침입자가 갖고 있는 정보에 따른 시나리오**

- 암호문만을 이용한 공격
  - 평문 메시지에 대한 어떠한 정보도 없는 경우
- 알려진 평문 공격
  - 침입자가 평문과 암호문에 나올 단어(이름 등)를 미리 알고 있는 경우 해당 단어에 대한 단어 쌍을 알 수 있다.
- 선택 평문 공격
  - 침입자가 특정 평문 메시지를 선택하여 송신자에게 보내게 하고 이에 대응하는 암호문의 형태를 얻을 수 있다.

여러 개의 단일 문자 대응법을 가지고 평문 메시지에서의 위치에 따라 서로 다른 단일 문자 대응 암호법을 사용한다.

즉, 같은 문자라도 평문 메시지에서의 위치에 따라 다르게 암호화 된다.

예를 들어, 단일 문자 대응법 첫번째를 C1, 단일 문자 대응법 두번째를 C2라고 해보자.

평문의 첫번째 메시지는 C1, 두번째는 C2, 세번째는 C1 … 식으로 평문 메시지의 위치에 따라 단일 문자 대응법을 달리 한다.


현재 TLS, PGP, IPsec 등에 사용되는 암호화 기법이다.

오늘날 널리 활용되는 블록 암호화 방법에는 AES, DES, 3DES 등이 있다.

블록 암호화에서는 메시지가 k 비트의 블록 단위로 쪼개어져 암호화 된다.

k 비트의 평문은 k 비트 블록의 평문을 k비트 블록의 암호문으로 일대일 사상 시킨다.

위 표와 같이 사상한다면 `010110001111`은 `101000111001` 로 암호화 된다.

k 비트에 대해서 총 `(2^k)!` 로 사상의 수가 천문학적으로 커진다.

그러나 `k=64`라고하면 송신자와 수신자 모두 `2^64`개의 입력 테이블에 대한 테이블을 유지해야하는데 이는 실행이 거의 불가능 하고, 키가 바뀌면 큰 테이블을 재생성해야 하기 때문에 실제 사용은 불가능 하다.

대신 블록 암호화 기법은 입출력 블록의 순열 테이블을 임의로 모방 생성하는 함수를 사용한다.

위 그림은 `k=64`일 때의 예시를 나타낸다.

**시나리오**

1. 64 비트의 블록을 8 비트씩 8개의 청크로 나눈다.
2. 각 8 비트 청크는 관리 가능한 크기인 8비트 입력 블록에 대응하는 8비트 출력 블록을 가진 테이블에 의해 처리된다.
3. 각 청크는 관리 가능한 크기인 8 비트 입력 블록에 대응하는 8 비트 출력 블록을 가진 테이블에 의해 처리된다.
4. 암호화된 청크는 하나의 64 비트 블록으로 다시 합쳐진다.
   - 각각의 위치는 뒤섞여서 합쳐진다.
5. 64 비트 블록을 다시 입력부로 넣는다.
6. 이 사이클을 n번 반복한다.
   - 각 입력 비트가 대부분의 최종 출력 바트들에 영향을 미치게 하기 위해서이다.
   - 라운드를 한번만 수행하면 하나의 입력 비트는 8개의 출력 비트에만 영향을 끼친다.

이 블록 암호화 알고리즘의 키는 블록을 뒤섞는 규칙이 알려져있다면 8개의 순열 테이블이다.

네트워크 애플리케이션에서는 일반적으로 긴 메시지를 암호화할 필요가 있는데, 블록 암호화를 이용하면 미묘하지만 중요한 문제가 발생한다.

2개 이상의 평문 블록이 동일하다면 같은 암호문을 생성해내고, 공격자는 동일한 암호문으로 원문을 추측해낼 수 있는 가능성이 생긴다.

여기에 하위 프로토콜에 대한 지식까지 활용하면 전체 메시지를 복호화할 수 있다.

이를 해결하기 위해 같은 평문 블록에 대해 다른 암호문 블록이 생성될 수 있도록 임의성을 추가할 수 있다.

**시나리오**

1. 송신자는 i번째 평문 블록 m(i)를 위해 k비트 길이의 임의의 수 r(i)를 생성한다.
2. `K(r(i) xor m(i)) = c(i)` 암호문을 만든다.
   - r(i)로 인해 m(i)와 m(j)가 같아도 암호문은 달라지게 된다.
3. 수신자는 r(i)와 c(i)를 받아서 `m(i) = K(c(i)) xor r(i)` 를 수행한다.
   - 침입자는 암호화되지 않은 r(i)를 볼수는 있지만 키를 알지 못하므로 평문 m(i)를 복호화할 수 없다.

그러나 송신자는 2배의 비트를 더 보내야 하고 2배의 대역폭을 필요로 한다.

이 문제를 해결하기 위해 `암호 블록 체이닝(Cipher Block Chaining, CBC)` 기법을 사용한다.

**시나리오**

1. 메시지를 암호화하기 전에 송신자는 초기화 벡터라 불리는 임의의 k 비트열 c(0)을 생성한다.
2. 송신자는 c(0)를 수신자에게 보낸다.
3. 첫번째 블록에 대해 송신자는 `c(1)= K(m(1) xor c(0))` 을 계산한다.
4. 암호화된 c(1)을 수신자에게 보낸다.
5. 송신자는 이를 계속 `c(i)= K(m(i) xor c(i-1))` 암호문 블록을 생성하고 보낸다.
   - 수신자는 c(i-1)을 알고 있으므로 계속 복호화할 수 있다.
   - 마찬가지로 같은 평문을 가지고 있어도 다른 암호문을 갖게 된다.
   - 침입자는 암호화되지 않은 c(0)을 볼수는 있지만 키를 알지 못하므로 평문 m(i)를 복호화할 수 없다.
   - 송신자는 하나의 초기화 벡터만 더 전송하면 되므로 대역폭 증가량이 미미하다.


공개키 암호화에서는 송수신자가 각각 키를 갖는다기보다 수신자가 2개의 키를 갖는다.

하나는 세상 모두에게 알려진 **공개키**이고, 다른 하나는 수신자만 아는 **개인키**이다.

**시나리오**

1. 송신자는 수신자에게 메시지를 보내기 위해 수신자의 공개키를 확인한다.
2. 수신자의 공개키로 메세지를 암호화하고 송신한다.
3. 수신자는 자신의 개인키로 암호문을 복호화 알고리즘을 사용하여 복호화한다.

RSA는 모듈로 n 연산(나머지)을 많이 사용한다.

**모듈로 연산의 유용한 성질**

```
[(a mod n)+(b mod n)]mod n=(a+b)mod n
[(a mod n)−(b mod n)]mod n=(a−b)mod n
[(a mod n)⋅(b mod n)]mod n=(a⋅b)mod n

// 3번째 성질로부터 나오는 식
(a mod n)^d mod n = a^d mod n
```

**공개키와 개인키의 선택**

1. 2개의 큰 소수 p와 q를 선택한다.
   - 값이 클수록 RSA를 깨기가 어려워지지만 암호화 복호화를 수행하는데 시간이 더 걸린다.
2. `n = pq`, `z =(p-1)(q-1)` 식을 계산한다.
3. 1을 제외하고 z의 서로소 n보다 작은 e를 선택한다.
   - 암호화 encryption의 e를 따왔다.
4. ed-1이 z로 정확히 나누어 떨어지는 숫자 d를 찾는다.
   - 복호화 decryption의 d를 따왔다.
   - 이 말은 즉슨, ed mod z = 1이 성립하도록 d를 선택한다와 같다.
5. 공개키는 숫자쌍 (n,e) 이다. 그의 개인키는 (n,d)이다.

큰 p와 q를 고르는 방법, 지수 연산 방법, e와 d를 고르는 방법 등은 이 책의 범위에서 벗어나므로 생략한다.

**알고리즘 시나리오**

1. 암호화를 위해 공개키 (n,e)를 활용한다. 메세지에 e승을 하고 이를 n으로 나눈 나머지를 계산한 값이 암호문 c가 된다.
   - 메세지는 k 비트열로 하나의 정수와 같아서 e의 제곱을 할 수 있다.
   - `c = m^e mod n`
2. 수신된 암호 메시지 c를 복호화 하기 위해 개인키 (n,d)를 활용한다.
   - `m = c^d mod n = m^ed mod n` 을 수행하여 복호화한다.

e.g.

수신자가 `p=5` , `q=7`로 선택한다.

이때 `n = 35`, `z = 24`가 된다.

5와 z가 공통인수가 없으므로 `e = 5` 를 선택한다.

`5x29-1 (즉, ed-1)` 이 24로 나누어떨어지므로 `d= 29`를 선택한다.

이제 공개키 (35,5)와 비밀키 (35,29)가 완성되었다.

이제 평문 m을 암호화 복호화 해보자.

m은 비트열 1100으로 숫자 12에 대응된다고 가정하자.

암호화 : `m^e = 248832`, `17(c) = 248832(m^e) mod 35(n)`

복호화 : `12(m) = 4819685721067509150915091411825223071697(c^d) mod 68(n)`


RSA에 필요한 지수 연산은 시간이 많이 필요하여 실제로 종종 대칭키 암호화와 함께 사용된다.

**시나리오**

1. 송신자는 데이터 암호화에 사용할 **세션키**를 고른다.
   - 세션키는 대칭키 암호화에 사용된다. 즉, 밥에게 세션키를 알려야 한다.
2. 송신자는 수신자의 공개키로 세션키를 RSA 암호화한다.
3. 수신자는 암호문을 받고 자신의 개인키로 복호화한다.
4. 수신자는 세션키를 얻고, 송신자가 보낸 데이터를 복호화할 수 있다.

`m = m mod n= m^ed mod n` 임을 증명하면 된다.

정수론에 의하면 p와 q가 소수이고 `n = pq`, `z = (p-1)(q-1)`이면, `x^y mod n` 이 `x^(y mod z) mod n`과 같다.

즉, 다음과 같은 식을 얻을 수 있다.

`m^ed mod n = m^(ed mod z) mod n`

ed mod z = 1이 되도록 e와 d를 선택하였으므로, `m = m mod n= m^ed mod n` 이다.

여기서 e와 d는 단순 제곱이므로 둘을 바꿔도 정상 동작한다.


1. 메시지가 정말 해당 출발지로부터 왔는가?
2. 메시지가 전달되는 도중 변경되지는 않았는가?


해시 함수는 입력 m을 받아서 해시라 불리는 고정된 크기의 문자열 H(m)을 계산해낸다.

암호화 해시 함수는 H(x) = H(y)가 되는 서로 다른 두 메시지 x와 y를 찾는 일이 산술적으로 실행 불가능하다.

즉, (m, H(m))이 원래 메시지와 그 메시지에 대해 송신자가 만들어낸 해시값이라고 할 때, 침입자가 원래 메시지와 동일한 해시값을 갖는 다른 메시지 y를 위조해낼 수 없다.

인터넷 체크섬과 같은 간단한 체크섬은 같은 값을 만들기 쉬워 암호화 해시 함수로 사용하기에는 너무 허술하다.

MD5 해시 알고리즘이 오늘날 널리 쓰이고 있다.

1. 덧붙이는 단계
   - 하나의 1을 메시지 뒤에 붙이고 충분히 많은 0을 뒤에 덧붙여서 메시지 길이가 단위 길이 조건을 만족시킨다.
2. 추가 단계
   - 덧붙이기 전 메시지 길이를 64비트로 표현하여 추가
3. 어큐뮬레이터 초기화
4. 루프 단계
   - 메시지를 16워드 길이의 단위 블록들로 나누어 4개 라운드로 처리한다.

SHA 알고리즘은 MD4에 사용된 원리와 유사한 원리를 사용하여 널리 사용된다.


1. 송신자는 메시지 m을 생성하고 해시값 H(m)을 만든다.
   - 이때 SHA 등이 사용된다.
2. 송신자는 메시지 m에 H(m)을 첨부하여 확장 메시지 (m, H(m))을 생성한 후 수신자에게 보낸다.
   (수신자의 입장에서는 (m, h)로 보임)
3. (m, h)를 받은 수신자는 H(m)을 계산하고 이것이 h와 같다면 문제 없이 처리되었음을 확인한다.

이때, 침입자가 (m’, H(m’))을 자신이 수신자라고 주장하며 보내면 위 단계를 통과하고 부적절한지 알 수 없다.


송신자를 확인하기 위해 송신자 수신자는 비트열 형태의 **인증키**인 비밀키를 공유하여야 한다.

1. 송신자는 메시지 m을 생성하고 인증키 s와 합하여 m+s를 만들고, H(m+s)를 생성한다.
   - H(m+s)를 **메시지 인증 코드**(message authentication code, MAC 이는 링크 계층의 메시지와는 다르다.)라고 부른다.
2. 송신자는 (m, H(m+s))를 보낸다. (수신자의 입장에서는 (m, h)로 보임)
3. 수신자는 (m, h)를 받으면 H(m+s)를 계산하고 값이 h와 같다면 문제가 없다고 결론 짓는다.

메시지 인증 코드는 복잡한 암호화 알고리즘을 필요로하지 않는다.

MD5와 SHA와 함께 사용되는 메시지 인증코드는 HMAC으로 가장 많이 사용되는 표준이다.

통신 개체들에게 인증키를 전달하는 방법은 네트워크 관리자가 각각의 라우터에 직접 접근하거나 인증키를 각 라우터의 공개키로 암호화하여 네트워크를 통해 전달할 수 있다.

디지털 세계에서 문서의 소유자를 명시하거나 어떤 사람이 문서의 내용에 동의했다는 것을 표시하길 원하고, **전자 서명**은 디지털 세계에서 이러한 목적으로 사용된다.

서명 시 실제로 그 사람이 서명했다는 사실, 그리고 오직 그 사람만이 문서에 서명할 수 있었다는 사실을 증명할 수 있어야 한다.

공개키 암호화 방법은 개인키와 공개키를 따로 가지고 있어 전자 서명에 효과적이다. (다른 사람은 개인키로 서명할 수 없다.)


1. 서명자는 문서 m을 서명하려한다.
2. 서명자는 자신의 개인키로 K(m)을 만든다. 이것이 바로 전자 서명이다.
   - 전자서명 K(m)은 **서명자의 개인키로 만들어져 서명자만 만들 수 있다.**
3. 전자서명 K(m)을 받은 사람들은 서명자의 공개키를 사용해 원래의 m을 다시 확인할 수 있다.
   - 즉, **공개키의 주인인 서명자가 쓴 서명이라는 것이 확인**된다.
   - 어느 한 사람이 중간에 문서를 조작해 m’을 만들었어도 m과 같지 않으므로 유효하지 않음을 알 수 있다. 즉, 메시지 무결성을 확인할 수 있다.

자신의 개인키로 먼저 암호화하고 공개키로 복호화해도 되는 이유는, `m^ed mod n = m^de mod n = m mod n` 이기 때문이다.

m 자체에 암호화 복호화를 하면 계산의 부하가 심하다.

이때, 해시 알고리즘을 사용하여 해결할 수 있다.

즉, m을 H(m)으로 표현되는 고정 길이의 지문을 계산해내고, K(H(m))을 계산하여 계산의 부하를 줄인다.

1. 메시지 m을 해시 알고리즘을 이용하여 고정 길이로 바꿔 H(m)을 만든다.
2. H(m)을 자신의 개인키로 암호화 한다.
3. (m,K(H(m)))을 보낸다.


1. 서명자로 부터 (m,K(h))를 받는다.
2. 서명자의 공개키로 K(h)를 복호화하여 h를 알아낸다.
3. m을 해시 알고리즘을 이용하여, H(m)으로 만들고 h와 일치하는지 알아낸다.

전자 서명은 인증기관과 함께 공개키 하부 구조를 요구하기 때문에 MAC에 비해 더 무거운 기술이다.

많은 프로토콜에서는 MAC이 사용된다.


전자 서명에서는 공개키가 특정 통신 개체에 속한다는 것을 보증하여야 한다. (IPsec과 TSL를 포함한 많은 보안 네트워킹 프로토콜에서 사용된다.)

중간에 침입자가 자신이 서명자라고 주장하며 메시지를 보내는데, 이때 공개키를 자신의 공개키를 담아 보낸다.

수신자는 침입자의 공개키를 사용해 메세지를 복호화 할 것이고, 수신자는 서명자가 쓴 서명임을 확신할 것이다.

즉, 공개키 암호를 사용하려면 서명자의 공개키라고 생각되는 것이 정말 서명자의 것인지 확인하여야 한다.

공개키가 어떤 통신 개체(서명자)의 것인지 보증하는 일은 일반적으로 CA(인증 기관)에서 담당한다.

CA는 신원을 확인하고 인증서를 발행한다.

1. CA는 어떤 개체(사람, 라우터)가 스스로 주장하는 자신의 신분이 바로 그 개체가 맞는지 확인한다.
   - 인증에 정해진 방법은 없고 CA가 적절한 방법으로 엄격하게 식별자 검증을 수행하리라는 점을 신뢰해야한다.
2. 일단 CA가 신원을 확인하면, CA는 개체의 공개키와 신분 확인서를 결합한 인증서를 만든다.
   - 인증서에는 CA가 서명한다.

**종단점 인증**이란 하나의 통신 개체가 다른 개체에게 자신의 신원을 컴퓨터 네트워크상으로 증명하는 작업이다.

예를 들어, 전자 메일 사용자가 서버에 신원을 입증할 수 있다.

서로 간의 인증은 인증 프로토콜의 한 부분으로서 교환된 메시지와 데이터만을 기반으로 수행되어야 한다.

대부분의 인증 프로토콜은 다른 프로토콜을 수행하기 전에 수행된다.

즉, 인증 후에 작업을 수행한다.


송신자가 이미 알려진 네트워크 주소(IP 주소)를 가지고 통신을 한다면 수신자는 인증 메시지를 가지고온 IP 데이터 그램 출발지 주소가 송신자의 IP 주소와 일치하는지 확인함으로써 앨리스를 인증할 수 있다.

그러나 IP 데이터그램을 생성해서 원하는 출발지 IP 주소를 넣고 그 데이터그램을 라우터로 보낼 수 있으므로 이는 안전하지 못하다.

예를 들어, 침입자가 가짜 출발지 주소를 쓰고 데이터를 보낼 수 있는데 이 방법은 `IP 스푸핑`의 한 형태이다.

침입자가 출발지 주소를 바꾸지 못하게 하면 되겠지만, 이는 강제할 수 없다.

인증자와 인증 받는 사람 간에 공유된 비밀번호를 사용할 수 있다.

지메일, 페이스북 등 많은 서비스가 비밀번호 인증을 사용한다.

그러나 이 프로토콜은 안전하지 못하다.

침입자가 송신자의 통신을 도청한다면 송신자의 비밀번호를 알아낼 수 있고, 이후 송신자인 척 할 수 있다.


비밀번호를 암호화하여 비밀번호를 엿듣는 것을 막을 수 있다.

송신자와 수신자는 대칭 비밀키를 공유하여 비밀번호를 암호화 복호화할 수 있다.

그러나 수신자는 `재생 공격(playback attack)`의 위험에 노출되어 있다.

침입자는 도청하여 송신자의 암호화된 비밀번호를 저장했다가 나중에 그대로 수신자에게 보낸다.

즉, 송신자인 척 할 수 있다.

`넌스(nonce)`는 프로토콜이 평생에 단 한 번만 사용하는 숫자를 뜻한다.

**시나리오**

1. 송신자는 메시지를 보낸다.
2. 수신자는 넌스 R을 선택하고 그것을 송신자에게 보낸다.
3. 송신자는 대칭 비밀키를 이용하여 그 넌스를 암호화하고, 암호화된 넌스 K(R)을 수신자에게 보낸다.
   - 해당 송신자가 다음에 또 통신을 하면 R이 바뀌어도 비밀키를 알고 있으므로 또 인증을 받을 수 있다.
   - 그러나 침입자라면 비밀키를 모르고 있으므로 암호화할 수 없다.
4. 수신자는 상대방이 대칭 비밀키를 알고 있으므로 상대방인 것을 확인한다.


보안은 인터넷 프로토콜 스택 위쪽 4개 계층의 어느 곳에서나 보안 서비스를 제공할 수 있다.

보안이 특정 애플리케이션 계층 프로토콜을 위해 제공되면 그 프로토콜을 사용하는 애플리케이션은 보안 서비스를 사용할 수 있게 된다.

보안은 네트워크 계층에서 제공하는 것으로 충분하지 않을까?

1. 네트워크 계층에서 데이터그램의 모든 데이터를 암호화하고 IP 주소를 인증함으로써 ‘전면적 범위’의 보안을 제공하더라도 사용자 레벨의 보안은 제공할 수 없다.
   - 예를 들어, 인터넷 상거래 사이트는 물건을 구입하려는 고객을 인증하는 데 IP 계층 보안에만 의존할 수는 없다.
2. 프로토콜 상위 계층에서 보안 서비스를 포함한 새로운 인터넷 서비스를 구현하는 일이 점차 쉬워지고 있다.


보안 전자메일 시스템을 만들기 위해 암호화 원리들을 이용해보자.

메시지를 대칭키 기술(AES,DES 등)으로 암호화 복호화하여 기밀성을 얻을 수 있다.

그러나 송수신자만 대칭키를 알기에 어렵기 때문에 공개키 암호화(RSA)를 고려하게 된다.

그러나 RSA를 통해 메시지를 암호화 복호화 한다면 계산 부하가 너무 심해서 실질적으로 쓸 수 없다.

이를 위해 세션키를 사용한다.

1. 송신자는 임의의 **대칭 세션키 Ks**를 선택한다.
   - 이 대칭 세션키는 AES나 DES에 사용된다.
2. Ks로 메시지 m을 암호화하여 암호문 1을 얻는다.
3. Ks는 송신자의 공개키로 암호화하여 암호문 2를 얻는다.
4. 이 두개의 암호문을 수신자에게 보낸다.
5. 수신자는 자신의 개인키로 암호문 1을 복호화하여 Ks를 얻을 수 있다.
6. 얻은 Ks로 암호문 2를 복호화하여 m을 얻을 수 있다.

이렇게 기밀성을 얻을 수 있다.


이 둘을 얻기 위해 전자서명과 해시 알고리즘을 이용한다.

1. 송신자는 메시지 요약문을 얻기 위해 m에 해시함수를 적용하여 H(m)을 얻는다.
2. 전자 서명을 만들기 위해 해시의 결과를 자신의 개인키로 암호화한다.
3. 메시지 m과 전자서명을 수신자에게 보낸다.
4. 수신자는 송신자의 공개키로 전자서명을 복호화한다.
5. 메세지 m에 해시 알고리즘을 적용한 결과와 4의 결과를 비교하여 같으면 보낸 사람을 확인할 수 있고, 메시지의 무결성을 확인할 수 있다.

1. 먼저 송신자 인증과 무결성 과정을 통해 얻은 메시지와 전자서명 꾸러미를 만든다.
2. 이 꾸러미를 메시지 취급하여 기밀성 과정을 통해 수신자에게 전달한다.
3. 수신자는 순서대로 복호화하여 확인한다.

그러나 수신자는 송신자의 공개키를 알아야하고, 송신자는 수신자의 공개키를 알아야 하므로 CA를 통해 공개키를 인증 받아야한다.


PGP는 암호화 기법의 좋은 예로 본질적으로 위 통합과 동일하다.

1. PGP가 설치되면 소프트웨어는 사용자를 위한 공개키 쌍을 만든다.
   - 공개키는 사용자 웹사이트에 게시되거나 공개키 서버에 놓인다.
   - PGP 공개키는 사용자간 `신뢰의 그물(web of trust)` 속에서 인증된다.
   - 어떤 PGP 사용자들은 키 서명을 위한 모임을 열어 같은 물리적 공간에 모여서 공개키를 교환하고 그들의 개인키로 서명하는 것으로 서로의 키를 보증한다.
2. 개인키는 비밀번호로 보호된다.
   - 개인키를 사용하려면 사용자는 비밀번호로 인증해야한다.
3. PGP는 전자메일과 같은 방식으로 사용자에게 메시지를 전자서명하거나 암호화하거나 둘다 하거나 하는 선택지를 제공한다.
   - 개인키, 공개키, 해시 알고리즘, RSA가 있으니 모두 가능하다.

보안 서비스가 추가되어 향상된 TCP 버전을 흔히 `TLS(Transport Layer Security)` 라고 부른다.

TLS는 기밀성, 데이터 무결성, 서버인증과 클라이언트 인증을 통해 TCP를 향상하여 보안 서비스를 제공한다.

TLS는 TCP를 보호하기 때문에 TCP 상에서 일어나는 어떠한 애플리케이션에든 사용될 수 있다.

TLS는 소켓을 사용하는 간단한 API를 제공하는데, TCP의 API와 유사하다.

TLS는 애플리케이션 계층에 존재하나 개발자의 관점에서는 보안 서비스로 강화된 TCP 서비스를 제공하는 트랜스포트 프로토콜이다.


TLS를 이해하기 위해 TLS의 단순화된 버전인 `almost-TLS`를 먼저 설명한다.

`almost-TLS` 는 핸드셰이크, 키 유도, 데이터 전송이라는 세 단계로 되어 있다.

1. 클라이언트는 서버와 TCP 연결을 설립한다.
2. 서버가 진짜 서버인지 확인한다.
   - 클라이언트는 hello 메시지를 보내고, 서버는 CA로부터 인증된 인증서를 보내어 클라이언트는 인증서 내의 공개키가 서버의 것이라는 것을 믿을 수 있다.
3. TLS 세션에 필요한 모든 대칭키를 생성하기 위해 서버와 클라이언트가 사용할 주 비밀키(Master Secret, MS)를 생성하여 전송한다.
   - MS를 보낼 때, 서버의 공개키로 암호화하여 EMS(Encrypted Master Secret)를 만든다.
   - 서버는 자신의 개인키로 EMS를 복호화 하여 MS를 얻는다.
   - 즉, 둘은 둘만 아는 MS를 알게 된다.


공유한 MS는 모든 암호화와 데이터 무결성 검사를 위한 대칭 세션키로 사용될 수 있으나 일반적으로 각각 다른 암호화 키를 사용하는 것이 좀 더 안전하다.

따라서 MS를 이용하여 4개의 키를 만든다.

- E(b) = 클라이언트가 서버에 보내는 데이터에 대한 세션 암호화 키
- M(b) = 클라이언트가 서버에 보내는 데이터에 대한 세션 HMAC(메시지 인증 코드) 키
- E(a) = 서버가 클라이언트에 보내는 데이터에 대한 세션 암호화 키
- M(a) = 서버가 클라이언트에 보내는 데이터에 대한 세션 HMAC(메시지 인증 코드) 키

이는 단순히 MS를 4개의 키를 쪼개어 이루어진다.

2개의 암호화 키는 데이터를 암호화하고, 2개의 HMAC 키는 데이터 무결성을 확인하는 데 사용된다.

TCP는 바이트 스트림 프로토콜이므로, TLS가 애플리케이션 데이터를 끊임없이 암호화하고 암호화된 데이터를 TCP에 쉴 새 없이 전달하는 것이 자연스럽다.

그렇다면 HMAC은 언제 해야할까?

분명한건 전체 세션 시간 동안 전송된 모든 데이터의 무결성을 확인하는 일이 TCP 세션이 종료될 때까지 미뤄둘 수 없다는 것이다.

TLS는 데이터 스트림을 레코드로 쪼개고 각 레코드에 무결성 검사를 위한 HMAC을 덧붙인 후 이 `레코드+HMAC`을 암호화한다.

HMAC을 생성하기 위해 클라이언트는 레코드 데이터와 키 M(b)를 해시 함수에 넣는다.

`레코드+HMAC` 꾸러미를 암호화 하기위해 E(b) 를 사용하여 TCP로 전송한다.

그러나 만약 침입자가 TCP 세그먼트 스트림에서 스트림을 삽입, 삭제, 교환할 수 있다면 위 방법은 안전하지 않다.

예를들어, 침입자가 2개의 세그먼트 순서를 바꾼 후 TCP 세그먼트 번호까지 그에 맞게 변경하여 서버에 보낸다면 서버의 TLS는 문제 없이 이를 애플리케이션 계층에 넘겨준다.

TLS는 순서번호를 이용해서 이 문제를 해결한다.

클라이언트는 순서 번호 카운터를 유지하며 TLS 레코드를 보낼 때마다 하나씩 증가시킨다.

HMAC을 계산할 때 `HMAC 키 M(b)`와 `레코드 데이터`와 `순서 번호`를 합친 결과의 해시로 사용한다.

서버는 클라이언트의 순서번호를 추적해서 자신의 HMAC 계산을 할 때 적절한 순서 번호를 포함시켜 레코드의 데이터 무결성을 확인한다.


첫 세 필드는 암호화되지 않는다.

타입 필드는 핸드셰이크 메시지인지 데이터를 담은 메시지인지 나타낸다.

이제 완전한 버전의 TLS를 살펴보자.


TLS는 서버와 클라이언트에게 특정 대칭키 알고리즘이나 공개키 알고리즘을 사용하도록 강제하지 않는다.

대신 핸드셰이크 과정에서 암호화 알고리즘을 합의하고, 서로에게 넌스를 보내 세션키를 생성한다.

**시나리오**

1. 클라이언트는 넌스와 함께 자신이 지원하는 암호화 알고리즘의 목록을 보낸다.
   - 넌스를 사용하는 이유는 만약 침입자가 모든 메시지를 엿들은 후 그대로 서버에게 보내게 된다면, 순서번호를 둔다고 하더라도 그것 또한 그대로 일치하므로 서버에서는 똑같은 메시지를 한번 더 들은 것으로 인지하기 때문이다.
   - 넌스를 포함하면 모든 메시지는 유일성을 가지게 되므로 보안에 안전해진다.
2. 목록으로부터 서버는 대칭키 알고리즘, 공개키 알고리즘, HMAC 키와 함께 HMAC 알고리즘을 선택한다.
3. 선택 결과와 인증서, 서버 넌스를 클라이언트에게 보낸다.
4. 클라이언트는 인증서를 확인하고 서버의 공개키를 알아낸 후 `PMS(Pre-Master-Secret)`을 생성한다. 이 PMS를 서버의 공개키로 암호화한 후 서버에게 보낸다.
5. 클라이언트와 서버는 같은 키 유도 함수를 사용하여 PMS와 넌스로부터 MS를 계산한다.
6. 이 MS는 2개의 암호화 키와 2개의 HMAC 키를 생성하기 위해 분할된다.
7. 이후 모든 메시지는 암호화되고 인증된다.
8. 클라이언트는 모든 핸드셰이크 메시지의 HMAC을 전송한다.
9. 서버는 모든 핸드셰이크 메시지의 HMAC을 전송한다.
   - 8, 9번 과정은 처음 암호화되지 않은 메시지에 대한 침입자의 수정을 대비해서 지금까지 주고 받은 메시지의 일치 불일치를 확인하는 것이다.

단순히 바로 TCP FIN 세그먼트를 보내 종료시키면 문제를 발생시킬 수도 있다.

침입자가 임의로 TCP FIN 세그먼트를 보내 종료시키는 절단 공격 문제가 발생한다.

이를 해결하기 위해 레코드의 타입 필드에 그 레코드가 TLS 세션 종료를 수행할 것인지를 표시한다.


IPsec이라고 알려진 IP 보안 프로토콜은 네트워크 계층의 보안을 제공한다.

- 호스트나 라우터 같은 네트워크 계층의 어떤 두 개체 사이에서 IP 데이터그램을 보호한다.
  - **데이터그램의 페이로드 부분을 암호화**하여 TCP 세그먼트 등이 암호화된다.
- 위의 기밀성을 제공하는 것처럼 출발지 인증, 데이터 무결성, 재생 공격 방지 같은 보안 서비스를 제공할 수 있다.


흩어져있는 기관들은 그들의 호스트와 서버가 기밀성을 유지하며 안전하게 서로에게 데이터를 전송할 수 있도록 종종 자신만의 IP 네트워크를 갖기를 원한다.

이를 위해 공공 인터넷과 완전히 분리된 라우터, 링크, DNS 시스템을 포함하는 물리적으로 독립된 네트워크를 실제로 설치할 수 있고, 이러한 네트워크를 `사설 네트워크(private network)`라고 한다.

큰 유지 비용이 드는 사설 네트워크 대신 오늘날에는 기존 공공 인터넷 상에 `VPN`을 설치한다.

`VPN` 을 이용하면 기관의 사무실간 트래픽은 공공 인터넷을 통해 전송된다.

그러나 기밀성을 제공하기 위해 이 트래픽들은 공공 인터넷에 들어가기 전에 암호화된다.

공공 인터넷을 통과하지 않을 때는 평범한 IPv4 데이터그램이 사용되고, 통과해야할 때는 IPsec을 지원하는 라우터가 IPv4 데이터그램을 IPsec 데이터그램으로 바꾼 후 인터넷으로 전송한다.

IPsec 데이터그램은 전형적인 IPv4 헤더를 가지고 있어 공공 인터넷의 라우터는 IPv4 데이터그램과 똑같이 이를 전달한다.

실질적으로는 IPsec 데이터그램의 페이로드는 IPsec헤더를 포함하고, 이는 IPsec 처리를 위해 사용된다.

출발지 IPsec 개체가 보안 데이터그램을 목적지 개체에 보낼 때 AH 프로토콜이나 ESP 프로토콜을 사용한다.

- AH프로토콜
  - 출발지 인증과 데이터 무결성을 제공하지만, 기밀성을 제공하지 않는다.
- ESP 프로토콜
  - 출발지 인증과 데이터 무결성, 기밀성을 제공한다.
  - 대부분 기밀성을 필요로 하여 널리 사용된다.


IPsec 데이터그램을 전송하기전 출발지 개체와 목적지 개체는 네트워크 계층에서 논리적 연결을 설립하는데 이것이 바로 `SA(security association)`이다.

SA는 단방향이어서 서로에게 데이터를 보내기 위해서는 두개의 SA가 필요하다.

기관 내에 n개의 호스트가 있다면, SA는 2n개 그리고 지점의 라우터가 m개가 있다면 추가로 2m개 즉, `2n + 2m`개 필요하다.

게이트웨이 라우터나 랩톱이 인터넷으로 보내는 모든 트래픽이 IPsec 방식으로 보호되지는 않는다.

예를 들어, 보안이 필요한 기관 내의 호스트가 아닌 구글 등의 공공 인터넷의 웹서버에 접속할 수도 있기 때문에 라우터나 랩톱은 IPv4 데이터그램과 IPsec 모두를 전송한다.

R1은 SA에 대해 다음과 같은 상태 정보를 포함한다.

- SA에 대한 32 비트 식별자 SPI
- SA 시작점의 인터페이스(200.168.1.100)와 최종점의 인터페이스(193.68.2.23)
- 사용되는 암호화 타입 (AES, DES 등)
- 암호화 키
- 무결성 검사 타입 (MD5, SHA 등)
- 인증키

이들을 사용해 암호화하고, 인증을 하며 R2도 마찬가지로 같은 상태정보를 유지한다.

SA가 많을 수 있어 그 상태정보를 유지해야하는데 IPsec 개체는 모든 SA에 대한 상태 정보를 그 개체의 OS 커널에 있는 `SAD(security association Database)`라는 데이터 구조에 저장한다.

라우터 R1은 원본 IPv4 데이터그램을 IPsec 데이터그램으로 변환하기 위해 다음 과정을 이용한다.

1. 원래 IPv4 데이터그램의 뒤에 ESP 트레일러를 덧붙인다.
   - 원래 IPv4 데이터그램에 원래 목적지 IP 주소, 출발지 IP 주소가 들어가 있다.
   - **ESP 트레일러**는 패딩, 패딩 길이, 다음 헤더라는 3개의 필드로 이루어져 있다.
     - 패딩 : 원래 데이터그램에 덧붙어 최종 메시지가 정수개의 고정 길이 블록으로 분할될 수 있게 한다.
     - 패딩 길이 : 패딩 비트가 얼마나 삽입되었는지 알려주고, 이를 이용해 패딩을 삭제한다.
     - 다음 : 페이로드에 포함된 데이터의 타입(ex: UDP)을 지시한다.
2. SA에 의해 지정된 알고리즘과 키를 이용하여 위 결과를 암호화한다.
3. 암호화된 결과의 앞에 ESP 헤더 필드를 덧붙인다. 결과로 나온 패키지를 엔칠라다라고 부르자.
   - ESP 헤더에는 SPI와 순서번호를 포함한다.
     - SPI : 수신 개체에게 데이터그램이 어느 SA에 속해 있는지 지시한다. 이 SPI를 가지고 자신의 SAD를 검색하여 알맞은 인증 및 복호화 알고리즘과 키를 결정한다.
     - 순서 번호 : 재생 공격을 막기 위해 새용된다.
4. SA가 지정한 알고리즘과 키를 이용하여 전체 엔칠라다에 대한 인증 MAC을 생성한다.
5. 엔칠라다 뒤에 MAC을 붙여 페이로드를 만든다.
   - 비밀 MAC 키를 엔칠라다에 붙이고 그 결과에 대해 고정 길이의 해시를 계산한다.
6. 전형적인 IPv4 헤더 필드를 가지고 완전히 새로운 IP 헤더를 만들어 위의 페이로드 앞에 붙인다.
   - 새로운 IP 헤더에는 출발지와 목적지 주소는 전달될 라우터 인터페이스의 주소가 들어간다.
   - 헤더 필드의 상위 프로토콜 값으로는 TCP,UDP 등을 나타내지 않고 이것이 ESP 프로토콜을 사용하는 IPsec임을 나타내는 값을 사용한다.

결과로 나온 IPsec 데이터그램은 전형적인 IPv4 헤더를 가지고 페이로드가 따라오는 진짜 IPv4 데이터그램이다.

전달하는 라우터들은 IPsec으로 암호화된 정보라는 것을 모른체 목적지 라우터 인터페이스로 이를 전달한다.

라우터 R2는 IPsec 데이터 그램을 받으면 다음과 같은 과정을 수행한다.

1. IP 헤더를 보고 IPsec ESP 프로토콜을 적용해야함을 알게된다.
2. 엔칠라다를 들여다보고 R2는 SPI를 이용하여 데이터그램이 어느 SA에 속한것인지 알아낸다.
3. 엔칠라다의 MAC을 계산하여 ESP MAC 필드의 값과 일치하는지 확인한다.
   - 일치하여야 조작되지 않은 것이다.
4. 데이터그램이 재생된 것이 아닌지 순서 번호 필드를 검사한다.
5. SA와 관련된 복호화 알고리즘과 키를 이용하여 암호화된 부분을 복호화한다.
6. 원래의 IP 데이터그램을 최종 목적지로 전송하기 위해 지점 네트워크로 전달한다.

IPsec 개체는 SAD와 함께 `SPD(security policy database)`라 불리는 자료구조를 유지한다.

SPD는 어떤 형태의 데이터그램(출발지 IP 주소, 목적지 IP 주소, 프로토콜 타입으로 결정)이 IPsec으로 처리되어야 하는지와 그때 사용될 SA를 지시한다.

즉, SPD의 정보는 도착한 데이터그램으로 무엇을 할지 알려주고, SAD의 정보는 어떻게 할 것인지를 알려준다.


수백 수천 개의 IPsec 라우터와 호스트로 이루어진 큰 VPN에서는 종단점의 SAD에 직접 SA 정보를 입력 하는 방법은 불가능하다.

즉, SA를 생성하는 자동화된 방법이 필요한데 이 방법으로 `IKE 프로토콜`을 이용한다.

각 IPsec 개체는 그 개체의 공개키가 포함된 인증서를 갖는다.

SSL 에서와 마찬가지로 IKE 프로토콜은 두 개체가 인증서를 교환하고 인증과 암호화 알고리즘에 대한 협상을 하게 하며 IPsec SA의 세션키를 생성하기 위한 중요한 자료를 안전하게 교환할 수 있게 한다.

IKE는 이러한 작업을 수행하기 위해 두단계를 거친다.

R1과 R2는 메시지 쌍을 두 번 교환한다.

- 첫 번째 메시지 교환시에는 양측이 라우터 사이의 IKE SA를 설립하기 위해 디피-헬만 알고리즘을 사용한다.
  - IKE SA는 IPsec SA와는 완전히 다르다.
  - IKE SA는 두 라우터 사이에 인증되고 암호화된 채널을 제공한다.
  - 이 첫 번째 메시지를 교환하는 동안 IKE SA의 암호화와 인증을 위한 키가 설립된다.
  - 또한, 두번째 단계에서 IPsec SA 키를 계산하기 위해 사용될 주 비밀키도 만들어진다.
  - 첫번째에서는 누구도 비밀키로 서명함으로써 자신의 신분을 드러내지 않는다.
- 두번째 교환에서는 양측이 메시지에 서명하여 서로에게 신분을 드러낸다.
  - 그러나 메시지가 보안 처리된 IKE SA 채널을 통해 전송되므로 단순한 도청자에게는 신분이 누설되지 않는다.
  - 양측이 IPsec SA에 의해 사용될 IPsec 암호화 및 인증 알고리즘에 대해 협의한다.


양측이 각 방향으로 하나씩 SA를 설립한다.

이 단계를 마칠 때는 이 2개의 SA에 대한 암호화 및 인증 세션키가 양측에 만들어져있다.

이후 보안 처리된 데이터그램을 만들기 위해 SA를 사용할 수 있다.


- 상호인증
  - 이동 장치가 AP에 접속하여 데이터그램을 외부에 전송하기 전에, 네트워크는 접속하는 이동 장치의 신원을 확인하고, 그 장치의 접속 권한을 점검하기 위해 장치를 인증하기를 원한다.
  - 이동장치의 경우도 접속하는 네트워크가 진짜 접속을 원하는 네트워크가 맞는지 인증하기를 원한다.
  - 이런 양방향 인증을 **상호 인증**이라고 한다.
- 암호화
  - 802.11 프레임은 무선 채널을 통해 교환되기 때문에, 이동 장치와 AP 간에 교환되는 사용자 레벨 데이터를 지니고 있는 링크 레벨 프레임의 암호화가 중요하다.
  - 높은 속도를 요해 대칭키 암호화가 사용된다.


1. 발견
   - AP는 자신의 존재와 함께 이동 장치에게 제공될 수 있는 인증과 암호화 형식을 알린다.
   - 이동 장치는 원하는 인증과 암호화 형식을 요청한다.
2. 상호 인증과 공유 대칭키 생성
   - 인증 서버와 이동 장치 간에 이미 **공유된 공통의 비밀**을 갖고 있다고 가정한다.
   - 이동 장치와 인증 서버는 서로 간의 인증에 넌스와 암호화 해싱 등과 함께 공유 비밀을 이용하게 된다.
   - 이동 장치와 AP 간의 무선 링크를 통해 전송될 프레임의 암호화에 사용될 공유 세션키를 생성한다.
3. 공유 대칭 세션키 분배
   - 대칭 비밀키는 이동 장치와 인증 서버에서 생성되기에, 인증 서버가 AP에게 공유 대칭 세션키를 알려주기 위한 프로토콜이 필요하다.
4. AP를 통한 이동 장치와 원격 호스트 간의 암호 통신
   - 2단계와 3단계에서 생성되고 분배된 세션키를 사용하여 암호화된 링크 계층 프레임을 가지고 통신이 이루어 진다.
   - 프레임 데이터를 암호화 복호화하기 위해 AES 대칭키 알고리즘을 사용한다.

초기 802.11 보안 규정 WEP은 심각한 보안 오류가 있었고, 이를 극복하기위해 WPA1이 개발되었다.

WPA1은 메시지 동질성 검사와 사용자가 일정 기간 암호화된 메시지 스트림을 관찰하여 암호화 키를 추측하게 하는 공격을 피하는 것을 도입하였다.

WPA2는 AES 대칭키 암호화를 의무화하여 WPA1을 개선했다.

위 그림은 간략한 네 방향 핸드셰이크 프로토콜을 보여준다.

공유 비밀키(ex 비밀번호)를 서로 알고 시작한다.

1. 인증 서버는 넌스를 생성하여 이동 장치로 전송한다.
2. 이동 장치는 넌스를 AS로부터 전송받고 자신의 넌스를 생성한다. 이동 장치는 **자신의 넌스, 받은 넌스, 최초 공유 비밀 키, 이동 장치의 MAC 주소, AS의 MAC 주소를 사용하여 대칭형 공유 세션키**를 생성해낸다. 그런 후 자신의 넌스그리고 받은 넌스와 원래의 공유 비밀을 암호화한 HMAC-signed 값을 전송한다.
3. 인증 서버는 최근에 전송한 넌스의 HMAC-signed 버전을 보아 이동 장치가 공유 비밀키로 암호화를 할 수 있었고, 인증 서버 또한 이동 장치가 주장하는 본인이라는 것을 알게되어 이동 장치를 인증하게 된다. **자신의 넌스, 받은 넌스, 최초 공유 비밀 키, 이동 장치의 MAC 주소, AS의 MAC 주소를 사용하여 대칭형 공유 세션키를 사용해 똑같은 대칭형 공유 세션키를 만들 수 있다.**

만든 대칭형 공유 세션키를 AP에 공유하여 이동 장치와 AP는 서로 데이터를 주고 받을 수 있다.


위 그림은 802.11 보안 프레임워크를 구현하기 위해 사용된 `확장 인증 프로토콜(Extensible Authentication Protocol, EAP)`를 보여준다.

이 프로토콜은 종단 간의 메시지 포멧을 정의한다.

EAP 메시지들은 EAPoL을 사용하여 캡슐화되어 무선 링크로 전송된다.

이러한 EAP 메시지들은 AP에서 역캡슐화되며, RADIUS 프로토콜을 사용하여 재캡슐화되어 UDP/IP를 통해 인증 서버로 전송된다.

4G/5G 환경에서의 상호 인증과 키 생성의 목적들은 802.11 환경에서와 동일하다.

4G 인증과 키 동의 프로토콜

1. HSS에 인증 요청
   - 이동 장치가 기지국을 경유하여 네트워크에 처음으로 접속 요청을 할 때, 이동성 관리 개체로 전달되는 기기의 국제 이동 가입자 식별자(IMSI)를 포함하는 접속 메시지를 보낸다.
   - MME는 IMSI와 방문지 네트워크 관련 정보를 HSS로 보낸다.
2. HSS로부터의 인증 응답
   - HSS는 사전 공유 비밀키를 사용하여 인증토큰인 auth_token과 예상되는 인증 응답인 xres를 유도하기 위해 암호화 동작을 수행한다.
   - auth_token은 이동 장치로 하여금 auth_token을 계산한 누구든지 비밀키를 알고 있다는 사실을 인지하게 하는 사전 공유 비밀키를 사용하여 HSS가 암호화한 정보를 포함한다.
   - 즉, auth_token은 사전공유키 K(IMSI)이고, 같은 사전 공유키를 가지고 있으면 IMSI를 알 수 있어 HSS가 비밀키를 알고 있음을 인지하고, 이동장치는 인증된다.
   - xres는 이동 장치가 계산에 필요해지는 값을 포함하고 있으며 MME에게 이동 장치가 비밀키를 알고 있음을 증빙하여 MME에게 이동 장치가 인증된다.
   - MME만이 인증 응답 메시지를 받고, 향수 사용을 위해 xres를 저장하고, 인증 토큰을 추출하여 이동 장치에 전송하는 중간자 역할을 한다.
3. 이동 장치로부터의 인증 응답
   - 이동 장치는 auth_token을 사전 공유키로 복호화하여 IMSI를 얻어 HSS를 인증한다.
   - 이동 장치는 res값을 계산하여(자신의 비밀키를 활용하여) 그 값을 MME에게 보낸다.
4. 이동장치 인증
   - MME는 이동 장치가 계산한 res와 HSS가 계산한 xres를 비교하여 일치하면 모두 공통 비밀키를 갖고 있음을 증빙한 것이므로 이동 장치가 인증된다.
   - MME는 기지국과 이동 장치에게 상호 인증이 완료되었음을 알리고, e단계에서 사용할 기지국 키를 보낸다.
5. 데이터 평면과 제어 평면 키 도출
   - 이동 장치와 기지국은 무선 채널을 통해 프레임 전송에 사용될 암/복호화 키들을 각자 결정한다.
`방화벽(firewall)`은 전체 인터넷으로부터 기관의 내부 네트워크를 분리시킨 하드웨어와 소프트웨어의 조합으로, 어떤 패킷은 통과가 허용되나 어떤 패킷은 차단된다.
네트워크 관리자가 해당 네트워크에 대한 트래픽 출입을 관리하여 접속을 제어한다.
- 외부와 내부를 오가는 모든 트래픽은 방화벽을 거친다.
- 로컬 보안 정책에 정의된 대로 승인된 트래픽만이 통과가 허용된다.
- 방화벽 자체가 침입 시도에 안전해야 한다.
기관은 일반적으로 내부의 네트워크를 ISP에 연결하는 게이트웨이 라우터를 갖는다.
외부와 내부를 오가는 모든 트래픽은이 라우터를 지나야만 하고, 이 라우터에서 **패킷 필터링**이 일어난다.
**필터링 결정의 근거**
- IP 출발지 또는 목적지 주소
  - 불행히 출발지 주소를 위장한 데이터그램을 막을 수 없다.
- IP 데이터그램 내의 프로토콜 타입 : TCP,UDP OSPF 등
- TCP 또는 UDP 출발지와 목적지 포트
- TCP 플래그 비트 : SYN, ACK
  - ACK 비트가 0인 입력 세그먼트를 거른다면 외부에서 오는 모든 TCP 연결은 거부하고, 내부에서 나가는 건 허락한다.
- ICMP 메시지 타입
- 네트워크에서 나가는 데이터그램과 들어오는 데이터그램에 대한 서로 다른 규칙들
- 서로 다른 라우터 인터페이스에 대한 서로 다른 규칙들
네트워크 관리자는 기관의 정책에 기초해서 방화벽을 설정한다.
예를 들어, 공개 웹 서버 접속 목적을 제외한 어떠한 TCP 연결도 받고 싶지 않다면, 목적지 포트 80번과 웹 서버에 해당하는 목적지 주소를 가진 TCP SYN 세그먼트를 제외한 모든 TCP SYN 세그먼트를 막을 수 있다.
방화벽의 규칙은 접속 제어 목록과 함께 라우터에 구현된다.
상황 고려 필터는 TCP 연결을 추적하여 이 정보를 패킷 차단 결정을 하는 데 이용한다.
상황 고려 필터는 연결 고려 테이블에 있는 진행 중인 모든 TCP 연결을 추적함으로써 전통적인 패킷 필터에서 통과되던 패킷도 관리한다. (관리하지 않는다면 Dos 공격 등을 막을 수 없다.)
예를들어, SYN,SYNACK,ACK,FIN을 관찰하여 연결이 60초 동안 사용되지 않는다면 그 연결은 이미 종료되었다고 가정할 수 있다.
상황 고려 필터는 접속 제어 목록에 **연결 검사**라는 새로운 열을 포함한다.
예를 들어, 외부에서 조작된 패킷을 TCP 출발지 포트 80번, ACK 플래그를 1로 설정하여 내부로 보내려고 한다고 해보자.
전통적인 패킷 필터는 이를 막을 수 없지만 상황 고려 필터는 연결 검사를 열을 통해 외부에서 들어오는 패킷을 연결 검사 테이블에서 연결된 상태인지 확인하고 조작된 패킷은 연결 검사 테이블에 없으므로 필터링된다.
좀 더 세밀한 수준의 보안을 위해 방화벽은 패킷 필터를 애플리케이션 게이트웨이와 결합해야 한다.
애플리케이션 게이트웨이는 모든 애플리케이션 데이터가 반드시 통과해야 하는 애플리케이션 맞춤 서버다.
다수의 애플리케이션 게이트웨이가 같은 호스트에서 실행될 수 있으나 각 게이트웨이는 자신만의 프로세스들을 가진 분리된 서버다.
제한된 내부 사용자만 외부로의 텔넷이 가능하게 하고 모든 외부 클라이언트는 내부로 텔넷을 수행하지 못하게 하는 방화벽을 설계해보자.
1. 애플리케이션 게이트웨이의 IP주소로부터 시작된 텔넷 연결을 제외하고 모든 텔넷 열결 시도를 막도록 라우터의 필터를 설정한다.
   - 이는 외부로의 모든 텔넷 연결이 애플리케이션 게이트웨이를 통과하게 한다.
2. 사용자는 먼저 애플리케이션 게이트웨이와 텔넷 세션을 설정한다.
3. 게이트웨이에는 입력되는 텔넷 세션 요청을 듣고 있는 애플리케이션이 있어서 사용자에게 ID와 비밀번호를 요구한다.
4. 사용자가 입력하면, 애플리케이션 게이트웨이는 그 사용자가 외부로의 텔넷 연결이 효용되어있는지 검사한다.
   - 허가되지 않았다면, 게이트웨이에 의해 종료된다.
   - 허가되었다면, 사용자가 원하는 외부 호스트의 이름을 묻고, 게이트웨이와 외부 호스트 간의 텔넷 연결을 설정한 후 내부 사용자에게서 오는 데이터를 외부 호스트에게 전달한다.
   - 즉, 애플리케이션 게이트웨이는 인증 뿐만 아니라 데이터 전달도 수행한다.
**단점**
1. 각 애플리케이션마다 서로 다른 애플리케이션 게이트웨이를 필요로 한다.
2. 모든 데이터가 게이트웨이를 경유하여 중계되므로 성능상의 손실이 있다.
3. 클라이언트 소프트웨어는 사용자가 요구할 때 어떻게 게이트웨이와 통신할 수 있는지 알아야 하며, 어떤 외부 서버에 연결할지 애플리케이션 게이트웨이에게 알려줄 수 있어야 한다.
자신의 IP 주소를 웹사이트에 남기고 싶지 않고 지역 ISP에 그 웹사이트에 방문한 사실을 남기고 싶지 않은 익명성을 원한다면 어떻게 해야할까?
신뢰할 수 있는 프록시 서버와 SSL의 조합을 사용할 수 있다.
1. 프록시와 SSL 연결을 설립한 후 이 연결을 통해 희망하는 사이트에 대한 HTTP 요청을 전송한다.
2. 프록시가 SSL로 암호화된 HTTP 요청을 복호화 해서 평문 형식의 HTTP 요청을 웹사이트로 전송한다.
3. 웹사이트는 프록시로 응답을 보내고, 프록시는 SSL을 통해 응답을 호스트에게 보낸다.
그러나 프록시는 결국 모든 것을 알고 있으므로 신뢰할 수 있는 프록시 서버를 사용하는 것이 중요하다.
통과하려는 패킷 헤더를 살펴볼 뿐만 아니라 자세한 패킷 관찰을 수행하는 새로운 틈새 장치에 대한 요구가 있다.
악의적일 수 있는 트래픽을 발견했을 때 경고를 발생시키는 장치를 침입 탐지 시스템(**intrusion detection system,IDS**)이라고 한다.
의심스러운 트래픽을 걸러내는 장치는 침입 방지 시스템(**intrusion prevention system ,IPS**)이라고 한다.
이 둘의 중요한 점은 어떻게 의심스러운 트래픽을 발견하느냐 이므로 두 시스템을 통틀어 IDS 시스템으로 호칭한다.
한 기관에서 IDS는 여러개일 수 있는데, 서로 협조하며 의심스러운 트래픽이 있을 땐 중앙 IDS 프로세서에 전달되어 네트워크 관리자에게 전달된다.
위 그림은 패킷 필터와 애플리케이션 게이트웨이에 의해 보호되고 IDS에 의해 감시되는 높은 보호 구역과 패킷 필터와 IDS만을 사용하는 낮은 구역으로 나눌 수 있다.
IDS는 지나가는 각각의 패킷을 수만 개의 시그니처와 비교해야하기 때문에 많은 연산이 필요하고 IDS를 안쪽에 위치시켜 전체 트래픽 중 일부만 관찰하면 되도록 한다.
시그니처 기반 IDS는 공격 시그니처에 대한 방대한 데이터베이스를 유지한다.
각 시그니처는 침입 행위에 관련된 규칙들의 집합이다.
시그니처는 단순히 단일 패킷에 대한 특징의 목록일 수도 있고, 연속된 일련의 패킷들에 관련한 것일 수도 있다.
네트워크 관리자는 시그니처를 자신에 맞게 수정하고 그것을 데이터베이스에 추가할 수 있다.
시그니처 기반 IDS는 지나가는 모든 패킷을 읽어 데이터베이스 내의 시그니처들과 비교한다.
만일 어떤 패킷이 데이터베이스 내의 시그니처와 일치하면 경고를 발생시킨다.
그러나 이 방법은 새로운 공격에 대해 대비할 수 없고, 모든 패킷이 데이터베이스와 비교되어야하므로 성능이 좋지 않다.
트래픽을 관찰할 때 트래픽 분석표를 만든다.
그 후 ICMP 패킷의 빈도가 지나치게 높다든지 포트 정보 수집과 ping 메시지가 갑자기 증가하는 등 통계학적으로 비정상적인 패킷의 스트림을 찾는다.
